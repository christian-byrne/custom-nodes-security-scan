
<!DOCTYPE html>
<html>
<head>

<meta charset="UTF-8">

<title>
    Bandit Report
</title>

<style>

html * {
    font-family: "Arial", sans-serif;
}

pre {
    font-family: "Monaco", monospace;
}

.bordered-box {
    border: 1px solid black;
    padding-top:.5em;
    padding-bottom:.5em;
    padding-left:1em;
}

.metrics-box {
    font-size: 1.1em;
    line-height: 130%;
}

.metrics-title {
    font-size: 1.5em;
    font-weight: 500;
    margin-bottom: .25em;
}

.issue-description {
    font-size: 1.3em;
    font-weight: 500;
}

.candidate-issues {
    margin-left: 2em;
    border-left: solid 1px; LightGray;
    padding-left: 5%;
    margin-top: .2em;
    margin-bottom: .2em;
}

.issue-block {
    border: 1px solid LightGray;
    padding-left: .5em;
    padding-top: .5em;
    padding-bottom: .5em;
    margin-bottom: .5em;
}

.issue-sev-high {
    background-color: Pink;
}

.issue-sev-medium {
    background-color: NavajoWhite;
}

.issue-sev-low {
    background-color: LightCyan;
}

</style>
</head>

<body>

<div id="metrics">
    <div class="metrics-box bordered-box">
        <div class="metrics-title">
            Metrics:<br>
        </div>
        Total lines of code: <span id="loc">14599</span><br>
        Total lines skipped (#nosec): <span id="nosec">0</span>
    </div>
</div>




<br>
<div id="results">
    
<div id="issue-0">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>9<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
</pre>
</div>


</div>
</div>

<div id="issue-1">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>9<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
</pre>
</div>


</div>
</div>

<div id="issue-2">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>10<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
</pre>
</div>


</div>
</div>

<div id="issue-3">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>10<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
</pre>
</div>


</div>
</div>

<div id="issue-4">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>33<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
122	                        channel_multiplier=2,
</pre>
</div>


</div>
</div>

<div id="issue-5">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>33<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
122	                        channel_multiplier=2,
</pre>
</div>


</div>
</div>

<div id="issue-6">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>37<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
</pre>
</div>


</div>
</div>

<div id="issue-7">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>37<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
</pre>
</div>


</div>
</div>

<div id="issue-8">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>40<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
</pre>
</div>


</div>
</div>

<div id="issue-9">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>40<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
</pre>
</div>


</div>
</div>

<div id="issue-10">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>43<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
</pre>
</div>


</div>
</div>

<div id="issue-11">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>43<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
</pre>
</div>


</div>
</div>

<div id="issue-12">
<div class="issue-block issue-sev-low">
    <b>start_process_with_a_shell: </b> Starting a process with a shell: Seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>46<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
122	                        channel_multiplier=2,
</pre>
</div>


</div>
</div>

<div id="issue-13">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/cog_predict.py</a><br>
    <b>Line number: </b>46<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# flake8: noqa
2	# This file is used for deploying replicate models
3	# running: cog predict -i img=@inputs/whole_imgs/10045.png -i version=&#x27;v1.4&#x27; -i scale=2
4	# push: cog push r8.im/tencentarc/gfpgan
5	# push (backup): cog push r8.im/xinntao/gfpgan
6	
7	import os
8	
9	os.system(&#x27;python setup.py develop&#x27;)
10	os.system(&#x27;pip install realesrgan&#x27;)
11	
12	import cv2
13	import shutil
14	import tempfile
15	import torch
16	from basicsr.archs.srvgg_arch import SRVGGNetCompact
17	
18	from gfpgan import GFPGANer
19	
20	try:
21	    from cog import BasePredictor, Input, Path
22	    from realesrgan.utils import RealESRGANer
23	except Exception:
24	    print(&#x27;please install cog and realesrgan package&#x27;)
25	
26	
27	class Predictor(BasePredictor):
28	
29	    def setup(self):
30	        os.makedirs(&#x27;output&#x27;, exist_ok=True)
31	        # download weights
32	        if not os.path.exists(&#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;):
33	            os.system(
34	                &#x27;wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P ./gfpgan/weights&#x27;
35	            )
36	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;):
37	            os.system(
38	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.2.pth -P ./gfpgan/weights&#x27;)
39	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;):
40	            os.system(
41	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P ./gfpgan/weights&#x27;)
42	        if not os.path.exists(&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;):
43	            os.system(
44	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P ./gfpgan/weights&#x27;)
45	        if not os.path.exists(&#x27;gfpgan/weights/RestoreFormer.pth&#x27;):
46	            os.system(
47	                &#x27;wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P ./gfpgan/weights&#x27;
48	            )
49	
50	        # background enhancer with RealESRGAN
51	        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type=&#x27;prelu&#x27;)
52	        model_path = &#x27;gfpgan/weights/realesr-general-x4v3.pth&#x27;
53	        half = True if torch.cuda.is_available() else False
54	        self.upsampler = RealESRGANer(
55	            scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=half)
56	
57	        # Use GFPGAN for face enhancement
58	        self.face_enhancer = GFPGANer(
59	            model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
60	            upscale=2,
61	            arch=&#x27;clean&#x27;,
62	            channel_multiplier=2,
63	            bg_upsampler=self.upsampler)
64	        self.current_version = &#x27;v1.4&#x27;
65	
66	    def predict(
67	            self,
68	            img: Path = Input(description=&#x27;Input&#x27;),
69	            version: str = Input(
70	                description=&#x27;GFPGAN version. v1.3: better quality. v1.4: more details and better identity.&#x27;,
71	                choices=[&#x27;v1.2&#x27;, &#x27;v1.3&#x27;, &#x27;v1.4&#x27;, &#x27;RestoreFormer&#x27;],
72	                default=&#x27;v1.4&#x27;),
73	            scale: float = Input(description=&#x27;Rescaling factor&#x27;, default=2),
74	    ) -&gt; Path:
75	        weight = 0.5
76	        print(img, version, scale, weight)
77	        try:
78	            extension = os.path.splitext(os.path.basename(str(img)))[1]
79	            img = cv2.imread(str(img), cv2.IMREAD_UNCHANGED)
80	            if len(img.shape) == 3 and img.shape[2] == 4:
81	                img_mode = &#x27;RGBA&#x27;
82	            elif len(img.shape) == 2:
83	                img_mode = None
84	                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
85	            else:
86	                img_mode = None
87	
88	            h, w = img.shape[0:2]
89	            if h &lt; 300:
90	                img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)
91	
92	            if self.current_version != version:
93	                if version == &#x27;v1.2&#x27;:
94	                    self.face_enhancer = GFPGANer(
95	                        model_path=&#x27;gfpgan/weights/GFPGANv1.2.pth&#x27;,
96	                        upscale=2,
97	                        arch=&#x27;clean&#x27;,
98	                        channel_multiplier=2,
99	                        bg_upsampler=self.upsampler)
100	                    self.current_version = &#x27;v1.2&#x27;
101	                elif version == &#x27;v1.3&#x27;:
102	                    self.face_enhancer = GFPGANer(
103	                        model_path=&#x27;gfpgan/weights/GFPGANv1.3.pth&#x27;,
104	                        upscale=2,
105	                        arch=&#x27;clean&#x27;,
106	                        channel_multiplier=2,
107	                        bg_upsampler=self.upsampler)
108	                    self.current_version = &#x27;v1.3&#x27;
109	                elif version == &#x27;v1.4&#x27;:
110	                    self.face_enhancer = GFPGANer(
111	                        model_path=&#x27;gfpgan/weights/GFPGANv1.4.pth&#x27;,
112	                        upscale=2,
113	                        arch=&#x27;clean&#x27;,
114	                        channel_multiplier=2,
115	                        bg_upsampler=self.upsampler)
116	                    self.current_version = &#x27;v1.4&#x27;
117	                elif version == &#x27;RestoreFormer&#x27;:
118	                    self.face_enhancer = GFPGANer(
119	                        model_path=&#x27;gfpgan/weights/RestoreFormer.pth&#x27;,
120	                        upscale=2,
121	                        arch=&#x27;RestoreFormer&#x27;,
122	                        channel_multiplier=2,
</pre>
</div>


</div>
</div>

<div id="issue-14">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/setup.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/setup.py</a><br>
    <b>Line number: </b>6<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	#!/usr/bin/env python
2	
3	from setuptools import find_packages, setup
4	
5	import os
6	import subprocess
7	import time
8	
9	version_file = &#x27;gfpgan/version.py&#x27;
10	
11	
12	def readme():
13	    with open(&#x27;README.md&#x27;, encoding=&#x27;utf-8&#x27;) as f:
14	        content = f.read()
15	    return content
16	
17	
18	def get_git_hash():
19	
20	    def _minimal_ext_cmd(cmd):
21	        # construct minimal environment
22	        env = {}
23	        for k in [&#x27;SYSTEMROOT&#x27;, &#x27;PATH&#x27;, &#x27;HOME&#x27;]:
24	            v = os.environ.get(k)
25	            if v is not None:
26	                env[k] = v
27	        # LANGUAGE is used on win32
28	        env[&#x27;LANGUAGE&#x27;] = &#x27;C&#x27;
29	        env[&#x27;LANG&#x27;] = &#x27;C&#x27;
30	        env[&#x27;LC_ALL&#x27;] = &#x27;C&#x27;
31	        out = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=env).communicate()[0]
32	        return out
33	
34	    try:
35	        out = _minimal_ext_cmd([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
36	        sha = out.strip().decode(&#x27;ascii&#x27;)
37	    except OSError:
38	        sha = &#x27;unknown&#x27;
39	
40	    return sha
41	
42	
43	def get_hash():
44	    if os.path.exists(&#x27;.git&#x27;):
45	        sha = get_git_hash()[:7]
46	    else:
47	        sha = &#x27;unknown&#x27;
48	
49	    return sha
50	
51	
52	def write_version_py():
53	    content = &quot;&quot;&quot;# GENERATED VERSION FILE
54	# TIME: {}
55	__version__ = &#x27;{}&#x27;
56	__gitsha__ = &#x27;{}&#x27;
57	version_info = ({})
58	&quot;&quot;&quot;
59	    sha = get_hash()
60	    with open(&#x27;VERSION&#x27;, &#x27;r&#x27;) as f:
61	        SHORT_VERSION = f.read().strip()
62	    VERSION_INFO = &#x27;, &#x27;.join([x if x.isdigit() else f&#x27;&quot;{x}&quot;&#x27; for x in SHORT_VERSION.split(&#x27;.&#x27;)])
63	
64	    version_file_str = content.format(time.asctime(), SHORT_VERSION, sha, VERSION_INFO)
65	    with open(version_file, &#x27;w&#x27;) as f:
66	        f.write(version_file_str)
67	
68	
69	def get_version():
70	    with open(version_file, &#x27;r&#x27;) as f:
71	        exec(compile(f.read(), version_file, &#x27;exec&#x27;))
72	    return locals()[&#x27;__version__&#x27;]
73	
74	
75	def get_requirements(filename=&#x27;requirements.txt&#x27;):
76	    here = os.path.dirname(os.path.realpath(__file__))
77	    with open(os.path.join(here, filename), &#x27;r&#x27;) as f:
78	        requires = [line.replace(&#x27;\n&#x27;, &#x27;&#x27;) for line in f.readlines()]
79	    return requires
80	
81	
82	if __name__ == &#x27;__main__&#x27;:
83	    write_version_py()
84	    setup(
85	        name=&#x27;gfpgan&#x27;,
86	        version=get_version(),
87	        description=&#x27;GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration&#x27;,
88	        long_description=readme(),
89	        long_description_content_type=&#x27;text/markdown&#x27;,
90	        author=&#x27;Xintao Wang&#x27;,
91	        author_email=&#x27;xintao.wang@outlook.com&#x27;,
92	        keywords=&#x27;computer vision, pytorch, image restoration, super-resolution, face restoration, gan, gfpgan&#x27;,
93	        url=&#x27;https://github.com/TencentARC/GFPGAN&#x27;,
94	        include_package_data=True,
95	        packages=find_packages(exclude=(&#x27;options&#x27;, &#x27;datasets&#x27;, &#x27;experiments&#x27;, &#x27;results&#x27;, &#x27;tb_logger&#x27;, &#x27;wandb&#x27;)),
96	        classifiers=[
97	            &#x27;Development Status :: 4 - Beta&#x27;,
98	            &#x27;License :: OSI Approved :: Apache Software License&#x27;,
99	            &#x27;Operating System :: OS Independent&#x27;,
100	            &#x27;Programming Language :: Python :: 3&#x27;,
101	            &#x27;Programming Language :: Python :: 3.7&#x27;,
102	            &#x27;Programming Language :: Python :: 3.8&#x27;,
103	        ],
104	        license=&#x27;Apache License Version 2.0&#x27;,
105	        setup_requires=[&#x27;cython&#x27;, &#x27;numpy&#x27;],
106	        install_requires=get_requirements(),
107	        zip_safe=False)
</pre>
</div>


</div>
</div>

<div id="issue-15">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/setup.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/setup.py</a><br>
    <b>Line number: </b>31<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	#!/usr/bin/env python
2	
3	from setuptools import find_packages, setup
4	
5	import os
6	import subprocess
7	import time
8	
9	version_file = &#x27;gfpgan/version.py&#x27;
10	
11	
12	def readme():
13	    with open(&#x27;README.md&#x27;, encoding=&#x27;utf-8&#x27;) as f:
14	        content = f.read()
15	    return content
16	
17	
18	def get_git_hash():
19	
20	    def _minimal_ext_cmd(cmd):
21	        # construct minimal environment
22	        env = {}
23	        for k in [&#x27;SYSTEMROOT&#x27;, &#x27;PATH&#x27;, &#x27;HOME&#x27;]:
24	            v = os.environ.get(k)
25	            if v is not None:
26	                env[k] = v
27	        # LANGUAGE is used on win32
28	        env[&#x27;LANGUAGE&#x27;] = &#x27;C&#x27;
29	        env[&#x27;LANG&#x27;] = &#x27;C&#x27;
30	        env[&#x27;LC_ALL&#x27;] = &#x27;C&#x27;
31	        out = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=env).communicate()[0]
32	        return out
33	
34	    try:
35	        out = _minimal_ext_cmd([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
36	        sha = out.strip().decode(&#x27;ascii&#x27;)
37	    except OSError:
38	        sha = &#x27;unknown&#x27;
39	
40	    return sha
41	
42	
43	def get_hash():
44	    if os.path.exists(&#x27;.git&#x27;):
45	        sha = get_git_hash()[:7]
46	    else:
47	        sha = &#x27;unknown&#x27;
48	
49	    return sha
50	
51	
52	def write_version_py():
53	    content = &quot;&quot;&quot;# GENERATED VERSION FILE
54	# TIME: {}
55	__version__ = &#x27;{}&#x27;
56	__gitsha__ = &#x27;{}&#x27;
57	version_info = ({})
58	&quot;&quot;&quot;
59	    sha = get_hash()
60	    with open(&#x27;VERSION&#x27;, &#x27;r&#x27;) as f:
61	        SHORT_VERSION = f.read().strip()
62	    VERSION_INFO = &#x27;, &#x27;.join([x if x.isdigit() else f&#x27;&quot;{x}&quot;&#x27; for x in SHORT_VERSION.split(&#x27;.&#x27;)])
63	
64	    version_file_str = content.format(time.asctime(), SHORT_VERSION, sha, VERSION_INFO)
65	    with open(version_file, &#x27;w&#x27;) as f:
66	        f.write(version_file_str)
67	
68	
69	def get_version():
70	    with open(version_file, &#x27;r&#x27;) as f:
71	        exec(compile(f.read(), version_file, &#x27;exec&#x27;))
72	    return locals()[&#x27;__version__&#x27;]
73	
74	
75	def get_requirements(filename=&#x27;requirements.txt&#x27;):
76	    here = os.path.dirname(os.path.realpath(__file__))
77	    with open(os.path.join(here, filename), &#x27;r&#x27;) as f:
78	        requires = [line.replace(&#x27;\n&#x27;, &#x27;&#x27;) for line in f.readlines()]
79	    return requires
80	
81	
82	if __name__ == &#x27;__main__&#x27;:
83	    write_version_py()
84	    setup(
85	        name=&#x27;gfpgan&#x27;,
86	        version=get_version(),
87	        description=&#x27;GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration&#x27;,
88	        long_description=readme(),
89	        long_description_content_type=&#x27;text/markdown&#x27;,
90	        author=&#x27;Xintao Wang&#x27;,
91	        author_email=&#x27;xintao.wang@outlook.com&#x27;,
92	        keywords=&#x27;computer vision, pytorch, image restoration, super-resolution, face restoration, gan, gfpgan&#x27;,
93	        url=&#x27;https://github.com/TencentARC/GFPGAN&#x27;,
94	        include_package_data=True,
95	        packages=find_packages(exclude=(&#x27;options&#x27;, &#x27;datasets&#x27;, &#x27;experiments&#x27;, &#x27;results&#x27;, &#x27;tb_logger&#x27;, &#x27;wandb&#x27;)),
96	        classifiers=[
97	            &#x27;Development Status :: 4 - Beta&#x27;,
98	            &#x27;License :: OSI Approved :: Apache Software License&#x27;,
99	            &#x27;Operating System :: OS Independent&#x27;,
100	            &#x27;Programming Language :: Python :: 3&#x27;,
101	            &#x27;Programming Language :: Python :: 3.7&#x27;,
102	            &#x27;Programming Language :: Python :: 3.8&#x27;,
103	        ],
104	        license=&#x27;Apache License Version 2.0&#x27;,
105	        setup_requires=[&#x27;cython&#x27;, &#x27;numpy&#x27;],
106	        install_requires=get_requirements(),
107	        zip_safe=False)
</pre>
</div>


</div>
</div>

<div id="issue-16">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/setup.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/setup.py</a><br>
    <b>Line number: </b>71<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
11	
12	def readme():
13	    with open(&#x27;README.md&#x27;, encoding=&#x27;utf-8&#x27;) as f:
14	        content = f.read()
15	    return content
16	
17	
18	def get_git_hash():
19	
20	    def _minimal_ext_cmd(cmd):
21	        # construct minimal environment
22	        env = {}
23	        for k in [&#x27;SYSTEMROOT&#x27;, &#x27;PATH&#x27;, &#x27;HOME&#x27;]:
24	            v = os.environ.get(k)
25	            if v is not None:
26	                env[k] = v
27	        # LANGUAGE is used on win32
28	        env[&#x27;LANGUAGE&#x27;] = &#x27;C&#x27;
29	        env[&#x27;LANG&#x27;] = &#x27;C&#x27;
30	        env[&#x27;LC_ALL&#x27;] = &#x27;C&#x27;
31	        out = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=env).communicate()[0]
32	        return out
33	
34	    try:
35	        out = _minimal_ext_cmd([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
36	        sha = out.strip().decode(&#x27;ascii&#x27;)
37	    except OSError:
38	        sha = &#x27;unknown&#x27;
39	
40	    return sha
41	
42	
43	def get_hash():
44	    if os.path.exists(&#x27;.git&#x27;):
45	        sha = get_git_hash()[:7]
46	    else:
47	        sha = &#x27;unknown&#x27;
48	
49	    return sha
50	
51	
52	def write_version_py():
53	    content = &quot;&quot;&quot;# GENERATED VERSION FILE
54	# TIME: {}
55	__version__ = &#x27;{}&#x27;
56	__gitsha__ = &#x27;{}&#x27;
57	version_info = ({})
58	&quot;&quot;&quot;
59	    sha = get_hash()
60	    with open(&#x27;VERSION&#x27;, &#x27;r&#x27;) as f:
61	        SHORT_VERSION = f.read().strip()
62	    VERSION_INFO = &#x27;, &#x27;.join([x if x.isdigit() else f&#x27;&quot;{x}&quot;&#x27; for x in SHORT_VERSION.split(&#x27;.&#x27;)])
63	
64	    version_file_str = content.format(time.asctime(), SHORT_VERSION, sha, VERSION_INFO)
65	    with open(version_file, &#x27;w&#x27;) as f:
66	        f.write(version_file_str)
67	
68	
69	def get_version():
70	    with open(version_file, &#x27;r&#x27;) as f:
71	        exec(compile(f.read(), version_file, &#x27;exec&#x27;))
72	    return locals()[&#x27;__version__&#x27;]
73	
74	
75	def get_requirements(filename=&#x27;requirements.txt&#x27;):
76	    here = os.path.dirname(os.path.realpath(__file__))
77	    with open(os.path.join(here, filename), &#x27;r&#x27;) as f:
78	        requires = [line.replace(&#x27;\n&#x27;, &#x27;&#x27;) for line in f.readlines()]
79	    return requires
80	
81	
82	if __name__ == &#x27;__main__&#x27;:
83	    write_version_py()
84	    setup(
85	        name=&#x27;gfpgan&#x27;,
86	        version=get_version(),
87	        description=&#x27;GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration&#x27;,
88	        long_description=readme(),
89	        long_description_content_type=&#x27;text/markdown&#x27;,
90	        author=&#x27;Xintao Wang&#x27;,
91	        author_email=&#x27;xintao.wang@outlook.com&#x27;,
92	        keywords=&#x27;computer vision, pytorch, image restoration, super-resolution, face restoration, gan, gfpgan&#x27;,
93	        url=&#x27;https://github.com/TencentARC/GFPGAN&#x27;,
94	        include_package_data=True,
95	        packages=find_packages(exclude=(&#x27;options&#x27;, &#x27;datasets&#x27;, &#x27;experiments&#x27;, &#x27;results&#x27;, &#x27;tb_logger&#x27;, &#x27;wandb&#x27;)),
96	        classifiers=[
97	            &#x27;Development Status :: 4 - Beta&#x27;,
98	            &#x27;License :: OSI Approved :: Apache Software License&#x27;,
99	            &#x27;Operating System :: OS Independent&#x27;,
100	            &#x27;Programming Language :: Python :: 3&#x27;,
101	            &#x27;Programming Language :: Python :: 3.7&#x27;,
102	            &#x27;Programming Language :: Python :: 3.8&#x27;,
103	        ],
104	        license=&#x27;Apache License Version 2.0&#x27;,
105	        setup_requires=[&#x27;cython&#x27;, &#x27;numpy&#x27;],
106	        install_requires=get_requirements(),
107	        zip_safe=False)
</pre>
</div>


</div>
</div>

<div id="issue-17">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/tests/test_ffhq_degradation_dataset.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/tests/test_ffhq_degradation_dataset.py</a><br>
    <b>Line number: </b>10<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	import pytest
2	import yaml
3	
4	from gfpgan.data.ffhq_degradation_dataset import FFHQDegradationDataset
5	
6	
7	def test_ffhq_degradation_dataset():
8	
9	    with open(&#x27;tests/data/test_ffhq_degradation_dataset.yml&#x27;, mode=&#x27;r&#x27;) as f:
10	        opt = yaml.load(f, Loader=yaml.FullLoader)
11	
12	    dataset = FFHQDegradationDataset(opt)
13	    assert dataset.io_backend_opt[&#x27;type&#x27;] == &#x27;disk&#x27;  # io backend
14	    assert len(dataset) == 1  # whether to read correct meta info
15	    assert dataset.kernel_list == [&#x27;iso&#x27;, &#x27;aniso&#x27;]  # correct initialization the degradation configurations
16	    assert dataset.color_jitter_prob == 1
17	
18	    # test __getitem__
19	    result = dataset.__getitem__(0)
20	    # check returned keys
21	    expected_keys = [&#x27;gt&#x27;, &#x27;lq&#x27;, &#x27;gt_path&#x27;]
22	    assert set(expected_keys).issubset(set(result.keys()))
23	    # check shape and contents
24	    assert result[&#x27;gt&#x27;].shape == (3, 512, 512)
25	    assert result[&#x27;lq&#x27;].shape == (3, 512, 512)
26	    assert result[&#x27;gt_path&#x27;] == &#x27;tests/data/gt/00000000.png&#x27;
27	
28	    # ------------------ test with probability = 0 -------------------- #
29	    opt[&#x27;color_jitter_prob&#x27;] = 0
30	    opt[&#x27;color_jitter_pt_prob&#x27;] = 0
31	    opt[&#x27;gray_prob&#x27;] = 0
32	    opt[&#x27;io_backend&#x27;] = dict(type=&#x27;disk&#x27;)
33	    dataset = FFHQDegradationDataset(opt)
34	    assert dataset.io_backend_opt[&#x27;type&#x27;] == &#x27;disk&#x27;  # io backend
35	    assert len(dataset) == 1  # whether to read correct meta info
36	    assert dataset.kernel_list == [&#x27;iso&#x27;, &#x27;aniso&#x27;]  # correct initialization the degradation configurations
37	    assert dataset.color_jitter_prob == 0
38	
39	    # test __getitem__
40	    result = dataset.__getitem__(0)
41	    # check returned keys
42	    expected_keys = [&#x27;gt&#x27;, &#x27;lq&#x27;, &#x27;gt_path&#x27;]
43	    assert set(expected_keys).issubset(set(result.keys()))
44	    # check shape and contents
45	    assert result[&#x27;gt&#x27;].shape == (3, 512, 512)
46	    assert result[&#x27;lq&#x27;].shape == (3, 512, 512)
47	    assert result[&#x27;gt_path&#x27;] == &#x27;tests/data/gt/00000000.png&#x27;
48	
49	    # ------------------ test lmdb backend -------------------- #
50	    opt[&#x27;dataroot_gt&#x27;] = &#x27;tests/data/ffhq_gt.lmdb&#x27;
51	    opt[&#x27;io_backend&#x27;] = dict(type=&#x27;lmdb&#x27;)
52	
53	    dataset = FFHQDegradationDataset(opt)
54	    assert dataset.io_backend_opt[&#x27;type&#x27;] == &#x27;lmdb&#x27;  # io backend
55	    assert len(dataset) == 1  # whether to read correct meta info
56	    assert dataset.kernel_list == [&#x27;iso&#x27;, &#x27;aniso&#x27;]  # correct initialization the degradation configurations
57	    assert dataset.color_jitter_prob == 0
58	
59	    # test __getitem__
60	    result = dataset.__getitem__(0)
61	    # check returned keys
62	    expected_keys = [&#x27;gt&#x27;, &#x27;lq&#x27;, &#x27;gt_path&#x27;]
63	    assert set(expected_keys).issubset(set(result.keys()))
64	    # check shape and contents
65	    assert result[&#x27;gt&#x27;].shape == (3, 512, 512)
66	    assert result[&#x27;lq&#x27;].shape == (3, 512, 512)
67	    assert result[&#x27;gt_path&#x27;] == &#x27;00000000&#x27;
68	
69	    # ------------------ test with crop_components -------------------- #
70	    opt[&#x27;crop_components&#x27;] = True
71	    opt[&#x27;component_path&#x27;] = &#x27;tests/data/test_eye_mouth_landmarks.pth&#x27;
72	    opt[&#x27;eye_enlarge_ratio&#x27;] = 1.4
73	    opt[&#x27;gt_gray&#x27;] = True
74	    opt[&#x27;io_backend&#x27;] = dict(type=&#x27;lmdb&#x27;)
75	
76	    dataset = FFHQDegradationDataset(opt)
77	    assert dataset.crop_components is True
78	
79	    # test __getitem__
80	    result = dataset.__getitem__(0)
81	    # check returned keys
82	    expected_keys = [&#x27;gt&#x27;, &#x27;lq&#x27;, &#x27;gt_path&#x27;, &#x27;loc_left_eye&#x27;, &#x27;loc_right_eye&#x27;, &#x27;loc_mouth&#x27;]
83	    assert set(expected_keys).issubset(set(result.keys()))
84	    # check shape and contents
85	    assert result[&#x27;gt&#x27;].shape == (3, 512, 512)
86	    assert result[&#x27;lq&#x27;].shape == (3, 512, 512)
87	    assert result[&#x27;gt_path&#x27;] == &#x27;00000000&#x27;
88	    assert result[&#x27;loc_left_eye&#x27;].shape == (4, )
89	    assert result[&#x27;loc_right_eye&#x27;].shape == (4, )
90	    assert result[&#x27;loc_mouth&#x27;].shape == (4, )
91	
92	    # ------------------ lmdb backend should have paths ends with lmdb -------------------- #
93	    with pytest.raises(ValueError):
94	        opt[&#x27;dataroot_gt&#x27;] = &#x27;tests/data/gt&#x27;
95	        opt[&#x27;io_backend&#x27;] = dict(type=&#x27;lmdb&#x27;)
96	        dataset = FFHQDegradationDataset(opt)
</pre>
</div>


</div>
</div>

<div id="issue-18">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/tests/test_gfpgan_model.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/extern/GFPGAN/tests/test_gfpgan_model.py</a><br>
    <b>Line number: </b>15<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	import tempfile
2	import torch
3	import yaml
4	from basicsr.archs.stylegan2_arch import StyleGAN2Discriminator
5	from basicsr.data.paired_image_dataset import PairedImageDataset
6	from basicsr.losses.losses import GANLoss, L1Loss, PerceptualLoss
7	
8	from gfpgan.archs.arcface_arch import ResNetArcFace
9	from gfpgan.archs.gfpganv1_arch import FacialComponentDiscriminator, GFPGANv1
10	from gfpgan.models.gfpgan_model import GFPGANModel
11	
12	
13	def test_gfpgan_model():
14	    with open(&#x27;tests/data/test_gfpgan_model.yml&#x27;, mode=&#x27;r&#x27;) as f:
15	        opt = yaml.load(f, Loader=yaml.FullLoader)
16	
17	    # build model
18	    model = GFPGANModel(opt)
19	    # test attributes
20	    assert model.__class__.__name__ == &#x27;GFPGANModel&#x27;
21	    assert isinstance(model.net_g, GFPGANv1)  # generator
22	    assert isinstance(model.net_d, StyleGAN2Discriminator)  # discriminator
23	    # facial component discriminators
24	    assert isinstance(model.net_d_left_eye, FacialComponentDiscriminator)
25	    assert isinstance(model.net_d_right_eye, FacialComponentDiscriminator)
26	    assert isinstance(model.net_d_mouth, FacialComponentDiscriminator)
27	    # identity network
28	    assert isinstance(model.network_identity, ResNetArcFace)
29	    # losses
30	    assert isinstance(model.cri_pix, L1Loss)
31	    assert isinstance(model.cri_perceptual, PerceptualLoss)
32	    assert isinstance(model.cri_gan, GANLoss)
33	    assert isinstance(model.cri_l1, L1Loss)
34	    # optimizer
35	    assert isinstance(model.optimizers[0], torch.optim.Adam)
36	    assert isinstance(model.optimizers[1], torch.optim.Adam)
37	
38	    # prepare data
39	    gt = torch.rand((1, 3, 512, 512), dtype=torch.float32)
40	    lq = torch.rand((1, 3, 512, 512), dtype=torch.float32)
41	    loc_left_eye = torch.rand((1, 4), dtype=torch.float32)
42	    loc_right_eye = torch.rand((1, 4), dtype=torch.float32)
43	    loc_mouth = torch.rand((1, 4), dtype=torch.float32)
44	    data = dict(gt=gt, lq=lq, loc_left_eye=loc_left_eye, loc_right_eye=loc_right_eye, loc_mouth=loc_mouth)
45	    model.feed_data(data)
46	    # check data shape
47	    assert model.lq.shape == (1, 3, 512, 512)
48	    assert model.gt.shape == (1, 3, 512, 512)
49	    assert model.loc_left_eyes.shape == (1, 4)
50	    assert model.loc_right_eyes.shape == (1, 4)
51	    assert model.loc_mouths.shape == (1, 4)
52	
53	    # ----------------- test optimize_parameters -------------------- #
54	    model.feed_data(data)
55	    model.optimize_parameters(1)
56	    assert model.output.shape == (1, 3, 512, 512)
57	    assert isinstance(model.log_dict, dict)
58	    # check returned keys
59	    expected_keys = [
60	        &#x27;l_g_pix&#x27;, &#x27;l_g_percep&#x27;, &#x27;l_g_style&#x27;, &#x27;l_g_gan&#x27;, &#x27;l_g_gan_left_eye&#x27;, &#x27;l_g_gan_right_eye&#x27;, &#x27;l_g_gan_mouth&#x27;,
61	        &#x27;l_g_comp_style_loss&#x27;, &#x27;l_identity&#x27;, &#x27;l_d&#x27;, &#x27;real_score&#x27;, &#x27;fake_score&#x27;, &#x27;l_d_r1&#x27;, &#x27;l_d_left_eye&#x27;,
62	        &#x27;l_d_right_eye&#x27;, &#x27;l_d_mouth&#x27;
63	    ]
64	    assert set(expected_keys).issubset(set(model.log_dict.keys()))
65	
66	    # ----------------- remove pyramid_loss_weight-------------------- #
67	    model.feed_data(data)
68	    model.optimize_parameters(100000)  # large than remove_pyramid_loss = 50000
69	    assert model.output.shape == (1, 3, 512, 512)
70	    assert isinstance(model.log_dict, dict)
71	    # check returned keys
72	    expected_keys = [
73	        &#x27;l_g_pix&#x27;, &#x27;l_g_percep&#x27;, &#x27;l_g_style&#x27;, &#x27;l_g_gan&#x27;, &#x27;l_g_gan_left_eye&#x27;, &#x27;l_g_gan_right_eye&#x27;, &#x27;l_g_gan_mouth&#x27;,
74	        &#x27;l_g_comp_style_loss&#x27;, &#x27;l_identity&#x27;, &#x27;l_d&#x27;, &#x27;real_score&#x27;, &#x27;fake_score&#x27;, &#x27;l_d_r1&#x27;, &#x27;l_d_left_eye&#x27;,
75	        &#x27;l_d_right_eye&#x27;, &#x27;l_d_mouth&#x27;
76	    ]
77	    assert set(expected_keys).issubset(set(model.log_dict.keys()))
78	
79	    # ----------------- test save -------------------- #
80	    with tempfile.TemporaryDirectory() as tmpdir:
81	        model.opt[&#x27;path&#x27;][&#x27;models&#x27;] = tmpdir
82	        model.opt[&#x27;path&#x27;][&#x27;training_states&#x27;] = tmpdir
83	        model.save(0, 1)
84	
85	    # ----------------- test the test function -------------------- #
86	    model.test()
87	    assert model.output.shape == (1, 3, 512, 512)
88	    # delete net_g_ema
89	    model.__delattr__(&#x27;net_g_ema&#x27;)
90	    model.test()
91	    assert model.output.shape == (1, 3, 512, 512)
92	    assert model.net_g.training is True  # should back to training mode after testing
93	
94	    # ----------------- test nondist_validation -------------------- #
95	    # construct dataloader
96	    dataset_opt = dict(
97	        name=&#x27;Demo&#x27;,
98	        dataroot_gt=&#x27;tests/data/gt&#x27;,
99	        dataroot_lq=&#x27;tests/data/gt&#x27;,
100	        io_backend=dict(type=&#x27;disk&#x27;),
101	        scale=4,
102	        phase=&#x27;val&#x27;)
103	    dataset = PairedImageDataset(dataset_opt)
104	    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1, shuffle=False, num_workers=0)
105	    assert model.is_train is True
106	    with tempfile.TemporaryDirectory() as tmpdir:
107	        model.opt[&#x27;path&#x27;][&#x27;visualization&#x27;] = tmpdir
108	        model.nondist_validation(dataloader, 1, None, save_img=True)
109	        assert model.is_train is True
110	        # check metric_results
111	        assert &#x27;psnr&#x27; in model.metric_results
112	        assert isinstance(model.metric_results[&#x27;psnr&#x27;], float)
113	
114	    # validation
115	    with tempfile.TemporaryDirectory() as tmpdir:
116	        model.opt[&#x27;is_train&#x27;] = False
117	        model.opt[&#x27;val&#x27;][&#x27;suffix&#x27;] = &#x27;test&#x27;
118	        model.opt[&#x27;path&#x27;][&#x27;visualization&#x27;] = tmpdir
119	        model.opt[&#x27;val&#x27;][&#x27;pbar&#x27;] = True
120	        model.nondist_validation(dataloader, 1, None, save_img=True)
</pre>
</div>


</div>
</div>

<div id="issue-19">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py</a><br>
    <b>Line number: </b>7<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import argparse
2	import ast
3	import os
4	import platform
5	import shlex
6	import stat
7	import subprocess
8	import sys
9	from contextlib import contextmanager
10	from importlib import import_module
11	from pathlib import Path
12	
13	import requests
14	
15	# region constants
16	here = Path(__file__).parent
17	executable = Path(sys.executable)
18	
19	# - detect mode
20	mode = None
21	if os.environ.get(&quot;COLAB_GPU&quot;):
22	    mode = &quot;colab&quot;
23	elif &quot;python_embeded&quot; in str(executable):
24	    mode = &quot;embeded&quot;
25	elif &quot;.venv&quot; in str(executable):
26	    mode = &quot;venv&quot;
27	
28	
29	if mode is None:
30	    mode = &quot;unknown&quot;
31	
32	repo_url = &quot;https://github.com/melmass/comfy_mtb.git&quot;
33	repo_owner = &quot;melmass&quot;
34	repo_name = &quot;comfy_mtb&quot;
35	short_platform = {
36	    &quot;windows&quot;: &quot;win_amd64&quot;,
37	    &quot;linux&quot;: &quot;linux_x86_64&quot;,
38	}
39	current_platform = platform.system().lower()
40	pip_map = {
41	    &quot;onnxruntime-gpu&quot;: &quot;onnxruntime&quot;,
42	    &quot;opencv-contrib&quot;: &quot;cv2&quot;,
43	    &quot;tb-nightly&quot;: &quot;tensorboard&quot;,
44	    &quot;protobuf&quot;: &quot;google.protobuf&quot;,
45	    &quot;qrcode[pil]&quot;: &quot;qrcode&quot;,
46	    &quot;requirements-parser&quot;: &quot;requirements&quot;
47	    # Add more mappings as needed
48	}
49	
50	# endregion
51	
52	# region ansi
53	# ANSI escape sequences for text styling
54	ANSI_FORMATS = {
55	    &quot;reset&quot;: &quot;\033[0m&quot;,
56	    &quot;bold&quot;: &quot;\033[1m&quot;,
57	    &quot;dim&quot;: &quot;\033[2m&quot;,
58	    &quot;italic&quot;: &quot;\033[3m&quot;,
59	    &quot;underline&quot;: &quot;\033[4m&quot;,
60	    &quot;blink&quot;: &quot;\033[5m&quot;,
61	    &quot;reverse&quot;: &quot;\033[7m&quot;,
62	    &quot;strike&quot;: &quot;\033[9m&quot;,
63	}
64	
65	ANSI_COLORS = {
66	    &quot;black&quot;: &quot;\033[30m&quot;,
67	    &quot;red&quot;: &quot;\033[31m&quot;,
68	    &quot;green&quot;: &quot;\033[32m&quot;,
69	    &quot;yellow&quot;: &quot;\033[33m&quot;,
70	    &quot;blue&quot;: &quot;\033[34m&quot;,
71	    &quot;magenta&quot;: &quot;\033[35m&quot;,
72	    &quot;cyan&quot;: &quot;\033[36m&quot;,
73	    &quot;white&quot;: &quot;\033[37m&quot;,
74	    &quot;bright_black&quot;: &quot;\033[30;1m&quot;,
75	    &quot;bright_red&quot;: &quot;\033[31;1m&quot;,
76	    &quot;bright_green&quot;: &quot;\033[32;1m&quot;,
77	    &quot;bright_yellow&quot;: &quot;\033[33;1m&quot;,
78	    &quot;bright_blue&quot;: &quot;\033[34;1m&quot;,
79	    &quot;bright_magenta&quot;: &quot;\033[35;1m&quot;,
80	    &quot;bright_cyan&quot;: &quot;\033[36;1m&quot;,
81	    &quot;bright_white&quot;: &quot;\033[37;1m&quot;,
82	    &quot;bg_black&quot;: &quot;\033[40m&quot;,
83	    &quot;bg_red&quot;: &quot;\033[41m&quot;,
84	    &quot;bg_green&quot;: &quot;\033[42m&quot;,
85	    &quot;bg_yellow&quot;: &quot;\033[43m&quot;,
86	    &quot;bg_blue&quot;: &quot;\033[44m&quot;,
87	    &quot;bg_magenta&quot;: &quot;\033[45m&quot;,
88	    &quot;bg_cyan&quot;: &quot;\033[46m&quot;,
89	    &quot;bg_white&quot;: &quot;\033[47m&quot;,
90	    &quot;bg_bright_black&quot;: &quot;\033[40;1m&quot;,
91	    &quot;bg_bright_red&quot;: &quot;\033[41;1m&quot;,
92	    &quot;bg_bright_green&quot;: &quot;\033[42;1m&quot;,
93	    &quot;bg_bright_yellow&quot;: &quot;\033[43;1m&quot;,
94	    &quot;bg_bright_blue&quot;: &quot;\033[44;1m&quot;,
95	    &quot;bg_bright_magenta&quot;: &quot;\033[45;1m&quot;,
96	    &quot;bg_bright_cyan&quot;: &quot;\033[46;1m&quot;,
97	    &quot;bg_bright_white&quot;: &quot;\033[47;1m&quot;,
98	}
99	
100	
101	def apply_format(text, *formats):
102	    &quot;&quot;&quot;Apply ANSI escape sequences for the specified formats to the given text.&quot;&quot;&quot;
103	    formatted_text = text
104	    for format in formats:
105	        formatted_text = f&quot;{ANSI_FORMATS.get(format, &#x27;&#x27;)}{formatted_text}{ANSI_FORMATS.get(&#x27;reset&#x27;, &#x27;&#x27;)}&quot;
106	    return formatted_text
107	
108	
109	def apply_color(text, color=None, background=None):
110	    &quot;&quot;&quot;Apply ANSI escape sequences for the specified color and background to the given text.&quot;&quot;&quot;
111	    formatted_text = text
112	    if color:
113	        formatted_text = f&quot;{ANSI_COLORS.get(color, &#x27;&#x27;)}{formatted_text}{ANSI_FORMATS.get(&#x27;reset&#x27;, &#x27;&#x27;)}&quot;
114	    if background:
115	        formatted_text = f&quot;{ANSI_COLORS.get(background, &#x27;&#x27;)}{formatted_text}{ANSI_FORMATS.get(&#x27;reset&#x27;, &#x27;&#x27;)}&quot;
116	    return formatted_text
117	
118	
119	def print_formatted(text, *formats, color=None, background=None, **kwargs):
120	    &quot;&quot;&quot;Print the given text with the specified formats, color, and background.&quot;&quot;&quot;
</pre>
</div>


</div>
</div>

<div id="issue-20">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py</a><br>
    <b>Line number: </b>180<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
120	    &quot;&quot;&quot;Print the given text with the specified formats, color, and background.&quot;&quot;&quot;
121	    formatted_text = apply_format(text, *formats)
122	    formatted_text = apply_color(formatted_text, color, background)
123	    file = kwargs.get(&quot;file&quot;, sys.stdout)
124	    header = &quot;[mtb install] &quot;
125	
126	    # Handle console encoding for Unicode characters (utf-8)
127	    encoded_header = header.encode(sys.stdout.encoding, errors=&quot;replace&quot;).decode(
128	        sys.stdout.encoding
129	    )
130	    encoded_text = formatted_text.encode(sys.stdout.encoding, errors=&quot;replace&quot;).decode(
131	        sys.stdout.encoding
132	    )
133	
134	    print(
135	        &quot; &quot; * len(encoded_header)
136	        if kwargs.get(&quot;no_header&quot;)
137	        else apply_color(apply_format(encoded_header, &quot;bold&quot;), color=&quot;yellow&quot;),
138	        encoded_text,
139	        file=file,
140	    )
141	
142	
143	# endregion
144	
145	
146	# region utils
147	def run_command(cmd, ignored_lines_start=None):
148	    if ignored_lines_start is None:
149	        ignored_lines_start = []
150	
151	    if isinstance(cmd, str):
152	        shell_cmd = cmd
153	    elif isinstance(cmd, list):
154	        shell_cmd = &quot; &quot;.join(
155	            arg.as_posix() if isinstance(arg, Path) else shlex.quote(str(arg))
156	            for arg in cmd
157	        )
158	    else:
159	        raise ValueError(
160	            &quot;Invalid &#x27;cmd&#x27; argument. It must be a string or a list of arguments.&quot;
161	        )
162	
163	    try:
164	        _run_command(shell_cmd, ignored_lines_start)
165	    except subprocess.CalledProcessError as e:
166	        print(f&quot;Command failed with return code: {e.returncode}&quot;, file=sys.stderr)
167	        print(e.stderr.strip(), file=sys.stderr)
168	
169	    except KeyboardInterrupt:
170	        print(&quot;Command execution interrupted.&quot;)
171	
172	
173	def _run_command(shell_cmd, ignored_lines_start):
174	    print_formatted(f&quot;Running {shell_cmd}&quot;, &quot;bold&quot;)
175	    result = subprocess.run(
176	        shell_cmd,
177	        stdout=subprocess.PIPE,
178	        stderr=subprocess.PIPE,
179	        text=True,
180	        shell=True,
181	        check=True,
182	    )
183	
184	    stdout_lines = result.stdout.strip().split(&quot;\n&quot;)
185	    stderr_lines = result.stderr.strip().split(&quot;\n&quot;)
186	
187	    # Print stdout, skipping ignored lines
188	    for line in stdout_lines:
189	        if not any(line.startswith(ign) for ign in ignored_lines_start):
190	            print(line)
191	
192	    # Print stderr
193	    for line in stderr_lines:
194	        print(line, file=sys.stderr)
195	
196	    print(&quot;Command executed successfully!&quot;)
197	
198	
199	def is_pipe():
200	    if not sys.stdin.isatty():
201	        return False
202	    if sys.platform == &quot;win32&quot;:
203	        try:
204	            import msvcrt
205	
206	            return msvcrt.get_osfhandle(0) != -1
207	        except ImportError:
208	            return False
209	    else:
210	        try:
211	            mode = os.fstat(0).st_mode
212	            return (
213	                stat.S_ISFIFO(mode)
214	                or stat.S_ISREG(mode)
215	                or stat.S_ISBLK(mode)
216	                or stat.S_ISSOCK(mode)
217	            )
218	        except OSError:
219	            return False
220	
221	
222	@contextmanager
223	def suppress_std():
224	    with open(os.devnull, &quot;w&quot;) as devnull:
225	        old_stdout = sys.stdout
226	        old_stderr = sys.stderr
227	        sys.stdout = devnull
228	        sys.stderr = devnull
229	
230	        try:
231	            yield
232	        finally:
233	            sys.stdout = old_stdout
234	            sys.stderr = old_stderr
235	
236	
237	# Get the version from __init__.py
238	def get_local_version():
239	    init_file = os.path.join(os.path.dirname(__file__), &quot;__init__.py&quot;)
240	    if os.path.isfile(init_file):
241	        with open(init_file, &quot;r&quot;) as f:
242	            tree = ast.parse(f.read())
243	            for node in ast.walk(tree):
244	                if isinstance(node, ast.Assign):
245	                    for target in node.targets:
246	                        if (
</pre>
</div>


</div>
</div>

<div id="issue-21">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py</a><br>
    <b>Line number: </b>256<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
196	    print(&quot;Command executed successfully!&quot;)
197	
198	
199	def is_pipe():
200	    if not sys.stdin.isatty():
201	        return False
202	    if sys.platform == &quot;win32&quot;:
203	        try:
204	            import msvcrt
205	
206	            return msvcrt.get_osfhandle(0) != -1
207	        except ImportError:
208	            return False
209	    else:
210	        try:
211	            mode = os.fstat(0).st_mode
212	            return (
213	                stat.S_ISFIFO(mode)
214	                or stat.S_ISREG(mode)
215	                or stat.S_ISBLK(mode)
216	                or stat.S_ISSOCK(mode)
217	            )
218	        except OSError:
219	            return False
220	
221	
222	@contextmanager
223	def suppress_std():
224	    with open(os.devnull, &quot;w&quot;) as devnull:
225	        old_stdout = sys.stdout
226	        old_stderr = sys.stderr
227	        sys.stdout = devnull
228	        sys.stderr = devnull
229	
230	        try:
231	            yield
232	        finally:
233	            sys.stdout = old_stdout
234	            sys.stderr = old_stderr
235	
236	
237	# Get the version from __init__.py
238	def get_local_version():
239	    init_file = os.path.join(os.path.dirname(__file__), &quot;__init__.py&quot;)
240	    if os.path.isfile(init_file):
241	        with open(init_file, &quot;r&quot;) as f:
242	            tree = ast.parse(f.read())
243	            for node in ast.walk(tree):
244	                if isinstance(node, ast.Assign):
245	                    for target in node.targets:
246	                        if (
247	                            isinstance(target, ast.Name)
248	                            and target.id == &quot;__version__&quot;
249	                            and isinstance(node.value, ast.Str)
250	                        ):
251	                            return node.value.s
252	    return None
253	
254	
255	def download_file(url, file_name):
256	    with requests.get(url, stream=True) as response:
257	        response.raise_for_status()
258	        total_size = int(response.headers.get(&quot;content-length&quot;, 0))
259	        with open(file_name, &quot;wb&quot;) as file, tqdm(
260	            desc=file_name.stem,
261	            total=total_size,
262	            unit=&quot;B&quot;,
263	            unit_scale=True,
264	            unit_divisor=1024,
265	        ) as progress_bar:
266	            for chunk in response.iter_content(chunk_size=8192):
267	                file.write(chunk)
268	                progress_bar.update(len(chunk))
269	
270	
271	def try_import(requirement):
272	    dependency = requirement.name.strip()
273	    import_name = pip_map.get(dependency, dependency)
274	    installed = False
275	
276	    pip_name = dependency
277	    pip_spec = &quot;&quot;.join(specs[0]) if (specs := requirement.specs) else &quot;&quot;
278	    try:
279	        with suppress_std():
280	            import_module(import_name)
281	        print_formatted(
282	            f&quot;\t✅ Package {pip_name} already installed (import name: &#x27;{import_name}&#x27;).&quot;,
283	            &quot;bold&quot;,
284	            color=&quot;green&quot;,
285	            no_header=True,
286	        )
287	        installed = True
288	    except ImportError:
289	        print_formatted(
290	            f&quot;\t⛔ Package {pip_name} is missing (import name: &#x27;{import_name}&#x27;).&quot;,
291	            &quot;bold&quot;,
292	            color=&quot;red&quot;,
293	            no_header=True,
294	        )
295	
296	    return (installed, pip_name, pip_spec, import_name)
297	
298	
299	def import_or_install(requirement, dry=False):
300	    installed, pip_name, pip_spec, import_name = try_import(requirement)
301	
302	    pip_install_name = pip_name + pip_spec
303	
304	    if not installed:
305	        print_formatted(f&quot;Installing package {pip_name}...&quot;, &quot;italic&quot;, color=&quot;yellow&quot;)
306	        if dry:
307	            print_formatted(
308	                f&quot;Dry-run: Package {pip_install_name} would be installed (import name: &#x27;{import_name}&#x27;).&quot;,
309	                color=&quot;yellow&quot;,
310	            )
311	        else:
312	            try:
313	                run_command([executable, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, pip_install_name])
314	                print_formatted(
315	                    f&quot;Package {pip_install_name} installed successfully using pip package name  (import name: &#x27;{import_name}&#x27;)&quot;,
</pre>
</div>


</div>
</div>

<div id="issue-22">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/install.py</a><br>
    <b>Line number: </b>336<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
276	    pip_name = dependency
277	    pip_spec = &quot;&quot;.join(specs[0]) if (specs := requirement.specs) else &quot;&quot;
278	    try:
279	        with suppress_std():
280	            import_module(import_name)
281	        print_formatted(
282	            f&quot;\t✅ Package {pip_name} already installed (import name: &#x27;{import_name}&#x27;).&quot;,
283	            &quot;bold&quot;,
284	            color=&quot;green&quot;,
285	            no_header=True,
286	        )
287	        installed = True
288	    except ImportError:
289	        print_formatted(
290	            f&quot;\t⛔ Package {pip_name} is missing (import name: &#x27;{import_name}&#x27;).&quot;,
291	            &quot;bold&quot;,
292	            color=&quot;red&quot;,
293	            no_header=True,
294	        )
295	
296	    return (installed, pip_name, pip_spec, import_name)
297	
298	
299	def import_or_install(requirement, dry=False):
300	    installed, pip_name, pip_spec, import_name = try_import(requirement)
301	
302	    pip_install_name = pip_name + pip_spec
303	
304	    if not installed:
305	        print_formatted(f&quot;Installing package {pip_name}...&quot;, &quot;italic&quot;, color=&quot;yellow&quot;)
306	        if dry:
307	            print_formatted(
308	                f&quot;Dry-run: Package {pip_install_name} would be installed (import name: &#x27;{import_name}&#x27;).&quot;,
309	                color=&quot;yellow&quot;,
310	            )
311	        else:
312	            try:
313	                run_command([executable, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, pip_install_name])
314	                print_formatted(
315	                    f&quot;Package {pip_install_name} installed successfully using pip package name  (import name: &#x27;{import_name}&#x27;)&quot;,
316	                    &quot;bold&quot;,
317	                    color=&quot;green&quot;,
318	                )
319	            except subprocess.CalledProcessError as e:
320	                print_formatted(
321	                    f&quot;Failed to install package {pip_install_name} using pip package name  (import name: &#x27;{import_name}&#x27;). Error: {str(e)}&quot;,
322	                    &quot;bold&quot;,
323	                    color=&quot;red&quot;,
324	                )
325	
326	
327	def get_github_assets(tag=None):
328	    if tag:
329	        tag_url = (
330	            f&quot;https://api.github.com/repos/{repo_owner}/{repo_name}/releases/tags/{tag}&quot;
331	        )
332	    else:
333	        tag_url = (
334	            f&quot;https://api.github.com/repos/{repo_owner}/{repo_name}/releases/latest&quot;
335	        )
336	    response = requests.get(tag_url)
337	    if response.status_code == 404:
338	        # print_formatted(
339	        #     f&quot;Tag version &#x27;{apply_color(version,&#x27;cyan&#x27;)}&#x27; not found for {owner}/{repo} repository.&quot;
340	        # )
341	        print_formatted(&quot;Error retrieving the release assets.&quot;, color=&quot;red&quot;)
342	        sys.exit()
343	
344	    tag_data = response.json()
345	    tag_name = tag_data[&quot;name&quot;]
346	
347	    return tag_data, tag_name
348	
349	
350	# endregion
351	
352	
353	try:
354	    from tqdm import tqdm
355	except ImportError:
356	    print_formatted(&quot;Installing tqdm...&quot;, &quot;italic&quot;, color=&quot;yellow&quot;)
357	    run_command([executable, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, &quot;--upgrade&quot;, &quot;tqdm&quot;])
358	    from tqdm import tqdm
359	
360	
361	def main():
362	    if len(sys.argv) == 1:
363	        print_formatted(
364	            &quot;mtb doesn&#x27;t need an install script anymore.&quot;, &quot;italic&quot;, color=&quot;yellow&quot;
365	        )
366	        return
367	    if all(arg not in (&quot;-p&quot;, &quot;--path&quot;) for arg in sys.argv):
368	        print(
369	            &quot;This script is only used for and edge case of remote installs on some cloud providers, unrecognized arguments:&quot;,
370	            sys.argv[1:],
371	        )
372	        return
373	
374	    # Parse command-line arguments
375	    parser = argparse.ArgumentParser(description=&quot;Comfy_mtb install script&quot;)
376	    parser.add_argument(
377	        &quot;--path&quot;,
378	        &quot;-p&quot;,
379	        type=str,
380	        help=&quot;Path to clone the repository to (i.e the absolute path to ComfyUI/custom_nodes)&quot;,
381	    )
382	
383	    print_formatted(&quot;mtb install&quot;, &quot;bold&quot;, color=&quot;yellow&quot;)
384	
385	    args = parser.parse_args()
386	
387	    print_formatted(f&quot;Detected environment: {apply_color(mode,&#x27;cyan&#x27;)}&quot;)
388	
389	    if args.path:
390	        clone_dir = Path(args.path)
391	        if not clone_dir.exists():
392	            print_formatted(
393	                &quot;The path provided does not exist on disk... It must be pointing to ComfyUI&#x27;s custom_nodes directory&quot;
394	            )
395	            sys.exit()
</pre>
</div>


</div>
</div>

<div id="issue-23">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/generate.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/generate.py</a><br>
    <b>Line number: </b>101<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
41	#         else:
42	#             mask = torch.zeros((64, 64), dtype=torch.float32, device=&quot;cpu&quot;)
43	#         return (image, mask)
44	
45	#     @classmethod
46	#     def IS_CHANGED(cls, image):
47	#         image_path = (cls.get_root() / image).as_posix()
48	
49	#         m = hashlib.sha256()
50	#         with open(image_path, &quot;rb&quot;) as f:
51	#             m.update(f.read())
52	#         return m.digest().hex()
53	
54	
55	class MTB_UnsplashImage:
56	    &quot;&quot;&quot;Unsplash Image given a keyword and a size&quot;&quot;&quot;
57	
58	    @classmethod
59	    def INPUT_TYPES(cls):
60	        return {
61	            &quot;required&quot;: {
62	                &quot;width&quot;: (
63	                    &quot;INT&quot;,
64	                    {&quot;default&quot;: 512, &quot;max&quot;: 8096, &quot;min&quot;: 0, &quot;step&quot;: 1},
65	                ),
66	                &quot;height&quot;: (
67	                    &quot;INT&quot;,
68	                    {&quot;default&quot;: 512, &quot;max&quot;: 8096, &quot;min&quot;: 0, &quot;step&quot;: 1},
69	                ),
70	                &quot;random_seed&quot;: (
71	                    &quot;INT&quot;,
72	                    {&quot;default&quot;: 0, &quot;max&quot;: 1e5, &quot;min&quot;: 0, &quot;step&quot;: 1},
73	                ),
74	            },
75	            &quot;optional&quot;: {
76	                &quot;keyword&quot;: (&quot;STRING&quot;, {&quot;default&quot;: &quot;nature&quot;}),
77	            },
78	        }
79	
80	    RETURN_TYPES = (&quot;IMAGE&quot;,)
81	    FUNCTION = &quot;do_unsplash_image&quot;
82	    CATEGORY = &quot;mtb/generate&quot;
83	
84	    def do_unsplash_image(self, width, height, random_seed, keyword=None):
85	        import io
86	
87	        import requests
88	
89	        base_url = &quot;https://source.unsplash.com/random/&quot;
90	
91	        if width and height:
92	            base_url += f&quot;/{width}x{height}&quot;
93	
94	        if keyword:
95	            keyword = keyword.replace(&quot; &quot;, &quot;%20&quot;)
96	            base_url += f&quot;?{keyword}&amp;{random_seed}&quot;
97	        else:
98	            base_url += f&quot;?&amp;{random_seed}&quot;
99	        try:
100	            log.debug(f&quot;Getting unsplash image from {base_url}&quot;)
101	            response = requests.get(base_url)
102	            response.raise_for_status()
103	
104	            image = Image.open(io.BytesIO(response.content))
105	            return (
106	                pil2tensor(
107	                    image,
108	                ),
109	            )
110	
111	        except requests.exceptions.RequestException as e:
112	            print(&quot;Error retrieving image:&quot;, e)
113	            return (None,)
114	
115	
116	class MTB_QrCode:
117	    &quot;&quot;&quot;Basic QR Code generator&quot;&quot;&quot;
118	
119	    @classmethod
120	    def INPUT_TYPES(cls):
121	        return {
122	            &quot;required&quot;: {
123	                &quot;url&quot;: (&quot;STRING&quot;, {&quot;default&quot;: &quot;https://www.github.com&quot;}),
124	                &quot;width&quot;: (
125	                    &quot;INT&quot;,
126	                    {&quot;default&quot;: 256, &quot;max&quot;: 8096, &quot;min&quot;: 0, &quot;step&quot;: 1},
127	                ),
128	                &quot;height&quot;: (
129	                    &quot;INT&quot;,
130	                    {&quot;default&quot;: 256, &quot;max&quot;: 8096, &quot;min&quot;: 0, &quot;step&quot;: 1},
131	                ),
132	                &quot;error_correct&quot;: ((&quot;L&quot;, &quot;M&quot;, &quot;Q&quot;, &quot;H&quot;), {&quot;default&quot;: &quot;L&quot;}),
133	                &quot;box_size&quot;: (
134	                    &quot;INT&quot;,
135	                    {&quot;default&quot;: 10, &quot;max&quot;: 8096, &quot;min&quot;: 0, &quot;step&quot;: 1},
136	                ),
137	                &quot;border&quot;: (
138	                    &quot;INT&quot;,
139	                    {&quot;default&quot;: 4, &quot;max&quot;: 8096, &quot;min&quot;: 0, &quot;step&quot;: 1},
140	                ),
141	                &quot;invert&quot;: ((&quot;BOOLEAN&quot;,), {&quot;default&quot;: False}),
142	            }
143	        }
144	
145	    RETURN_TYPES = (&quot;IMAGE&quot;,)
146	    FUNCTION = &quot;do_qr&quot;
147	    CATEGORY = &quot;mtb/generate&quot;
148	
149	    def do_qr(
150	        self, url, width, height, error_correct, box_size, border, invert
151	    ):
152	        log.warning(
153	            &quot;This node will soon be deprecated, there are much better alternatives like https://github.com/coreyryanhanson/comfy-qr&quot;
154	        )
155	        if error_correct == &quot;L&quot; or error_correct not in [&quot;M&quot;, &quot;Q&quot;, &quot;H&quot;]:
156	            error_correct = qrcode.constants.ERROR_CORRECT_L
157	        elif error_correct == &quot;M&quot;:
158	            error_correct = qrcode.constants.ERROR_CORRECT_M
159	        elif error_correct == &quot;Q&quot;:
160	            error_correct = qrcode.constants.ERROR_CORRECT_Q
</pre>
</div>


</div>
</div>

<div id="issue-24">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Audit url open for permitted schemes. Allowing use of file:/ or custom schemes is often unexpected.<br>
    <b>Test ID:</b> B310<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/graph_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/graph_utils.py</a><br>
    <b>Line number: </b>36<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen</a><br>

<div class="code">
<pre>
1	import io
2	import json
3	import urllib.parse
4	import urllib.request
5	from math import pi
6	from typing import Optional
7	
8	import comfy.model_management as model_management
9	import comfy.utils
10	import numpy as np
11	import torch
12	import torchvision.transforms.functional as F
13	from PIL import Image
14	
15	from ..log import log
16	from ..utils import (
17	    EASINGS,
18	    apply_easing,
19	    get_server_info,
20	    numpy_NFOV,
21	    pil2tensor,
22	    tensor2np,
23	)
24	
25	
26	def get_image(filename, subfolder, folder_type):
27	    log.debug(
28	        f&quot;Getting image {filename} from foldertype {folder_type} {f&#x27;in subfolder: {subfolder}&#x27; if subfolder else &#x27;&#x27;}&quot;
29	    )
30	    data = {&quot;filename&quot;: filename, &quot;subfolder&quot;: subfolder, &quot;type&quot;: folder_type}
31	    base_url, port = get_server_info()
32	
33	    url_values = urllib.parse.urlencode(data)
34	    url = f&quot;http://{base_url}:{port}/view?{url_values}&quot;
35	    log.debug(f&quot;Fetching image from {url}&quot;)
36	    with urllib.request.urlopen(url) as response:
37	        return io.BytesIO(response.read())
38	
39	
40	class MTB_ToDevice:
41	    &quot;&quot;&quot;Send a image or mask tensor to the given device.&quot;&quot;&quot;
42	
43	    @classmethod
44	    def INPUT_TYPES(cls):
45	        devices = [&quot;cpu&quot;]
46	        if torch.backends.mps.is_available():
47	            devices.append(&quot;mps&quot;)
48	        if torch.cuda.is_available():
49	            devices.append(&quot;cuda&quot;)
50	            for i in range(torch.cuda.device_count()):
51	                devices.append(f&quot;cuda{i}&quot;)
52	
53	        return {
54	            &quot;required&quot;: {
55	                &quot;ignore_errors&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
56	                &quot;device&quot;: (devices, {&quot;default&quot;: &quot;cpu&quot;}),
57	            },
58	            &quot;optional&quot;: {
59	                &quot;image&quot;: (&quot;IMAGE&quot;,),
60	                &quot;mask&quot;: (&quot;MASK&quot;,),
61	            },
62	        }
63	
64	    RETURN_TYPES = (&quot;IMAGE&quot;, &quot;MASK&quot;)
65	    RETURN_NAMES = (&quot;images&quot;, &quot;masks&quot;)
66	    CATEGORY = &quot;mtb/utils&quot;
67	    FUNCTION = &quot;to_device&quot;
68	
69	    def to_device(
70	        self,
71	        *,
72	        ignore_errors=False,
73	        device=&quot;cuda&quot;,
74	        image: Optional[torch.Tensor] = None,
75	        mask: Optional[torch.Tensor] = None,
76	    ):
77	        if not ignore_errors and image is None and mask is None:
78	            raise ValueError(
79	                &quot;You must either provide an image or a mask,&quot;
80	                &quot; use ignore_error to passthrough&quot;
81	            )
82	        if image is not None:
83	            image = image.to(device)
84	        if mask is not None:
85	            mask = mask.to(device)
86	        return (image, mask)
87	
88	
89	# class MTB_ApplyTextTemplate:
90	class MTB_ApplyTextTemplate:
91	    &quot;&quot;&quot;
92	    Experimental node to interpolate strings from inputs.
93	
94	    Interpolation just requires {}, for instance:
95	
96	    Some string {var_1} and {var_2}
97	    &quot;&quot;&quot;
98	
99	    @classmethod
100	    def INPUT_TYPES(cls):
101	        return {
102	            &quot;required&quot;: {
103	                &quot;template&quot;: (&quot;STRING&quot;, {&quot;default&quot;: &quot;&quot;, &quot;multiline&quot;: True}),
104	            },
105	        }
106	
107	    RETURN_TYPES = (&quot;STRING&quot;,)
108	    RETURN_NAMES = (&quot;string&quot;,)
109	    CATEGORY = &quot;mtb/utils&quot;
110	    FUNCTION = &quot;execute&quot;
111	
112	    def execute(self, *, template: str, **kwargs):
113	        res = f&quot;{template}&quot;
114	        for k, v in kwargs.items():
115	            res = res.replace(f&quot;{{{k}}}&quot;, f&quot;{v}&quot;)
116	
117	        return (res,)
118	
119	
120	class MTB_MatchDimensions:
</pre>
</div>


</div>
</div>

<div id="issue-25">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Audit url open for permitted schemes. Allowing use of file:/ or custom schemes is often unexpected.<br>
    <b>Test ID:</b> B310<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/graph_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/graph_utils.py</a><br>
    <b>Line number: </b>372<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen</a><br>

<div class="code">
<pre>
312	            center_point = [rotation_angle / (2 * pi), elevation]
313	
314	            nfov = numpy_NFOV(fov, height, width)
315	            frame = nfov.to_nfov(source, center_point=center_point)
316	
317	            frames.append(frame)
318	
319	            model_management.throw_exception_if_processing_interrupted()
320	            pbar.update(1)
321	
322	        return (pil2tensor(frames),)
323	
324	
325	class MTB_GetBatchFromHistory:
326	    &quot;&quot;&quot;Very experimental node to load images from the history of the server.
327	
328	    Queue items without output are ignored in the count.
329	    &quot;&quot;&quot;
330	
331	    @classmethod
332	    def INPUT_TYPES(cls):
333	        return {
334	            &quot;required&quot;: {
335	                &quot;enable&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: True}),
336	                &quot;count&quot;: (&quot;INT&quot;, {&quot;default&quot;: 1, &quot;min&quot;: 0}),
337	                &quot;offset&quot;: (&quot;INT&quot;, {&quot;default&quot;: 0, &quot;min&quot;: -1e9, &quot;max&quot;: 1e9}),
338	                &quot;internal_count&quot;: (&quot;INT&quot;, {&quot;default&quot;: 0}),
339	            },
340	            &quot;optional&quot;: {
341	                &quot;passthrough_image&quot;: (&quot;IMAGE&quot;,),
342	            },
343	        }
344	
345	    RETURN_TYPES = (&quot;IMAGE&quot;,)
346	    RETURN_NAMES = (&quot;images&quot;,)
347	    CATEGORY = &quot;mtb/animation&quot;
348	    FUNCTION = &quot;load_from_history&quot;
349	
350	    def load_from_history(
351	        self,
352	        *,
353	        enable=True,
354	        count=0,
355	        offset=0,
356	        internal_count=0,  # hacky way to invalidate the node
357	        passthrough_image=None,
358	    ):
359	        if not enable or count == 0:
360	            if passthrough_image is not None:
361	                log.debug(&quot;Using passthrough image&quot;)
362	                return (passthrough_image,)
363	            log.debug(&quot;Load from history is disabled for this iteration&quot;)
364	            return (torch.zeros(0),)
365	        frames = []
366	
367	        base_url, port = get_server_info()
368	
369	        history_url = f&quot;http://{base_url}:{port}/history&quot;
370	        log.debug(f&quot;Fetching history from {history_url}&quot;)
371	        output = torch.zeros(0)
372	        with urllib.request.urlopen(history_url) as response:
373	            output = self.load_batch_frames(response, offset, count, frames)
374	
375	        if output.size(0) == 0:
376	            log.warn(&quot;No output found in history&quot;)
377	
378	        return (output,)
379	
380	    def load_batch_frames(self, response, offset, count, frames):
381	        history = json.loads(response.read())
382	
383	        output_images = []
384	
385	        for run in history.values():
386	            for node_output in run[&quot;outputs&quot;].values():
387	                if &quot;images&quot; in node_output:
388	                    for image in node_output[&quot;images&quot;]:
389	                        image_data = get_image(
390	                            image[&quot;filename&quot;],
391	                            image[&quot;subfolder&quot;],
392	                            image[&quot;type&quot;],
393	                        )
394	                        output_images.append(image_data)
395	
396	        if not output_images:
397	            return torch.zeros(0)
398	
399	        # Directly get desired range of images
400	        start_index = max(len(output_images) - offset - count, 0)
401	        end_index = len(output_images) - offset
402	        selected_images = output_images[start_index:end_index]
403	
404	        frames = [Image.open(image) for image in selected_images]
405	
406	        if not frames:
407	            return torch.zeros(0)
408	        elif len(frames) != count:
409	            log.warning(f&quot;Expected {count} images, got {len(frames)} instead&quot;)
410	
411	        return pil2tensor(frames)
412	
413	
414	class MTB_AnyToString:
415	    &quot;&quot;&quot;Tries to take any input and convert it to a string.&quot;&quot;&quot;
416	
417	    @classmethod
418	    def INPUT_TYPES(cls):
419	        return {
420	            &quot;required&quot;: {&quot;input&quot;: (&quot;*&quot;)},
421	        }
422	
423	    RETURN_TYPES = (&quot;STRING&quot;,)
424	    FUNCTION = &quot;do_str&quot;
425	    CATEGORY = &quot;mtb/converters&quot;
426	
427	    def do_str(self, input):
428	        if isinstance(input, str):
429	            return (input,)
430	        elif isinstance(input, torch.Tensor):
431	            return (f&quot;Tensor of shape {input.shape} and dtype {input.dtype}&quot;,)
</pre>
</div>


</div>
</div>

<div id="issue-26">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Use of possibly insecure function - consider using safer ast.literal_eval.<br>
    <b>Test ID:</b> B307<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/graph_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/graph_utils.py</a><br>
    <b>Line number: </b>515<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval</a><br>

<div class="code">
<pre>
455	            &quot;required&quot;: {
456	                &quot;string&quot;: (&quot;STRING&quot;, {&quot;forceInput&quot;: True}),
457	                &quot;old&quot;: (&quot;STRING&quot;, {&quot;default&quot;: &quot;&quot;}),
458	                &quot;new&quot;: (&quot;STRING&quot;, {&quot;default&quot;: &quot;&quot;}),
459	            }
460	        }
461	
462	    FUNCTION = &quot;replace_str&quot;
463	    RETURN_TYPES = (&quot;STRING&quot;,)
464	    CATEGORY = &quot;mtb/string&quot;
465	
466	    def replace_str(self, string: str, old: str, new: str):
467	        log.debug(f&quot;Current string: {string}&quot;)
468	        log.debug(f&quot;Find string: {old}&quot;)
469	        log.debug(f&quot;Replace string: {new}&quot;)
470	
471	        string = string.replace(old, new)
472	
473	        log.debug(f&quot;New string: {string}&quot;)
474	
475	        return (string,)
476	
477	
478	class MTB_MathExpression:
479	    &quot;&quot;&quot;Node to evaluate a simple math expression string&quot;&quot;&quot;
480	
481	    @classmethod
482	    def INPUT_TYPES(cls):
483	        return {
484	            &quot;required&quot;: {
485	                &quot;expression&quot;: (&quot;STRING&quot;, {&quot;default&quot;: &quot;&quot;, &quot;multiline&quot;: True}),
486	            }
487	        }
488	
489	    FUNCTION = &quot;eval_expression&quot;
490	    RETURN_TYPES = (&quot;FLOAT&quot;, &quot;INT&quot;)
491	    RETURN_NAMES = (&quot;result (float)&quot;, &quot;result (int)&quot;)
492	    CATEGORY = &quot;mtb/math&quot;
493	    DESCRIPTION = (
494	        &quot;evaluate a simple math expression string (!! Fallsback to eval)&quot;
495	    )
496	
497	    def eval_expression(self, expression, **kwargs):
498	        from ast import literal_eval
499	
500	        for key, value in kwargs.items():
501	            print(f&quot;Replacing placeholder &lt;{key}&gt; with value {value}&quot;)
502	            expression = expression.replace(f&quot;&lt;{key}&gt;&quot;, str(value))
503	
504	        result = -1
505	        try:
506	            result = literal_eval(expression)
507	        except SyntaxError as e:
508	            raise ValueError(
509	                f&quot;The expression syntax is wrong &#x27;{expression}&#x27;: {e}&quot;
510	            ) from e
511	
512	        except ValueError:
513	            try:
514	                expression = expression.replace(&quot;^&quot;, &quot;**&quot;)
515	                result = eval(expression)
516	            except Exception as e:
517	                # Handle any other exceptions and provide a meaningful error message
518	                raise ValueError(
519	                    f&quot;Error evaluating expression &#x27;{expression}&#x27;: {e}&quot;
520	                ) from e
521	
522	        return (result, int(result))
523	
524	
525	class MTB_FitNumber:
526	    &quot;&quot;&quot;Fit the input float using a source and target range&quot;&quot;&quot;
527	
528	    @classmethod
529	    def INPUT_TYPES(cls):
530	        return {
531	            &quot;required&quot;: {
532	                &quot;value&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 0, &quot;forceInput&quot;: True}),
533	                &quot;clamp&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
534	                &quot;source_min&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 0.0, &quot;step&quot;: 0.01}),
535	                &quot;source_max&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 1.0, &quot;step&quot;: 0.01}),
536	                &quot;target_min&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 0.0, &quot;step&quot;: 0.01}),
537	                &quot;target_max&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 1.0, &quot;step&quot;: 0.01}),
538	                &quot;easing&quot;: (
539	                    EASINGS,
540	                    {&quot;default&quot;: &quot;Linear&quot;},
541	                ),
542	            }
543	        }
544	
545	    FUNCTION = &quot;set_range&quot;
546	    RETURN_TYPES = (&quot;FLOAT&quot;,)
547	    CATEGORY = &quot;mtb/math&quot;
548	    DESCRIPTION = &quot;Fit the input float using a source and target range&quot;
549	
550	    def set_range(
551	        self,
552	        value: float,
553	        clamp: bool,
554	        source_min: float,
555	        source_max: float,
556	        target_min: float,
557	        target_max: float,
558	        easing: str,
559	    ):
560	        if source_min == source_max:
561	            normalized_value = 0
562	        else:
563	            normalized_value = (value - source_min) / (source_max - source_min)
564	        if clamp:
565	            normalized_value = max(min(normalized_value, 1), 0)
566	
567	        eased_value = apply_easing(normalized_value, easing)
568	
569	        # - Convert the eased value to the target range
570	        res = target_min + (target_max - target_min) * eased_value
571	
572	        return (res,)
573	
574	
</pre>
</div>


</div>
</div>

<div id="issue-27">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/image_processing.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/image_processing.py</a><br>
    <b>Line number: </b>295<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
235	        if num_channels_A == 3 and num_channels_B == 4:
236	            imageA = torch.cat(
237	                (imageA, torch.ones_like(imageA[:, :, 0:1])), dim=2
238	            )
239	        elif num_channels_B == 3 and num_channels_A == 4:
240	            imageB = torch.cat(
241	                (imageB, torch.ones_like(imageB[:, :, 0:1])), dim=2
242	            )
243	        match mode:
244	            case &quot;diff&quot;:
245	                compare_image = torch.abs(imageA - imageB)
246	            case &quot;blend&quot;:
247	                compare_image = 0.5 * (imageA + imageB)
248	            case &quot;checkerboard&quot;:
249	                imageA = imageA.numpy()
250	                imageB = imageB.numpy()
251	                compared_channels = [
252	                    torch.from_numpy(
253	                        compare_images(
254	                            imageA[:, :, i], imageB[:, :, i], method=mode
255	                        )
256	                    )
257	                    for i in range(imageA.shape[2])
258	                ]
259	
260	                compare_image = torch.stack(compared_channels, dim=2)
261	            case _:
262	                compare_image = None
263	                raise ValueError(f&quot;Unknown mode {mode}&quot;)
264	
265	        compare_image = compare_image.unsqueeze(0)
266	
267	        return (compare_image,)
268	
269	
270	import requests
271	
272	
273	class MTB_LoadImageFromUrl:
274	    &quot;&quot;&quot;Load an image from the given URL&quot;&quot;&quot;
275	
276	    @classmethod
277	    def INPUT_TYPES(cls):
278	        return {
279	            &quot;required&quot;: {
280	                &quot;url&quot;: (
281	                    &quot;STRING&quot;,
282	                    {
283	                        &quot;default&quot;: &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Example.jpg/800px-Example.jpg&quot;
284	                    },
285	                ),
286	            }
287	        }
288	
289	    RETURN_TYPES = (&quot;IMAGE&quot;,)
290	    FUNCTION = &quot;load&quot;
291	    CATEGORY = &quot;mtb/IO&quot;
292	
293	    def load(self, url):
294	        # get the image from the url
295	        image = Image.open(requests.get(url, stream=True).raw)
296	        image = ImageOps.exif_transpose(image)
297	        return (pil2tensor(image),)
298	
299	
300	class MTB_Blur:
301	    &quot;&quot;&quot;Blur an image using a Gaussian filter.&quot;&quot;&quot;
302	
303	    @classmethod
304	    def INPUT_TYPES(cls):
305	        return {
306	            &quot;required&quot;: {
307	                &quot;image&quot;: (&quot;IMAGE&quot;,),
308	                &quot;sigmaX&quot;: (
309	                    &quot;FLOAT&quot;,
310	                    {&quot;default&quot;: 3.0, &quot;min&quot;: 0.0, &quot;max&quot;: 200.0, &quot;step&quot;: 0.01},
311	                ),
312	                &quot;sigmaY&quot;: (
313	                    &quot;FLOAT&quot;,
314	                    {&quot;default&quot;: 3.0, &quot;min&quot;: 0.0, &quot;max&quot;: 200.0, &quot;step&quot;: 0.01},
315	                ),
316	            },
317	            &quot;optional&quot;: {&quot;sigmasX&quot;: (&quot;FLOATS&quot;,), &quot;sigmasY&quot;: (&quot;FLOATS&quot;,)},
318	        }
319	
320	    RETURN_TYPES = (&quot;IMAGE&quot;,)
321	    FUNCTION = &quot;blur&quot;
322	    CATEGORY = &quot;mtb/image processing&quot;
323	
324	    def blur(
325	        self, image: torch.Tensor, sigmaX, sigmaY, sigmasX=None, sigmasY=None
326	    ):
327	        image_np = image.numpy() * 255
328	
329	        blurred_images = []
330	        if sigmasX is not None:
331	            if sigmasY is None:
332	                sigmasY = sigmasX
333	            if len(sigmasX) != image.size(0):
334	                raise ValueError(
335	                    f&quot;SigmasX must have same length as image, sigmasX is {len(sigmasX)} but the batch size is {image.size(0)}&quot;
336	                )
337	
338	            for i in range(image.size(0)):
339	                blurred = gaussian(
340	                    image_np[i],
341	                    sigma=(sigmasX[i], sigmasY[i], 0),
342	                    channel_axis=2,
343	                )
344	                blurred_images.append(blurred)
345	
346	            image_np = np.array(blurred_images)
347	        else:
348	            for i in range(image.size(0)):
349	                blurred = gaussian(
350	                    image_np[i], sigma=(sigmaX, sigmaY, 0), channel_axis=2
351	                )
352	                blurred_images.append(blurred)
353	
354	            image_np = np.array(blurred_images)
</pre>
</div>


</div>
</div>

<div id="issue-28">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py</a><br>
    <b>Line number: </b>2<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import json
2	import subprocess
3	import uuid
4	from pathlib import Path
5	from typing import List, Optional
6	
7	import comfy.model_management as model_management
8	import folder_paths
9	import numpy as np
10	import torch
11	from PIL import Image
12	
13	from ..log import log
14	from ..utils import PIL_FILTER_MAP, output_dir, session_id, tensor2np
15	
16	
17	def get_playlist_path(playlist_name: str, persistant_playlist=False):
18	    if persistant_playlist:
19	        return output_dir / &quot;playlists&quot; / f&quot;{playlist_name}.json&quot;
20	
21	    return output_dir / &quot;playlists&quot; / session_id / f&quot;{playlist_name}.json&quot;
22	
23	
24	class MTB_ReadPlaylist:
25	    &quot;&quot;&quot;Read a playlist&quot;&quot;&quot;
26	
27	    @classmethod
28	    def INPUT_TYPES(cls):
29	        return {
30	            &quot;required&quot;: {
31	                &quot;enable&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: True}),
32	                &quot;persistant_playlist&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
33	                &quot;playlist_name&quot;: (
34	                    &quot;STRING&quot;,
35	                    {&quot;default&quot;: &quot;playlist_{index:04d}&quot;},
36	                ),
37	                &quot;index&quot;: (&quot;INT&quot;, {&quot;default&quot;: 0, &quot;min&quot;: 0}),
38	            }
39	        }
40	
41	    RETURN_TYPES = (&quot;PLAYLIST&quot;,)
42	    FUNCTION = &quot;read_playlist&quot;
43	    CATEGORY = &quot;mtb/IO&quot;
44	
45	    def read_playlist(
46	        self,
47	        enable: bool,
48	        persistant_playlist: bool,
49	        playlist_name: str,
50	        index: int,
51	    ):
52	        playlist_name = playlist_name.format(index=index)
53	        playlist_path = get_playlist_path(playlist_name, persistant_playlist)
54	        if not enable:
55	            return (None,)
56	
57	        if not playlist_path.exists():
58	            log.warning(f&quot;Playlist {playlist_path} does not exist, skipping&quot;)
59	            return (None,)
60	
61	        log.debug(f&quot;Reading playlist {playlist_path}&quot;)
62	        return (json.loads(playlist_path.read_text(encoding=&quot;utf-8&quot;)),)
63	
64	
65	class MTB_AddToPlaylist:
66	    &quot;&quot;&quot;Add a video to the playlist&quot;&quot;&quot;
67	
68	    @classmethod
69	    def INPUT_TYPES(cls):
70	        return {
71	            &quot;required&quot;: {
72	                &quot;relative_paths&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
73	                &quot;persistant_playlist&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
74	                &quot;playlist_name&quot;: (
75	                    &quot;STRING&quot;,
76	                    {&quot;default&quot;: &quot;playlist_{index:04d}&quot;},
77	                ),
78	                &quot;index&quot;: (&quot;INT&quot;, {&quot;default&quot;: 0, &quot;min&quot;: 0}),
79	            }
80	        }
81	
82	    RETURN_TYPES = ()
83	    OUTPUT_NODE = True
84	    FUNCTION = &quot;add_to_playlist&quot;
85	    CATEGORY = &quot;mtb/IO&quot;
86	
87	    def add_to_playlist(
88	        self,
89	        relative_paths: bool,
90	        persistant_playlist: bool,
91	        playlist_name: str,
92	        index: int,
93	        **kwargs,
94	    ):
95	        playlist_name = playlist_name.format(index=index)
96	        playlist_path = get_playlist_path(playlist_name, persistant_playlist)
97	
98	        if not playlist_path.parent.exists():
99	            playlist_path.parent.mkdir(parents=True, exist_ok=True)
100	
101	        playlist = []
102	        if not playlist_path.exists():
103	            playlist_path.write_text(&quot;[]&quot;)
104	        else:
105	            playlist = json.loads(playlist_path.read_text())
106	        log.debug(f&quot;Playlist {playlist_path} has {len(playlist)} items&quot;)
107	        for video in kwargs.values():
108	            if relative_paths:
109	                video = Path(video).relative_to(output_dir).as_posix()
110	
111	            log.debug(f&quot;Adding {video} to playlist&quot;)
112	            playlist.append(video)
113	
114	        log.debug(f&quot;Writing playlist {playlist_path}&quot;)
115	        playlist_path.write_text(json.dumps(playlist), encoding=&quot;utf-8&quot;)
116	        return ()
117	
118	
119	class MTB_ExportWithFfmpeg:
120	    &quot;&quot;&quot;Export with FFmpeg (Experimental)&quot;&quot;&quot;
</pre>
</div>


</div>
</div>

<div id="issue-29">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py</a><br>
    <b>Line number: </b>197<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
137	                    [&quot;prores_ks&quot;, &quot;libx264&quot;, &quot;libx265&quot;, &quot;gif&quot;],
138	                    {&quot;default&quot;: &quot;prores_ks&quot;},
139	                ),
140	            },
141	        }
142	
143	    RETURN_TYPES = (&quot;VIDEO&quot;,)
144	    OUTPUT_NODE = True
145	    FUNCTION = &quot;export_prores&quot;
146	    CATEGORY = &quot;mtb/IO&quot;
147	
148	    def export_prores(
149	        self,
150	        fps: float,
151	        prefix: str,
152	        format: str,
153	        codec: str,
154	        images: Optional[torch.Tensor] = None,
155	        playlist: Optional[List[str]] = None,
156	    ):
157	        pix_fmt = &quot;rgb48le&quot; if codec == &quot;prores_ks&quot; else &quot;yuv420p&quot;
158	        file_ext = format
159	        file_id = f&quot;{prefix}_{uuid.uuid4()}.{file_ext}&quot;
160	
161	        if playlist is not None and images is not None:
162	            log.info(f&quot;Exporting to {output_dir / file_id}&quot;)
163	
164	        if playlist is not None:
165	            if len(playlist) == 0:
166	                log.debug(&quot;Playlist is empty, skipping&quot;)
167	                return (&quot;&quot;,)
168	
169	            temp_playlist_path = (
170	                output_dir / f&quot;temp_playlist_{uuid.uuid4()}.txt&quot;
171	            )
172	            log.debug(
173	                f&quot;Create a temporary file to list the videos for concatenation to {temp_playlist_path}&quot;
174	            )
175	
176	            with open(temp_playlist_path, &quot;w&quot;) as f:
177	                for video_path in playlist:
178	                    f.write(f&quot;file &#x27;{video_path}&#x27;\n&quot;)
179	
180	            out_path = (output_dir / file_id).as_posix()
181	
182	            # Prepare the FFmpeg command for concatenating videos from the playlist
183	            command = [
184	                &quot;ffmpeg&quot;,
185	                &quot;-f&quot;,
186	                &quot;concat&quot;,
187	                &quot;-safe&quot;,
188	                &quot;0&quot;,
189	                &quot;-i&quot;,
190	                temp_playlist_path.as_posix(),
191	                &quot;-c&quot;,
192	                &quot;copy&quot;,
193	                &quot;-y&quot;,
194	                out_path,
195	            ]
196	            log.debug(f&quot;Executing {command}&quot;)
197	            subprocess.run(command)
198	
199	            temp_playlist_path.unlink()
200	
201	            return (out_path,)
202	
203	        if (
204	            images is None or images.size(0) == 0
205	        ):  # the is None check is just for the type checker
206	            return (&quot;&quot;,)
207	
208	        frames = tensor2np(images)
209	        log.debug(f&quot;Frames type {type(frames[0])}&quot;)
210	        log.debug(f&quot;Exporting {len(frames)} frames&quot;)
211	
212	        if codec == &quot;gif&quot;:
213	            out_path = (output_dir / file_id).as_posix()
214	            command = [
215	                &quot;ffmpeg&quot;,
216	                &quot;-f&quot;,
217	                &quot;image2pipe&quot;,
218	                &quot;-vcodec&quot;,
219	                &quot;png&quot;,
220	                &quot;-r&quot;,
221	                str(fps),
222	                &quot;-i&quot;,
223	                &quot;-&quot;,
224	                &quot;-vcodec&quot;,
225	                &quot;gif&quot;,
226	                &quot;-y&quot;,
227	                out_path,
228	            ]
229	            process = subprocess.Popen(command, stdin=subprocess.PIPE)
230	            for frame in frames:
231	                model_management.throw_exception_if_processing_interrupted()
232	                Image.fromarray(frame).save(process.stdin, &quot;PNG&quot;)
233	
234	            process.stdin.close()
235	            process.wait()
236	        else:
237	            frames = [frame.astype(np.uint16) * 257 for frame in frames]
238	
239	        height, width, _ = frames[0].shape
240	
241	        out_path = (output_dir / file_id).as_posix()
242	
243	        # Prepare the FFmpeg command
244	        command = [
245	            &quot;ffmpeg&quot;,
246	            &quot;-y&quot;,
247	            &quot;-f&quot;,
248	            &quot;rawvideo&quot;,
249	            &quot;-vcodec&quot;,
250	            &quot;rawvideo&quot;,
251	            &quot;-s&quot;,
252	            f&quot;{width}x{height}&quot;,
253	            &quot;-pix_fmt&quot;,
254	            pix_fmt,
255	            &quot;-r&quot;,
256	            str(fps),
</pre>
</div>


</div>
</div>

<div id="issue-30">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py</a><br>
    <b>Line number: </b>229<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
169	            temp_playlist_path = (
170	                output_dir / f&quot;temp_playlist_{uuid.uuid4()}.txt&quot;
171	            )
172	            log.debug(
173	                f&quot;Create a temporary file to list the videos for concatenation to {temp_playlist_path}&quot;
174	            )
175	
176	            with open(temp_playlist_path, &quot;w&quot;) as f:
177	                for video_path in playlist:
178	                    f.write(f&quot;file &#x27;{video_path}&#x27;\n&quot;)
179	
180	            out_path = (output_dir / file_id).as_posix()
181	
182	            # Prepare the FFmpeg command for concatenating videos from the playlist
183	            command = [
184	                &quot;ffmpeg&quot;,
185	                &quot;-f&quot;,
186	                &quot;concat&quot;,
187	                &quot;-safe&quot;,
188	                &quot;0&quot;,
189	                &quot;-i&quot;,
190	                temp_playlist_path.as_posix(),
191	                &quot;-c&quot;,
192	                &quot;copy&quot;,
193	                &quot;-y&quot;,
194	                out_path,
195	            ]
196	            log.debug(f&quot;Executing {command}&quot;)
197	            subprocess.run(command)
198	
199	            temp_playlist_path.unlink()
200	
201	            return (out_path,)
202	
203	        if (
204	            images is None or images.size(0) == 0
205	        ):  # the is None check is just for the type checker
206	            return (&quot;&quot;,)
207	
208	        frames = tensor2np(images)
209	        log.debug(f&quot;Frames type {type(frames[0])}&quot;)
210	        log.debug(f&quot;Exporting {len(frames)} frames&quot;)
211	
212	        if codec == &quot;gif&quot;:
213	            out_path = (output_dir / file_id).as_posix()
214	            command = [
215	                &quot;ffmpeg&quot;,
216	                &quot;-f&quot;,
217	                &quot;image2pipe&quot;,
218	                &quot;-vcodec&quot;,
219	                &quot;png&quot;,
220	                &quot;-r&quot;,
221	                str(fps),
222	                &quot;-i&quot;,
223	                &quot;-&quot;,
224	                &quot;-vcodec&quot;,
225	                &quot;gif&quot;,
226	                &quot;-y&quot;,
227	                out_path,
228	            ]
229	            process = subprocess.Popen(command, stdin=subprocess.PIPE)
230	            for frame in frames:
231	                model_management.throw_exception_if_processing_interrupted()
232	                Image.fromarray(frame).save(process.stdin, &quot;PNG&quot;)
233	
234	            process.stdin.close()
235	            process.wait()
236	        else:
237	            frames = [frame.astype(np.uint16) * 257 for frame in frames]
238	
239	        height, width, _ = frames[0].shape
240	
241	        out_path = (output_dir / file_id).as_posix()
242	
243	        # Prepare the FFmpeg command
244	        command = [
245	            &quot;ffmpeg&quot;,
246	            &quot;-y&quot;,
247	            &quot;-f&quot;,
248	            &quot;rawvideo&quot;,
249	            &quot;-vcodec&quot;,
250	            &quot;rawvideo&quot;,
251	            &quot;-s&quot;,
252	            f&quot;{width}x{height}&quot;,
253	            &quot;-pix_fmt&quot;,
254	            pix_fmt,
255	            &quot;-r&quot;,
256	            str(fps),
257	            &quot;-i&quot;,
258	            &quot;-&quot;,
259	            &quot;-c:v&quot;,
260	            codec,
261	            &quot;-r&quot;,
262	            str(fps),
263	            &quot;-y&quot;,
264	            out_path,
265	        ]
266	
267	        process = subprocess.Popen(command, stdin=subprocess.PIPE)
268	
269	        for frame in frames:
270	            model_management.throw_exception_if_processing_interrupted()
271	            process.stdin.write(frame.tobytes())
272	
273	        process.stdin.close()
274	        process.wait()
275	
276	        return (out_path,)
277	
278	
279	def prepare_animated_batch(
280	    batch: torch.Tensor,
281	    pingpong=False,
282	    resize_by=1.0,
283	    resample_filter: Optional[Image.Resampling] = None,
284	    image_type=np.uint8,
285	) -&gt; List[Image.Image]:
286	    images = tensor2np(batch)
287	    images = [frame.astype(image_type) for frame in images]
288	
</pre>
</div>


</div>
</div>

<div id="issue-31">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py</a><br>
    <b>Line number: </b>267<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
207	
208	        frames = tensor2np(images)
209	        log.debug(f&quot;Frames type {type(frames[0])}&quot;)
210	        log.debug(f&quot;Exporting {len(frames)} frames&quot;)
211	
212	        if codec == &quot;gif&quot;:
213	            out_path = (output_dir / file_id).as_posix()
214	            command = [
215	                &quot;ffmpeg&quot;,
216	                &quot;-f&quot;,
217	                &quot;image2pipe&quot;,
218	                &quot;-vcodec&quot;,
219	                &quot;png&quot;,
220	                &quot;-r&quot;,
221	                str(fps),
222	                &quot;-i&quot;,
223	                &quot;-&quot;,
224	                &quot;-vcodec&quot;,
225	                &quot;gif&quot;,
226	                &quot;-y&quot;,
227	                out_path,
228	            ]
229	            process = subprocess.Popen(command, stdin=subprocess.PIPE)
230	            for frame in frames:
231	                model_management.throw_exception_if_processing_interrupted()
232	                Image.fromarray(frame).save(process.stdin, &quot;PNG&quot;)
233	
234	            process.stdin.close()
235	            process.wait()
236	        else:
237	            frames = [frame.astype(np.uint16) * 257 for frame in frames]
238	
239	        height, width, _ = frames[0].shape
240	
241	        out_path = (output_dir / file_id).as_posix()
242	
243	        # Prepare the FFmpeg command
244	        command = [
245	            &quot;ffmpeg&quot;,
246	            &quot;-y&quot;,
247	            &quot;-f&quot;,
248	            &quot;rawvideo&quot;,
249	            &quot;-vcodec&quot;,
250	            &quot;rawvideo&quot;,
251	            &quot;-s&quot;,
252	            f&quot;{width}x{height}&quot;,
253	            &quot;-pix_fmt&quot;,
254	            pix_fmt,
255	            &quot;-r&quot;,
256	            str(fps),
257	            &quot;-i&quot;,
258	            &quot;-&quot;,
259	            &quot;-c:v&quot;,
260	            codec,
261	            &quot;-r&quot;,
262	            str(fps),
263	            &quot;-y&quot;,
264	            out_path,
265	        ]
266	
267	        process = subprocess.Popen(command, stdin=subprocess.PIPE)
268	
269	        for frame in frames:
270	            model_management.throw_exception_if_processing_interrupted()
271	            process.stdin.write(frame.tobytes())
272	
273	        process.stdin.close()
274	        process.wait()
275	
276	        return (out_path,)
277	
278	
279	def prepare_animated_batch(
280	    batch: torch.Tensor,
281	    pingpong=False,
282	    resize_by=1.0,
283	    resample_filter: Optional[Image.Resampling] = None,
284	    image_type=np.uint8,
285	) -&gt; List[Image.Image]:
286	    images = tensor2np(batch)
287	    images = [frame.astype(image_type) for frame in images]
288	
289	    height, width, _ = batch[0].shape
290	
291	    if pingpong:
292	        reversed_frames = images[::-1]
293	        images.extend(reversed_frames)
294	    pil_images = [Image.fromarray(frame) for frame in images]
295	
296	    # Resize frames if necessary
297	    if abs(resize_by - 1.0) &gt; 1e-6:
298	        new_width = int(width * resize_by)
299	        new_height = int(height * resize_by)
300	        pil_images_resized = [
301	            frame.resize((new_width, new_height), resample=resample_filter)
302	            for frame in pil_images
303	        ]
304	        pil_images = pil_images_resized
305	
306	    return pil_images
307	
308	
309	# todo: deprecate for apng
310	class MTB_SaveGif:
311	    &quot;&quot;&quot;Save the images from the batch as a GIF&quot;&quot;&quot;
312	
313	    @classmethod
314	    def INPUT_TYPES(cls):
315	        return {
316	            &quot;required&quot;: {
317	                &quot;image&quot;: (&quot;IMAGE&quot;,),
318	                &quot;fps&quot;: (&quot;INT&quot;, {&quot;default&quot;: 12, &quot;min&quot;: 1, &quot;max&quot;: 120}),
319	                &quot;resize_by&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 1.0, &quot;min&quot;: 0.1}),
320	                &quot;optimize&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
321	                &quot;pingpong&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
322	                &quot;resample_filter&quot;: (list(PIL_FILTER_MAP.keys()),),
323	                &quot;use_ffmpeg&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
324	            },
325	        }
326	
</pre>
</div>


</div>
</div>

<div id="issue-32">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/nodes/io.py</a><br>
    <b>Line number: </b>376<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
316	            &quot;required&quot;: {
317	                &quot;image&quot;: (&quot;IMAGE&quot;,),
318	                &quot;fps&quot;: (&quot;INT&quot;, {&quot;default&quot;: 12, &quot;min&quot;: 1, &quot;max&quot;: 120}),
319	                &quot;resize_by&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 1.0, &quot;min&quot;: 0.1}),
320	                &quot;optimize&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
321	                &quot;pingpong&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
322	                &quot;resample_filter&quot;: (list(PIL_FILTER_MAP.keys()),),
323	                &quot;use_ffmpeg&quot;: (&quot;BOOLEAN&quot;, {&quot;default&quot;: False}),
324	            },
325	        }
326	
327	    RETURN_TYPES = ()
328	    OUTPUT_NODE = True
329	    CATEGORY = &quot;mtb/IO&quot;
330	    FUNCTION = &quot;save_gif&quot;
331	
332	    def save_gif(
333	        self,
334	        image,
335	        fps=12,
336	        resize_by=1.0,
337	        optimize=False,
338	        pingpong=False,
339	        resample_filter=None,
340	        use_ffmpeg=False,
341	    ):
342	        if image.size(0) == 0:
343	            return (&quot;&quot;,)
344	
345	        if resample_filter is not None:
346	            resample_filter = PIL_FILTER_MAP.get(resample_filter)
347	
348	        pil_images = prepare_animated_batch(
349	            image,
350	            pingpong,
351	            resize_by,
352	            resample_filter,
353	        )
354	
355	        ruuid = uuid.uuid4()
356	        ruuid = ruuid.hex[:10]
357	        out_path = f&quot;{folder_paths.output_directory}/{ruuid}.gif&quot;
358	
359	        if use_ffmpeg:
360	            # Use FFmpeg to create the GIF from PIL images
361	            command = [
362	                &quot;ffmpeg&quot;,
363	                &quot;-f&quot;,
364	                &quot;image2pipe&quot;,
365	                &quot;-vcodec&quot;,
366	                &quot;png&quot;,
367	                &quot;-r&quot;,
368	                str(fps),
369	                &quot;-i&quot;,
370	                &quot;-&quot;,
371	                &quot;-vcodec&quot;,
372	                &quot;gif&quot;,
373	                &quot;-y&quot;,
374	                out_path,
375	            ]
376	            process = subprocess.Popen(command, stdin=subprocess.PIPE)
377	            for image in pil_images:
378	                model_management.throw_exception_if_processing_interrupted()
379	                image.save(process.stdin, &quot;PNG&quot;)
380	            process.stdin.close()
381	            process.wait()
382	
383	        else:
384	            pil_images[0].save(
385	                out_path,
386	                save_all=True,
387	                append_images=pil_images[1:],
388	                optimize=optimize,
389	                duration=int(1000 / fps),
390	                loop=0,
391	            )
392	        results = [
393	            {&quot;filename&quot;: f&quot;{ruuid}.gif&quot;, &quot;subfolder&quot;: &quot;&quot;, &quot;type&quot;: &quot;output&quot;}
394	        ]
395	        return {&quot;ui&quot;: {&quot;gif&quot;: results}}
396	
397	
398	__nodes__ = [
399	    MTB_SaveGif,
400	    MTB_ExportWithFfmpeg,
401	    MTB_AddToPlaylist,
402	    MTB_ReadPlaylist,
403	]
</pre>
</div>


</div>
</div>

<div id="issue-33">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/download_models.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/download_models.py</a><br>
    <b>Line number: </b>5<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import os
2	import requests
3	from rich.console import Console
4	from tqdm import tqdm
5	import subprocess
6	import sys
7	
8	try:
9	    import folder_paths
10	except ModuleNotFoundError:
11	    import sys
12	
13	    sys.path.append(os.path.join(os.path.dirname(__file__), &quot;../../..&quot;))
14	    import folder_paths
15	
16	models_to_download = {
17	    &quot;DeepBump&quot;: {
18	        &quot;size&quot;: 25.5,
19	        &quot;download_url&quot;: &quot;https://github.com/HugoTini/DeepBump/raw/master/deepbump256.onnx&quot;,
20	        &quot;destination&quot;: &quot;deepbump&quot;,
21	    },
22	    &quot;Face Swap&quot;: {
23	        &quot;size&quot;: 660,
24	        &quot;download_url&quot;: [
25	            &quot;https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_mobilenet0.25_Final.pth&quot;,
26	            &quot;https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth&quot;,
27	            &quot;https://huggingface.co/deepinsight/inswapper/resolve/main/inswapper_128.onnx&quot;,
28	        ],
29	        &quot;destination&quot;: &quot;insightface&quot;,
30	    },
31	    &quot;GFPGAN (face enhancement)&quot;: {
32	        &quot;size&quot;: 332,
33	        &quot;download_url&quot;: [
34	            &quot;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&quot;,
35	            &quot;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth&quot;
36	            # TODO: provide a way to selectively download models from &quot;packs&quot;
37	            # https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth
38	            # https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth
39	            # https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth
40	        ],
41	        &quot;destination&quot;: &quot;face_restore&quot;,
42	    },
43	    &quot;FILM: Frame Interpolation for Large Motion&quot;: {
44	        &quot;size&quot;: 402,
45	        &quot;download_url&quot;: [
46	            &quot;https://drive.google.com/drive/folders/131_--QrieM4aQbbLWrUtbO2cGbX8-war&quot;
47	        ],
48	        &quot;destination&quot;: &quot;FILM&quot;,
49	    },
50	}
51	
52	console = Console()
53	
54	from urllib.parse import urlparse
55	from pathlib import Path
56	
57	
58	def download_model(download_url, destination):
59	    if isinstance(download_url, list):
60	        for url in download_url:
61	            download_model(url, destination)
62	        return
63	
64	    filename = os.path.basename(urlparse(download_url).path)
65	    response = None
66	    if &quot;drive.google.com&quot; in download_url:
67	        try:
68	            import gdown
69	        except ImportError:
70	            print(&quot;Installing gdown&quot;)
71	            subprocess.check_call(
72	                [
73	                    sys.executable,
74	                    &quot;-m&quot;,
75	                    &quot;pip&quot;,
76	                    &quot;install&quot;,
77	                    &quot;git+https://github.com/melMass/gdown@main&quot;,
78	                ]
79	            )
80	            import gdown
81	
82	        if &quot;/folders/&quot; in download_url:
83	            # download folder
84	            try:
85	                gdown.download_folder(download_url, output=destination, resume=True)
86	            except TypeError:
87	                gdown.download_folder(download_url, output=destination)
88	
89	            return
90	        # download from google drive
91	        gdown.download(download_url, destination, quiet=False, resume=True)
92	        return
93	
94	    response = requests.get(download_url, stream=True)
95	    total_size = int(response.headers.get(&quot;content-length&quot;, 0))
96	
97	    destination_path = os.path.join(destination, filename)
98	    with open(destination_path, &quot;wb&quot;) as file:
99	        with tqdm(
100	            total=total_size, unit=&quot;B&quot;, unit_scale=True, desc=destination_path, ncols=80
101	        ) as progress_bar:
102	            for data in response.iter_content(chunk_size=4096):
103	                file.write(data)
104	                progress_bar.update(len(data))
105	
106	    console.print(
107	        f&quot;Downloaded model from {download_url} to {destination_path}&quot;,
108	        style=&quot;bold green&quot;,
109	    )
110	
111	
112	def ask_user_for_downloads(models_to_download):
113	    console.print(&quot;Choose models to download:&quot;)
114	    choices = {}
115	    for i, model_name in enumerate(models_to_download.keys(), start=1):
116	        choices[str(i)] = model_name
117	        console.print(f&quot;{i}. {model_name}&quot;)
118	
119	    console.print(
120	        &quot;Enter the numbers of the models you want to download (comma-separated):&quot;
</pre>
</div>


</div>
</div>

<div id="issue-34">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/download_models.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/download_models.py</a><br>
    <b>Line number: </b>71<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
11	    import sys
12	
13	    sys.path.append(os.path.join(os.path.dirname(__file__), &quot;../../..&quot;))
14	    import folder_paths
15	
16	models_to_download = {
17	    &quot;DeepBump&quot;: {
18	        &quot;size&quot;: 25.5,
19	        &quot;download_url&quot;: &quot;https://github.com/HugoTini/DeepBump/raw/master/deepbump256.onnx&quot;,
20	        &quot;destination&quot;: &quot;deepbump&quot;,
21	    },
22	    &quot;Face Swap&quot;: {
23	        &quot;size&quot;: 660,
24	        &quot;download_url&quot;: [
25	            &quot;https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_mobilenet0.25_Final.pth&quot;,
26	            &quot;https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth&quot;,
27	            &quot;https://huggingface.co/deepinsight/inswapper/resolve/main/inswapper_128.onnx&quot;,
28	        ],
29	        &quot;destination&quot;: &quot;insightface&quot;,
30	    },
31	    &quot;GFPGAN (face enhancement)&quot;: {
32	        &quot;size&quot;: 332,
33	        &quot;download_url&quot;: [
34	            &quot;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&quot;,
35	            &quot;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth&quot;
36	            # TODO: provide a way to selectively download models from &quot;packs&quot;
37	            # https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth
38	            # https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth
39	            # https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth
40	        ],
41	        &quot;destination&quot;: &quot;face_restore&quot;,
42	    },
43	    &quot;FILM: Frame Interpolation for Large Motion&quot;: {
44	        &quot;size&quot;: 402,
45	        &quot;download_url&quot;: [
46	            &quot;https://drive.google.com/drive/folders/131_--QrieM4aQbbLWrUtbO2cGbX8-war&quot;
47	        ],
48	        &quot;destination&quot;: &quot;FILM&quot;,
49	    },
50	}
51	
52	console = Console()
53	
54	from urllib.parse import urlparse
55	from pathlib import Path
56	
57	
58	def download_model(download_url, destination):
59	    if isinstance(download_url, list):
60	        for url in download_url:
61	            download_model(url, destination)
62	        return
63	
64	    filename = os.path.basename(urlparse(download_url).path)
65	    response = None
66	    if &quot;drive.google.com&quot; in download_url:
67	        try:
68	            import gdown
69	        except ImportError:
70	            print(&quot;Installing gdown&quot;)
71	            subprocess.check_call(
72	                [
73	                    sys.executable,
74	                    &quot;-m&quot;,
75	                    &quot;pip&quot;,
76	                    &quot;install&quot;,
77	                    &quot;git+https://github.com/melMass/gdown@main&quot;,
78	                ]
79	            )
80	            import gdown
81	
82	        if &quot;/folders/&quot; in download_url:
83	            # download folder
84	            try:
85	                gdown.download_folder(download_url, output=destination, resume=True)
86	            except TypeError:
87	                gdown.download_folder(download_url, output=destination)
88	
89	            return
90	        # download from google drive
91	        gdown.download(download_url, destination, quiet=False, resume=True)
92	        return
93	
94	    response = requests.get(download_url, stream=True)
95	    total_size = int(response.headers.get(&quot;content-length&quot;, 0))
96	
97	    destination_path = os.path.join(destination, filename)
98	    with open(destination_path, &quot;wb&quot;) as file:
99	        with tqdm(
100	            total=total_size, unit=&quot;B&quot;, unit_scale=True, desc=destination_path, ncols=80
101	        ) as progress_bar:
102	            for data in response.iter_content(chunk_size=4096):
103	                file.write(data)
104	                progress_bar.update(len(data))
105	
106	    console.print(
107	        f&quot;Downloaded model from {download_url} to {destination_path}&quot;,
108	        style=&quot;bold green&quot;,
109	    )
110	
111	
112	def ask_user_for_downloads(models_to_download):
113	    console.print(&quot;Choose models to download:&quot;)
114	    choices = {}
115	    for i, model_name in enumerate(models_to_download.keys(), start=1):
116	        choices[str(i)] = model_name
117	        console.print(f&quot;{i}. {model_name}&quot;)
118	
119	    console.print(
120	        &quot;Enter the numbers of the models you want to download (comma-separated):&quot;
121	    )
122	    user_input = console.input(&quot;&gt;&gt; &quot;)
123	    selected_models = user_input.split(&quot;,&quot;)
124	    models_to_download_selected = {}
125	
126	    for choice in selected_models:
127	        choice = choice.strip()
128	
129	        if choice in choices:
130	            model_name = choices[choice]
131	            models_to_download_selected[model_name] = models_to_download[model_name]
132	
133	        elif choice == &quot;&quot;:
134	            # download all
135	            models_to_download_selected = models_to_download
136	        else:
137	            console.print(f&quot;Invalid choice: {choice}. Skipping.&quot;)
138	
</pre>
</div>


</div>
</div>

<div id="issue-35">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/download_models.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/download_models.py</a><br>
    <b>Line number: </b>94<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
34	            &quot;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth&quot;,
35	            &quot;https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth&quot;
36	            # TODO: provide a way to selectively download models from &quot;packs&quot;
37	            # https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth
38	            # https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth
39	            # https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth
40	        ],
41	        &quot;destination&quot;: &quot;face_restore&quot;,
42	    },
43	    &quot;FILM: Frame Interpolation for Large Motion&quot;: {
44	        &quot;size&quot;: 402,
45	        &quot;download_url&quot;: [
46	            &quot;https://drive.google.com/drive/folders/131_--QrieM4aQbbLWrUtbO2cGbX8-war&quot;
47	        ],
48	        &quot;destination&quot;: &quot;FILM&quot;,
49	    },
50	}
51	
52	console = Console()
53	
54	from urllib.parse import urlparse
55	from pathlib import Path
56	
57	
58	def download_model(download_url, destination):
59	    if isinstance(download_url, list):
60	        for url in download_url:
61	            download_model(url, destination)
62	        return
63	
64	    filename = os.path.basename(urlparse(download_url).path)
65	    response = None
66	    if &quot;drive.google.com&quot; in download_url:
67	        try:
68	            import gdown
69	        except ImportError:
70	            print(&quot;Installing gdown&quot;)
71	            subprocess.check_call(
72	                [
73	                    sys.executable,
74	                    &quot;-m&quot;,
75	                    &quot;pip&quot;,
76	                    &quot;install&quot;,
77	                    &quot;git+https://github.com/melMass/gdown@main&quot;,
78	                ]
79	            )
80	            import gdown
81	
82	        if &quot;/folders/&quot; in download_url:
83	            # download folder
84	            try:
85	                gdown.download_folder(download_url, output=destination, resume=True)
86	            except TypeError:
87	                gdown.download_folder(download_url, output=destination)
88	
89	            return
90	        # download from google drive
91	        gdown.download(download_url, destination, quiet=False, resume=True)
92	        return
93	
94	    response = requests.get(download_url, stream=True)
95	    total_size = int(response.headers.get(&quot;content-length&quot;, 0))
96	
97	    destination_path = os.path.join(destination, filename)
98	    with open(destination_path, &quot;wb&quot;) as file:
99	        with tqdm(
100	            total=total_size, unit=&quot;B&quot;, unit_scale=True, desc=destination_path, ncols=80
101	        ) as progress_bar:
102	            for data in response.iter_content(chunk_size=4096):
103	                file.write(data)
104	                progress_bar.update(len(data))
105	
106	    console.print(
107	        f&quot;Downloaded model from {download_url} to {destination_path}&quot;,
108	        style=&quot;bold green&quot;,
109	    )
110	
111	
112	def ask_user_for_downloads(models_to_download):
113	    console.print(&quot;Choose models to download:&quot;)
114	    choices = {}
115	    for i, model_name in enumerate(models_to_download.keys(), start=1):
116	        choices[str(i)] = model_name
117	        console.print(f&quot;{i}. {model_name}&quot;)
118	
119	    console.print(
120	        &quot;Enter the numbers of the models you want to download (comma-separated):&quot;
121	    )
122	    user_input = console.input(&quot;&gt;&gt; &quot;)
123	    selected_models = user_input.split(&quot;,&quot;)
124	    models_to_download_selected = {}
125	
126	    for choice in selected_models:
127	        choice = choice.strip()
128	
129	        if choice in choices:
130	            model_name = choices[choice]
131	            models_to_download_selected[model_name] = models_to_download[model_name]
132	
133	        elif choice == &quot;&quot;:
134	            # download all
135	            models_to_download_selected = models_to_download
136	        else:
137	            console.print(f&quot;Invalid choice: {choice}. Skipping.&quot;)
138	
139	    return models_to_download_selected
140	
141	
142	def handle_interrupt():
143	    console.print(&quot;Interrupted by user.&quot;, style=&quot;bold red&quot;)
144	
145	
146	def main(models_to_download, skip_input=False):
147	    try:
148	        models_to_download_selected = {}
149	
150	        def check_destination(urls, destination):
151	            if isinstance(urls, list):
152	                for url in urls:
153	                    check_destination(url, destination)
</pre>
</div>


</div>
</div>

<div id="issue-36">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/interpolate_frames.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/interpolate_frames.py</a><br>
    <b>Line number: </b>16<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import glob
2	from pathlib import Path
3	import uuid
4	import sys
5	from typing import List
6	
7	sys.path.append((Path(__file__).parent / &quot;extern&quot;).as_posix())
8	
9	
10	import argparse
11	from rich_argparse import RichHelpFormatter
12	from rich.console import Console
13	from rich.progress import Progress
14	
15	import numpy as np
16	import subprocess
17	
18	
19	def write_prores_444_video(output_file, frames: List[np.ndarray], fps):
20	    # Convert float images to the range of 0-65535 (12-bit color depth)
21	    frames = [(frame * 65535).clip(0, 65535).astype(np.uint16) for frame in frames]
22	
23	    height, width, _ = frames[0].shape
24	
25	    # Prepare the FFmpeg command
26	    command = [
27	        &quot;ffmpeg&quot;,
28	        &quot;-y&quot;,  # Overwrite output file if it already exists
29	        &quot;-f&quot;,
30	        &quot;rawvideo&quot;,
31	        &quot;-vcodec&quot;,
32	        &quot;rawvideo&quot;,
33	        &quot;-s&quot;,
34	        f&quot;{width}x{height}&quot;,
35	        &quot;-pix_fmt&quot;,
36	        &quot;rgb48le&quot;,
37	        &quot;-r&quot;,
38	        str(fps),
39	        &quot;-i&quot;,
40	        &quot;-&quot;,
41	        &quot;-c:v&quot;,
42	        &quot;prores_ks&quot;,
43	        &quot;-profile:v&quot;,
44	        &quot;4&quot;,
45	        &quot;-pix_fmt&quot;,
46	        &quot;yuva444p10le&quot;,
47	        &quot;-r&quot;,
48	        str(fps),
49	        &quot;-y&quot;,  # Overwrite output file if it already exists
50	        output_file,
51	    ]
52	
53	    process = subprocess.Popen(command, stdin=subprocess.PIPE)
54	
55	    for frame in frames:
56	        process.stdin.write(frame.tobytes())
57	
58	    process.stdin.close()
59	    process.wait()
60	
61	
62	if __name__ == &quot;__main__&quot;:
63	    default_output = f&quot;./output_{uuid.uuid4()}.mov&quot;
64	    parser = argparse.ArgumentParser(
65	        description=&quot;FILM frame interpolation&quot;, formatter_class=RichHelpFormatter
66	    )
67	    parser.add_argument(&quot;inputs&quot;, nargs=&quot;*&quot;, help=&quot;Input image files&quot;)
68	    parser.add_argument(&quot;--output&quot;, help=&quot;Output JSON file&quot;, default=default_output)
69	    parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, action=&quot;store_true&quot;, help=&quot;Verbose mode&quot;)
70	    parser.add_argument(
71	        &quot;--glob&quot;, help=&quot;Enable glob pattern matching&quot;, metavar=&quot;PATTERN&quot;
72	    )
73	    parser.add_argument(
74	        &quot;--interpolate&quot;, type=int, default=4, help=&quot;Time for interpolated frames&quot;
75	    )
76	    parser.add_argument(&quot;--fps&quot;, type=int, default=30, help=&quot;Out FPS&quot;)
77	    align = 64
78	    block_width = 2
79	    block_height = 2
80	
81	    args = parser.parse_args()
82	
83	    # - checks
84	    if not args.glob and not args.inputs:
85	        parser.error(&quot;Either --glob flag or inputs must be provided.&quot;)
86	    if args.glob:
87	        glob_pattern = args.glob
88	        try:
89	            pattern_path = str(Path(glob_pattern).expanduser().resolve())
90	
91	            if not any(glob.glob(pattern_path)):
92	                raise ValueError(f&quot;No files found for glob pattern: {glob_pattern}&quot;)
93	        except Exception as e:
94	            console = Console()
95	            console.print(
96	                f&quot;[bold red]Error: Invalid glob pattern &#x27;{glob_pattern}&#x27;: {e}[/bold red]&quot;
97	            )
98	
99	            exit(1)
100	    else:
101	        glob_pattern = None
102	
103	    input_files: List[Path] = []
104	
105	    if glob_pattern:
106	        input_files = [
107	            Path(p)
108	            for p in list(glob.glob(str(Path(glob_pattern).expanduser().resolve())))
109	        ]
110	    else:
111	        input_files = [Path(p) for p in args.inputs]
112	
113	    console = Console()
114	    console.print(&quot;Input Files:&quot;, style=&quot;bold&quot;, end=&quot; &quot;)
115	    console.print(f&quot;{len(input_files):03d} files&quot;, style=&quot;cyan&quot;)
116	    # for input_file in args.inputs:
117	    #     console.print(f&quot;- {input_file}&quot;, style=&quot;cyan&quot;)
118	    console.print(&quot;\nOutput File:&quot;, style=&quot;bold&quot;, end=&quot; &quot;)
119	    console.print(f&quot;{Path(args.output).resolve().absolute()}&quot;, style=&quot;cyan&quot;)
120	
</pre>
</div>


</div>
</div>

<div id="issue-37">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/interpolate_frames.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/scripts/interpolate_frames.py</a><br>
    <b>Line number: </b>53<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	import glob
2	from pathlib import Path
3	import uuid
4	import sys
5	from typing import List
6	
7	sys.path.append((Path(__file__).parent / &quot;extern&quot;).as_posix())
8	
9	
10	import argparse
11	from rich_argparse import RichHelpFormatter
12	from rich.console import Console
13	from rich.progress import Progress
14	
15	import numpy as np
16	import subprocess
17	
18	
19	def write_prores_444_video(output_file, frames: List[np.ndarray], fps):
20	    # Convert float images to the range of 0-65535 (12-bit color depth)
21	    frames = [(frame * 65535).clip(0, 65535).astype(np.uint16) for frame in frames]
22	
23	    height, width, _ = frames[0].shape
24	
25	    # Prepare the FFmpeg command
26	    command = [
27	        &quot;ffmpeg&quot;,
28	        &quot;-y&quot;,  # Overwrite output file if it already exists
29	        &quot;-f&quot;,
30	        &quot;rawvideo&quot;,
31	        &quot;-vcodec&quot;,
32	        &quot;rawvideo&quot;,
33	        &quot;-s&quot;,
34	        f&quot;{width}x{height}&quot;,
35	        &quot;-pix_fmt&quot;,
36	        &quot;rgb48le&quot;,
37	        &quot;-r&quot;,
38	        str(fps),
39	        &quot;-i&quot;,
40	        &quot;-&quot;,
41	        &quot;-c:v&quot;,
42	        &quot;prores_ks&quot;,
43	        &quot;-profile:v&quot;,
44	        &quot;4&quot;,
45	        &quot;-pix_fmt&quot;,
46	        &quot;yuva444p10le&quot;,
47	        &quot;-r&quot;,
48	        str(fps),
49	        &quot;-y&quot;,  # Overwrite output file if it already exists
50	        output_file,
51	    ]
52	
53	    process = subprocess.Popen(command, stdin=subprocess.PIPE)
54	
55	    for frame in frames:
56	        process.stdin.write(frame.tobytes())
57	
58	    process.stdin.close()
59	    process.wait()
60	
61	
62	if __name__ == &quot;__main__&quot;:
63	    default_output = f&quot;./output_{uuid.uuid4()}.mov&quot;
64	    parser = argparse.ArgumentParser(
65	        description=&quot;FILM frame interpolation&quot;, formatter_class=RichHelpFormatter
66	    )
67	    parser.add_argument(&quot;inputs&quot;, nargs=&quot;*&quot;, help=&quot;Input image files&quot;)
68	    parser.add_argument(&quot;--output&quot;, help=&quot;Output JSON file&quot;, default=default_output)
69	    parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, action=&quot;store_true&quot;, help=&quot;Verbose mode&quot;)
70	    parser.add_argument(
71	        &quot;--glob&quot;, help=&quot;Enable glob pattern matching&quot;, metavar=&quot;PATTERN&quot;
72	    )
73	    parser.add_argument(
74	        &quot;--interpolate&quot;, type=int, default=4, help=&quot;Time for interpolated frames&quot;
75	    )
76	    parser.add_argument(&quot;--fps&quot;, type=int, default=30, help=&quot;Out FPS&quot;)
77	    align = 64
78	    block_width = 2
79	    block_height = 2
80	
81	    args = parser.parse_args()
82	
83	    # - checks
84	    if not args.glob and not args.inputs:
85	        parser.error(&quot;Either --glob flag or inputs must be provided.&quot;)
86	    if args.glob:
87	        glob_pattern = args.glob
88	        try:
89	            pattern_path = str(Path(glob_pattern).expanduser().resolve())
90	
91	            if not any(glob.glob(pattern_path)):
92	                raise ValueError(f&quot;No files found for glob pattern: {glob_pattern}&quot;)
93	        except Exception as e:
94	            console = Console()
95	            console.print(
96	                f&quot;[bold red]Error: Invalid glob pattern &#x27;{glob_pattern}&#x27;: {e}[/bold red]&quot;
97	            )
98	
99	            exit(1)
100	    else:
101	        glob_pattern = None
102	
103	    input_files: List[Path] = []
104	
105	    if glob_pattern:
106	        input_files = [
107	            Path(p)
108	            for p in list(glob.glob(str(Path(glob_pattern).expanduser().resolve())))
109	        ]
110	    else:
111	        input_files = [Path(p) for p in args.inputs]
112	
113	    console = Console()
114	    console.print(&quot;Input Files:&quot;, style=&quot;bold&quot;, end=&quot; &quot;)
115	    console.print(f&quot;{len(input_files):03d} files&quot;, style=&quot;cyan&quot;)
116	    # for input_file in args.inputs:
117	    #     console.print(f&quot;- {input_file}&quot;, style=&quot;cyan&quot;)
118	    console.print(&quot;\nOutput File:&quot;, style=&quot;bold&quot;, end=&quot; &quot;)
119	    console.print(f&quot;{Path(args.output).resolve().absolute()}&quot;, style=&quot;cyan&quot;)
120	
</pre>
</div>


</div>
</div>

<div id="issue-38">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py</a><br>
    <b>Line number: </b>9<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import contextlib
2	import functools
3	import importlib
4	import math
5	import os
6	import shlex
7	import shutil
8	import socket
9	import subprocess
10	import sys
11	import uuid
12	from pathlib import Path
13	from typing import List, Optional, Union
14	
15	import folder_paths
16	import numpy as np
17	import requests
18	import torch
19	from PIL import Image
20	
21	from .install import pip_map
22	
23	try:
24	    from .log import log
25	except ImportError:
26	    try:
27	        from log import log
28	
29	        log.warn(&quot;Imported log without relative path&quot;)
30	    except ImportError:
31	        import logging
32	
33	        log = logging.getLogger(&quot;comfy mtb utils&quot;)
34	        log.warn(&quot;[comfy mtb] You probably called the file outside a module.&quot;)
35	
36	
37	# region SANITY_CHECK Utilities
38	
39	
40	def make_report():
41	    pass
42	
43	
44	# endregion
45	
46	
47	# region NFOV
48	class numpy_NFOV:
49	    def __init__(self, fov=None, height: int = 400, width: int = 800):
50	        self.field_of_view = fov or [0.45, 0.45]
51	        self.PI = np.pi
52	        self.PI_2 = np.pi * 0.5
53	        self.PI2 = np.pi * 2.0
54	        self.height = height
55	        self.width = width
56	        self.screen_points = self._get_screen_img()
57	
58	    def _get_coord_rad(self, is_center_point, center_point=None):
59	        if is_center_point:
60	            center_point = np.array(center_point)
61	            return (center_point * 2 - 1) * np.array([self.PI, self.PI_2])
62	        else:
63	            return (
64	                (self.screen_points * 2 - 1)
65	                * np.array([self.PI, self.PI_2])
66	                * (np.ones(self.screen_points.shape) * self.field_of_view)
67	            )
68	
69	    def _get_screen_img(self):
70	        xx, yy = np.meshgrid(
71	            np.linspace(0, 1, self.width), np.linspace(0, 1, self.height)
72	        )
73	        return np.array([xx.ravel(), yy.ravel()]).T
74	
75	    def _calc_spherical_to_gnomonic(self, converted_screen_coord):
76	        x = converted_screen_coord.T[0]
77	        y = converted_screen_coord.T[1]
78	
79	        rou = np.sqrt(x**2 + y**2)
80	        c = np.arctan(rou)
81	        sin_c = np.sin(c)
82	        cos_c = np.cos(c)
83	
84	        lat = np.arcsin(
85	            cos_c * np.sin(self.cp[1]) + (y * sin_c * np.cos(self.cp[1])) / rou
86	        )
87	        lon = self.cp[0] + np.arctan2(
88	            x * sin_c,
89	            rou * np.cos(self.cp[1]) * cos_c - y * np.sin(self.cp[1]) * sin_c,
90	        )
91	
92	        lat = (lat / self.PI_2 + 1.0) * 0.5
93	        lon = (lon / self.PI + 1.0) * 0.5
94	
95	        return np.array([lon, lat]).T
96	
97	    def _bilinear_interpolation(self, screen_coord):
98	        uf = np.mod(screen_coord.T[0], 1) * self.frame_width  # long - width
99	        vf = np.mod(screen_coord.T[1], 1) * self.frame_height  # lat - height
100	
101	        x0 = np.floor(uf).astype(int)  # coord of pixel to bottom left
102	        y0 = np.floor(vf).astype(int)
103	        x2 = np.add(
104	            x0, np.ones(uf.shape).astype(int)
105	        )  # coords of pixel to top right
106	        y2 = np.add(y0, np.ones(vf.shape).astype(int))
107	
108	        base_y0 = np.multiply(y0, self.frame_width)
109	        base_y2 = np.multiply(y2, self.frame_width)
110	
111	        A_idx = np.add(base_y0, x0)
112	        B_idx = np.add(base_y2, x0)
113	        C_idx = np.add(base_y0, x2)
114	        D_idx = np.add(base_y2, x2)
115	
116	        flat_img = np.reshape(self.frame, [-1, self.frame_channel])
117	
118	        A = np.take(flat_img, A_idx, axis=0)
119	        B = np.take(flat_img, B_idx, axis=0)
120	        C = np.take(flat_img, C_idx, axis=0)
</pre>
</div>


</div>
</div>

<div id="issue-39">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py</a><br>
    <b>Line number: </b>187<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
127	
128	        # interpolate
129	        AA = np.multiply(A, np.array([wa, wa, wa]).T)
130	        BB = np.multiply(B, np.array([wb, wb, wb]).T)
131	        CC = np.multiply(C, np.array([wc, wc, wc]).T)
132	        DD = np.multiply(D, np.array([wd, wd, wd]).T)
133	        nfov = np.reshape(
134	            np.round(AA + BB + CC + DD).astype(np.uint8),
135	            [self.height, self.width, 3],
136	        )
137	
138	        return nfov
139	
140	    def to_nfov(self, frame, center_point):
141	        self.frame = frame
142	        self.frame_height = frame.shape[0]
143	        self.frame_width = frame.shape[1]
144	        self.frame_channel = frame.shape[2]
145	
146	        self.cp = self._get_coord_rad(
147	            center_point=center_point, is_center_point=True
148	        )
149	        converted_screen_coord = self._get_coord_rad(is_center_point=False)
150	        return self._bilinear_interpolation(
151	            self._calc_spherical_to_gnomonic(converted_screen_coord)
152	        )
153	
154	
155	# endregion
156	
157	
158	# region SERVER Utilities
159	class IPChecker:
160	    def __init__(self):
161	        self.ips = list(self.get_local_ips())
162	        log.debug(f&quot;Found {len(self.ips)} local ips&quot;)
163	        self.checked_ips = set()
164	
165	    def get_working_ip(self, test_url_template):
166	        for ip in self.ips:
167	            if ip not in self.checked_ips:
168	                self.checked_ips.add(ip)
169	                test_url = test_url_template.format(ip)
170	                if self._test_url(test_url):
171	                    return ip
172	        return None
173	
174	    @staticmethod
175	    def get_local_ips(prefix=&quot;192.168.&quot;):
176	        hostname = socket.gethostname()
177	        log.debug(f&quot;Getting local ips for {hostname}&quot;)
178	        for info in socket.getaddrinfo(hostname, None):
179	            # Filter out IPv6 addresses if you only want IPv4
180	            log.debug(info)
181	            # if info[1] == socket.SOCK_STREAM and
182	            if info[0] == socket.AF_INET and info[4][0].startswith(prefix):
183	                yield info[4][0]
184	
185	    def _test_url(self, url):
186	        try:
187	            response = requests.get(url)
188	            return response.status_code == 200
189	        except Exception:
190	            return False
191	
192	
193	@functools.lru_cache(maxsize=1)
194	def get_server_info():
195	    from comfy.cli_args import args
196	
197	    ip_checker = IPChecker()
198	    base_url = args.listen
199	    if base_url == &quot;0.0.0.0&quot;:
200	        log.debug(&quot;Server set to 0.0.0.0, we will try to resolve the host IP&quot;)
201	        base_url = ip_checker.get_working_ip(
202	            f&quot;http://{{}}:{args.port}/history&quot;
203	        )
204	        log.debug(f&quot;Setting ip to {base_url}&quot;)
205	    return (base_url, args.port)
206	
207	
208	# endregion
209	
210	
211	# region MISC Utilities
212	def backup_file(
213	    fp: Path,
214	    target: Optional[Path] = None,
215	    backup_dir: str = &quot;.bak&quot;,
216	    suffix: Optional[str] = None,
217	    prefix: Optional[str] = None,
218	):
219	    if not fp.exists():
220	        raise FileNotFoundError(f&quot;No file found at {fp}&quot;)
221	
222	    backup_directory = target or fp.parent / backup_dir
223	    backup_directory.mkdir(parents=True, exist_ok=True)
224	
225	    stem = fp.stem
226	
227	    if suffix or prefix:
228	        new_stem = f&quot;{prefix or &#x27;&#x27;}{stem}{suffix or &#x27;&#x27;}&quot;
229	    else:
230	        new_stem = f&quot;{stem}_{uuid.uuid4()}&quot;
231	
232	    backup_file_path = backup_directory / f&quot;{new_stem}{fp.suffix}&quot;
233	
234	    # Perform the backup
235	    shutil.copy(fp, backup_file_path)
236	    log.debug(f&quot;File backed up to {backup_file_path}&quot;)
237	
238	
239	def hex_to_rgb(hex_color):
240	    try:
241	        hex_color = hex_color.lstrip(&quot;#&quot;)
242	        return tuple(int(hex_color[i : i + 2], 16) for i in (0, 2, 4))
243	    except ValueError:
244	        log.error(f&quot;Invalid hex color: {hex_color}&quot;)
245	        return (0, 0, 0)
246	
</pre>
</div>


</div>
</div>

<div id="issue-40">
<div class="issue-block issue-sev-medium">
    <b>hardcoded_bind_all_interfaces: </b> Possible binding to all interfaces.<br>
    <b>Test ID:</b> B104<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>MEDIUM<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/605.html" target="_blank">CWE-605</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py</a><br>
    <b>Line number: </b>199<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b104_hardcoded_bind_all_interfaces.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b104_hardcoded_bind_all_interfaces.html</a><br>

<div class="code">
<pre>
139	
140	    def to_nfov(self, frame, center_point):
141	        self.frame = frame
142	        self.frame_height = frame.shape[0]
143	        self.frame_width = frame.shape[1]
144	        self.frame_channel = frame.shape[2]
145	
146	        self.cp = self._get_coord_rad(
147	            center_point=center_point, is_center_point=True
148	        )
149	        converted_screen_coord = self._get_coord_rad(is_center_point=False)
150	        return self._bilinear_interpolation(
151	            self._calc_spherical_to_gnomonic(converted_screen_coord)
152	        )
153	
154	
155	# endregion
156	
157	
158	# region SERVER Utilities
159	class IPChecker:
160	    def __init__(self):
161	        self.ips = list(self.get_local_ips())
162	        log.debug(f&quot;Found {len(self.ips)} local ips&quot;)
163	        self.checked_ips = set()
164	
165	    def get_working_ip(self, test_url_template):
166	        for ip in self.ips:
167	            if ip not in self.checked_ips:
168	                self.checked_ips.add(ip)
169	                test_url = test_url_template.format(ip)
170	                if self._test_url(test_url):
171	                    return ip
172	        return None
173	
174	    @staticmethod
175	    def get_local_ips(prefix=&quot;192.168.&quot;):
176	        hostname = socket.gethostname()
177	        log.debug(f&quot;Getting local ips for {hostname}&quot;)
178	        for info in socket.getaddrinfo(hostname, None):
179	            # Filter out IPv6 addresses if you only want IPv4
180	            log.debug(info)
181	            # if info[1] == socket.SOCK_STREAM and
182	            if info[0] == socket.AF_INET and info[4][0].startswith(prefix):
183	                yield info[4][0]
184	
185	    def _test_url(self, url):
186	        try:
187	            response = requests.get(url)
188	            return response.status_code == 200
189	        except Exception:
190	            return False
191	
192	
193	@functools.lru_cache(maxsize=1)
194	def get_server_info():
195	    from comfy.cli_args import args
196	
197	    ip_checker = IPChecker()
198	    base_url = args.listen
199	    if base_url == &quot;0.0.0.0&quot;:
200	        log.debug(&quot;Server set to 0.0.0.0, we will try to resolve the host IP&quot;)
201	        base_url = ip_checker.get_working_ip(
202	            f&quot;http://{{}}:{args.port}/history&quot;
203	        )
204	        log.debug(f&quot;Setting ip to {base_url}&quot;)
205	    return (base_url, args.port)
206	
207	
208	# endregion
209	
210	
211	# region MISC Utilities
212	def backup_file(
213	    fp: Path,
214	    target: Optional[Path] = None,
215	    backup_dir: str = &quot;.bak&quot;,
216	    suffix: Optional[str] = None,
217	    prefix: Optional[str] = None,
218	):
219	    if not fp.exists():
220	        raise FileNotFoundError(f&quot;No file found at {fp}&quot;)
221	
222	    backup_directory = target or fp.parent / backup_dir
223	    backup_directory.mkdir(parents=True, exist_ok=True)
224	
225	    stem = fp.stem
226	
227	    if suffix or prefix:
228	        new_stem = f&quot;{prefix or &#x27;&#x27;}{stem}{suffix or &#x27;&#x27;}&quot;
229	    else:
230	        new_stem = f&quot;{stem}_{uuid.uuid4()}&quot;
231	
232	    backup_file_path = backup_directory / f&quot;{new_stem}{fp.suffix}&quot;
233	
234	    # Perform the backup
235	    shutil.copy(fp, backup_file_path)
236	    log.debug(f&quot;File backed up to {backup_file_path}&quot;)
237	
238	
239	def hex_to_rgb(hex_color):
240	    try:
241	        hex_color = hex_color.lstrip(&quot;#&quot;)
242	        return tuple(int(hex_color[i : i + 2], 16) for i in (0, 2, 4))
243	    except ValueError:
244	        log.error(f&quot;Invalid hex color: {hex_color}&quot;)
245	        return (0, 0, 0)
246	
247	
248	def add_path(path, prepend=False):
249	    if isinstance(path, list):
250	        for p in path:
251	            add_path(p, prepend)
252	        return
253	
254	    if isinstance(path, Path):
255	        path = path.resolve().as_posix()
256	
257	    if path not in sys.path:
258	        if prepend:
</pre>
</div>


</div>
</div>

<div id="issue-41">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfy_mtb/utils.py</a><br>
    <b>Line number: </b>300<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
240	    try:
241	        hex_color = hex_color.lstrip(&quot;#&quot;)
242	        return tuple(int(hex_color[i : i + 2], 16) for i in (0, 2, 4))
243	    except ValueError:
244	        log.error(f&quot;Invalid hex color: {hex_color}&quot;)
245	        return (0, 0, 0)
246	
247	
248	def add_path(path, prepend=False):
249	    if isinstance(path, list):
250	        for p in path:
251	            add_path(p, prepend)
252	        return
253	
254	    if isinstance(path, Path):
255	        path = path.resolve().as_posix()
256	
257	    if path not in sys.path:
258	        if prepend:
259	            sys.path.insert(0, path)
260	        else:
261	            sys.path.append(path)
262	
263	
264	def run_command(cmd, ignored_lines_start=None):
265	    if ignored_lines_start is None:
266	        ignored_lines_start = []
267	
268	    if isinstance(cmd, str):
269	        shell_cmd = cmd
270	    elif isinstance(cmd, list):
271	        shell_cmd = &quot; &quot;.join(
272	            arg.as_posix() if isinstance(arg, Path) else shlex.quote(str(arg))
273	            for arg in cmd
274	        )
275	    else:
276	        raise ValueError(
277	            &quot;Invalid &#x27;cmd&#x27; argument. It must be a string or a list of arguments.&quot;
278	        )
279	
280	    try:
281	        _run_command(shell_cmd, ignored_lines_start)
282	    except subprocess.CalledProcessError as e:
283	        print(
284	            f&quot;Command failed with return code: {e.returncode}&quot;, file=sys.stderr
285	        )
286	        print(e.stderr.strip(), file=sys.stderr)
287	
288	    except KeyboardInterrupt:
289	        print(&quot;Command execution interrupted.&quot;)
290	
291	
292	def _run_command(shell_cmd, ignored_lines_start):
293	    log.debug(f&quot;Running {shell_cmd}&quot;)
294	
295	    result = subprocess.run(
296	        shell_cmd,
297	        stdout=subprocess.PIPE,
298	        stderr=subprocess.PIPE,
299	        text=True,
300	        shell=True,
301	        check=True,
302	    )
303	
304	    stdout_lines = result.stdout.strip().split(&quot;\n&quot;)
305	    stderr_lines = result.stderr.strip().split(&quot;\n&quot;)
306	
307	    # Print stdout, skipping ignored lines
308	    for line in stdout_lines:
309	        if not any(line.startswith(ign) for ign in ignored_lines_start):
310	            print(line)
311	
312	    # Print stderr
313	    for line in stderr_lines:
314	        print(line, file=sys.stderr)
315	
316	    print(&quot;Command executed successfully!&quot;)
317	
318	
319	def import_install(package_name):
320	    package_spec = reqs_map.get(package_name, package_name)
321	
322	    try:
323	        importlib.import_module(package_name)
324	
325	    except Exception:  # (ImportError, ModuleNotFoundError):
326	        run_command(
327	            [
328	                Path(sys.executable).as_posix(),
329	                &quot;-m&quot;,
330	                &quot;pip&quot;,
331	                &quot;install&quot;,
332	                package_spec,
333	            ]
334	        )
335	        importlib.import_module(package_name)
336	
337	
338	# endregion
339	
340	
341	# region GLOBAL VARIABLES
342	# - detect mode
343	comfy_mode = None
344	if os.environ.get(&quot;COLAB_GPU&quot;):
345	    comfy_mode = &quot;colab&quot;
346	elif &quot;python_embeded&quot; in sys.executable:
347	    comfy_mode = &quot;embeded&quot;
348	elif &quot;.venv&quot; in sys.executable:
349	    comfy_mode = &quot;venv&quot;
350	
351	# - Get the absolute path of the parent directory of the current script
352	here = Path(__file__).parent.absolute()
353	
354	# - Construct the absolute path to the ComfyUI directory
355	comfy_dir = Path(folder_paths.base_path)
356	models_dir = Path(folder_paths.models_dir)
357	output_dir = Path(folder_paths.output_directory)
358	styles_dir = comfy_dir / &quot;styles&quot;
359	session_id = str(uuid.uuid4())
360	# - Construct the path to the font file
361	font_path = here / &quot;data&quot; / &quot;font.ttf&quot;
362	
363	# - Add extern folder to path
364	extern_root = here / &quot;extern&quot;
365	add_path(extern_root)
366	
</pre>
</div>


</div>
</div>

</div>

</body>
</html>
