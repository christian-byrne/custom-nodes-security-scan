
<!DOCTYPE html>
<html>
<head>

<meta charset="UTF-8">

<title>
    Bandit Report
</title>

<style>

html * {
    font-family: "Arial", sans-serif;
}

pre {
    font-family: "Monaco", monospace;
}

.bordered-box {
    border: 1px solid black;
    padding-top:.5em;
    padding-bottom:.5em;
    padding-left:1em;
}

.metrics-box {
    font-size: 1.1em;
    line-height: 130%;
}

.metrics-title {
    font-size: 1.5em;
    font-weight: 500;
    margin-bottom: .25em;
}

.issue-description {
    font-size: 1.3em;
    font-weight: 500;
}

.candidate-issues {
    margin-left: 2em;
    border-left: solid 1px; LightGray;
    padding-left: 5%;
    margin-top: .2em;
    margin-bottom: .2em;
}

.issue-block {
    border: 1px solid LightGray;
    padding-left: .5em;
    padding-top: .5em;
    padding-bottom: .5em;
    margin-bottom: .5em;
}

.issue-sev-high {
    background-color: Pink;
}

.issue-sev-medium {
    background-color: NavajoWhite;
}

.issue-sev-low {
    background-color: LightCyan;
}

</style>
</head>

<body>

<div id="metrics">
    <div class="metrics-box bordered-box">
        <div class="metrics-title">
            Metrics:<br>
        </div>
        Total lines of code: <span id="loc">5755</span><br>
        Total lines skipped (#nosec): <span id="nosec">0</span>
    </div>
</div>




<br>
<div id="results">
    
<div id="issue-0">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/ComfyUI-KJNodes/nodes/nodes.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/ComfyUI-KJNodes/nodes/nodes.py</a><br>
    <b>Line number: </b>1630<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
1570	   
1571	sd3 requires 6.5 credits per generation  
1572	sd3-turbo requires 4 credits per generation  
1573	
1574	If no image is provided, mode is set to text-to-image  
1575	
1576	&quot;&quot;&quot;
1577	
1578	    def apicall(self, prompt, n_prompt, model, seed, aspect_ratio, output_format, 
1579	                img2img_strength=0.5, image=None, disable_metadata=True, api_key=&quot;&quot;):
1580	        from comfy.cli_args import args
1581	        if disable_metadata:
1582	            args.disable_metadata = True
1583	        else:
1584	            args.disable_metadata = False
1585	        
1586	        import requests
1587	        from torchvision import transforms
1588	        
1589	        data = {
1590	                &quot;mode&quot;: &quot;text-to-image&quot;,
1591	                &quot;prompt&quot;: prompt,
1592	                &quot;model&quot;: model,
1593	                &quot;seed&quot;: seed,
1594	                &quot;output_format&quot;: output_format
1595	                }
1596	        
1597	        if image is not None:
1598	            image = image.permute(0, 3, 1, 2).squeeze(0)
1599	            to_pil = transforms.ToPILImage()
1600	            pil_image = to_pil(image)
1601	            # Save the PIL Image to a BytesIO object
1602	            buffer = io.BytesIO()
1603	            pil_image.save(buffer, format=&#x27;PNG&#x27;)
1604	            buffer.seek(0)
1605	            files = {&quot;image&quot;: (&quot;image.png&quot;, buffer, &quot;image/png&quot;)}
1606	           
1607	            data[&quot;mode&quot;] = &quot;image-to-image&quot;
1608	            data[&quot;image&quot;] = pil_image
1609	            data[&quot;strength&quot;] = img2img_strength
1610	        else:
1611	            data[&quot;aspect_ratio&quot;] = aspect_ratio,
1612	            files = {&quot;none&quot;: &#x27;&#x27;}
1613	        
1614	        if model != &quot;sd3-turbo&quot;:
1615	            data[&quot;negative_prompt&quot;] = n_prompt
1616	
1617	        headers={
1618	                &quot;accept&quot;: &quot;image/*&quot;
1619	            }
1620	        
1621	        if api_key != &quot;&quot;:
1622	            headers[&quot;authorization&quot;] = api_key
1623	        else:
1624	            config_file_path = os.path.join(script_directory,&quot;config.json&quot;)
1625	            with open(config_file_path, &#x27;r&#x27;) as file:
1626	                config = json.load(file)
1627	            api_key_from_config = config.get(&quot;sai_api_key&quot;)
1628	            headers[&quot;authorization&quot;] = api_key_from_config            
1629	        
1630	        response = requests.post(
1631	            f&quot;https://api.stability.ai/v2beta/stable-image/generate/sd3&quot;,
1632	            headers=headers,
1633	            files = files,
1634	            data = data,
1635	        )
1636	
1637	        if response.status_code == 200:
1638	            # Convert the response content to a PIL Image
1639	            image = Image.open(io.BytesIO(response.content))
1640	            # Convert the PIL Image to a PyTorch tensor
1641	            transform = transforms.ToTensor()
1642	            tensor_image = transform(image)
1643	            tensor_image = tensor_image.unsqueeze(0)
1644	            tensor_image = tensor_image.permute(0, 2, 3, 1).cpu().float()
1645	            return (tensor_image,)
1646	        else:
1647	            try:
1648	                # Attempt to parse the response as JSON
1649	                error_data = response.json()
1650	                raise Exception(f&quot;Server error: {error_data}&quot;)
1651	            except json.JSONDecodeError:
1652	                # If the response is not valid JSON, raise a different exception
1653	                raise Exception(f&quot;Server error: {response.text}&quot;)
1654	            
1655	class LoadICLightUnet:
1656	    @classmethod
1657	    def INPUT_TYPES(s):
1658	        return {
1659	            &quot;required&quot;: {
1660	                &quot;model&quot;: (&quot;MODEL&quot;,),
1661	                &quot;model_path&quot;: (folder_paths.get_filename_list(&quot;unet&quot;), )
1662	            } 
1663	        }
1664	
1665	    RETURN_TYPES = (&quot;MODEL&quot;,)
1666	    FUNCTION = &quot;load&quot;
1667	    CATEGORY = &quot;KJNodes/experimental&quot;
1668	    DESCRIPTION = &quot;&quot;&quot;
1669	LoadICLightUnet: Loads an ICLightUnet model. (Experimental)
1670	WORK IN PROGRESS  
1671	Very hacky (but currently working) way to load the converted IC-Light model available here:  
1672	https://huggingface.co/Kijai/iclight-comfy/blob/main/iclight_fc_converted.safetensors  
1673	
1674	Used with InstructPixToPixConditioning -node
1675	
1676	&quot;&quot;&quot;
1677	
1678	    def load(self, model, model_path):
1679	        print(&quot;LoadICLightUnet: Checking LoadICLightUnet path&quot;)
1680	        model_full_path = folder_paths.get_full_path(&quot;unet&quot;, model_path)
1681	        if not os.path.exists(model_full_path):
1682	            raise Exception(&quot;Invalid model path&quot;)
1683	        else:
1684	            print(&quot;LoadICLightUnet: Loading LoadICLightUnet weights&quot;)
1685	            from comfy.utils import load_torch_file
1686	            model_clone = model.clone()
1687	
1688	            conv_layer = model_clone.model.diffusion_model.input_blocks[0][0]
1689	            print(f&quot;Current number of input channels: {conv_layer.in_channels}&quot;)
1690	            
1691	            # Create a new Conv2d layer with 8 input channels
1692	            new_conv_layer = torch.nn.Conv2d(8, conv_layer.out_channels, kernel_size=conv_layer.kernel_size, stride=conv_layer.stride, padding=conv_layer.padding)
1693	            new_conv_layer.weight.zero_()
1694	            new_conv_layer.weight[:, :4, :, :].copy_(conv_layer.weight)
</pre>
</div>


</div>
</div>

</div>

</body>
</html>
