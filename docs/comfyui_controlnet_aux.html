
<!DOCTYPE html>
<html>
<head>

<meta charset="UTF-8">

<title>
    Bandit Report
</title>

<style>

html * {
    font-family: "Arial", sans-serif;
}

pre {
    font-family: "Monaco", monospace;
}

.bordered-box {
    border: 1px solid black;
    padding-top:.5em;
    padding-bottom:.5em;
    padding-left:1em;
}

.metrics-box {
    font-size: 1.1em;
    line-height: 130%;
}

.metrics-title {
    font-size: 1.5em;
    font-weight: 500;
    margin-bottom: .25em;
}

.issue-description {
    font-size: 1.3em;
    font-weight: 500;
}

.candidate-issues {
    margin-left: 2em;
    border-left: solid 1px; LightGray;
    padding-left: 5%;
    margin-top: .2em;
    margin-bottom: .2em;
}

.issue-block {
    border: 1px solid LightGray;
    padding-left: .5em;
    padding-top: .5em;
    padding-bottom: .5em;
    margin-bottom: .5em;
}

.issue-sev-high {
    background-color: Pink;
}

.issue-sev-medium {
    background-color: NavajoWhite;
}

.issue-sev-low {
    background-color: LightCyan;
}

</style>
</head>

<body>

<div id="metrics">
    <div class="metrics-box bordered-box">
        <div class="metrics-title">
            Metrics:<br>
        </div>
        Total lines of code: <span id="loc">183960</span><br>
        Total lines skipped (#nosec): <span id="nosec">0</span>
    </div>
</div>




<br>
<div id="results">
    
<div id="issue-0">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/mediapipe_face.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/mediapipe_face.py</a><br>
    <b>Line number: </b>4<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	from ..utils import common_annotator_call, create_node_input_types, run_script
2	import comfy.model_management as model_management
3	import os, sys
4	import subprocess, threading
5	
6	def install_deps():
7	    try:
8	        import mediapipe
9	    except ImportError:
10	        run_script([sys.executable, &#x27;-s&#x27;, &#x27;-m&#x27;, &#x27;pip&#x27;, &#x27;install&#x27;, &#x27;mediapipe&#x27;])
11	        run_script([sys.executable, &#x27;-s&#x27;, &#x27;-m&#x27;, &#x27;pip&#x27;, &#x27;install&#x27;, &#x27;--upgrade&#x27;, &#x27;protobuf&#x27;])
12	
13	class Media_Pipe_Face_Mesh_Preprocessor:
14	    @classmethod
15	    def INPUT_TYPES(s):
16	        return create_node_input_types(
17	            max_faces=(&quot;INT&quot;, {&quot;default&quot;: 10, &quot;min&quot;: 1, &quot;max&quot;: 50, &quot;step&quot;: 1}), #Which image has more than 50 detectable faces?
18	            min_confidence=(&quot;FLOAT&quot;, {&quot;default&quot;: 0.5, &quot;min&quot;: 0.01, &quot;max&quot;: 1.0, &quot;step&quot;: 0.01})
19	        )
20	        
21	    RETURN_TYPES = (&quot;IMAGE&quot;,)
22	    FUNCTION = &quot;detect&quot;
23	
24	    CATEGORY = &quot;ControlNet Preprocessors/Faces and Poses Estimators&quot;
25	
26	    def detect(self, image, max_faces, min_confidence, resolution=512):
27	        #Ref: https://github.com/Fannovel16/comfy_controlnet_preprocessors/issues/70#issuecomment-1677967369
28	        install_deps()
29	        from controlnet_aux.mediapipe_face import MediapipeFaceDetector
30	        return (common_annotator_call(MediapipeFaceDetector(), image, max_faces=max_faces, min_confidence=min_confidence, resolution=resolution), )
31	
32	NODE_CLASS_MAPPINGS = {
33	    &quot;MediaPipe-FaceMeshPreprocessor&quot;: Media_Pipe_Face_Mesh_Preprocessor
34	}
35	
36	NODE_DISPLAY_NAME_MAPPINGS = {
37	    &quot;MediaPipe-FaceMeshPreprocessor&quot;: &quot;MediaPipe Face Mesh&quot;
38	}
</pre>
</div>


</div>
</div>

<div id="issue-1">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/mesh_graphormer.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/mesh_graphormer.py</a><br>
    <b>Line number: </b>7<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	from ..utils import common_annotator_call, create_node_input_types, MAX_RESOLUTION, run_script
2	import comfy.model_management as model_management
3	import numpy as np
4	import torch
5	from einops import rearrange
6	import os, sys
7	import subprocess, threading
8	import scipy.ndimage
9	import cv2
10	import torch.nn.functional as F
11	
12	def install_deps():
13	    try:
14	        import mediapipe
15	    except ImportError:
16	        run_script([sys.executable, &#x27;-s&#x27;, &#x27;-m&#x27;, &#x27;pip&#x27;, &#x27;install&#x27;, &#x27;mediapipe&#x27;])
17	        run_script([sys.executable, &#x27;-s&#x27;, &#x27;-m&#x27;, &#x27;pip&#x27;, &#x27;install&#x27;, &#x27;--upgrade&#x27;, &#x27;protobuf&#x27;])
18	    
19	    try:
20	        import trimesh
21	    except ImportError:
22	        run_script([sys.executable, &#x27;-s&#x27;, &#x27;-m&#x27;, &#x27;pip&#x27;, &#x27;install&#x27;, &#x27;trimesh[easy]&#x27;])
23	
24	#Sauce: https://github.com/comfyanonymous/ComfyUI/blob/8c6493578b3dda233e9b9a953feeaf1e6ca434ad/comfy_extras/nodes_mask.py#L309
25	def expand_mask(mask, expand, tapered_corners):
26	    c = 0 if tapered_corners else 1
27	    kernel = np.array([[c, 1, c],
28	                        [1, 1, 1],
29	                        [c, 1, c]])
30	    mask = mask.reshape((-1, mask.shape[-2], mask.shape[-1]))
31	    out = []
32	    for m in mask:
33	        output = m.numpy()
34	        for _ in range(abs(expand)):
35	            if expand &lt; 0:
36	                output = scipy.ndimage.grey_erosion(output, footprint=kernel)
37	            else:
38	                output = scipy.ndimage.grey_dilation(output, footprint=kernel)
39	        output = torch.from_numpy(output)
40	        out.append(output)
41	    return torch.stack(out, dim=0)
42	
43	class Mesh_Graphormer_Depth_Map_Preprocessor:
44	    @classmethod
45	    def INPUT_TYPES(s):
46	        types = create_node_input_types(mask_bbox_padding=(&quot;INT&quot;, {&quot;default&quot;: 30, &quot;min&quot;: 0, &quot;max&quot;: 100}))
47	        types[&quot;optional&quot;].update(
48	            {
49	                &quot;mask_type&quot;: ([&quot;based_on_depth&quot;, &quot;tight_bboxes&quot;, &quot;original&quot;], {&quot;default&quot;: &quot;based_on_depth&quot;}),
50	                &quot;mask_expand&quot;: (&quot;INT&quot;, {&quot;default&quot;: 5, &quot;min&quot;: -MAX_RESOLUTION, &quot;max&quot;: MAX_RESOLUTION, &quot;step&quot;: 1}),
51	                &quot;rand_seed&quot;: (&quot;INT&quot;, {&quot;default&quot;: 88, &quot;min&quot;: 0, &quot;max&quot;: 0xffffffffffffffff}),
52	                &quot;detect_thr&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 0.6, &quot;min&quot;: 0, &quot;max&quot;: 1, &quot;step&quot;: 0.01}),
53	                &quot;presence_thr&quot;: (&quot;FLOAT&quot;, {&quot;default&quot;: 0.6, &quot;min&quot;: 0, &quot;max&quot;: 1, &quot;step&quot;: 0.01}),
54	            }
55	        )
56	        return types
57	
58	    RETURN_TYPES = (&quot;IMAGE&quot;, &quot;MASK&quot;)
59	    RETURN_NAMES = (&quot;IMAGE&quot;, &quot;INPAINTING_MASK&quot;)
60	    FUNCTION = &quot;execute&quot;
61	
62	    CATEGORY = &quot;ControlNet Preprocessors/Normal and Depth Estimators&quot;
63	
64	    def execute(self, image, mask_bbox_padding=30, mask_type=&quot;based_on_depth&quot;, mask_expand=5, resolution=512, rand_seed=88, detect_thr=0.6, presence_thr=0.6, **kwargs):
65	        install_deps()
66	        from controlnet_aux.mesh_graphormer import MeshGraphormerDetector
67	        model = kwargs[&quot;model&quot;] if &quot;model&quot; in kwargs \
68	            else MeshGraphormerDetector.from_pretrained(detect_thr=detect_thr, presence_thr=presence_thr).to(model_management.get_torch_device())
69	        
70	        depth_map_list = []
71	        mask_list = []
72	        for single_image in image:
73	            np_image = np.asarray(single_image.cpu() * 255., dtype=np.uint8)
74	            depth_map, mask, info = model(np_image, output_type=&quot;np&quot;, detect_resolution=resolution, mask_bbox_padding=mask_bbox_padding, seed=rand_seed)
75	            if mask_type == &quot;based_on_depth&quot;:
76	                H, W = mask.shape[:2]
77	                mask = cv2.resize(depth_map.copy(), (W, H))
78	                mask[mask &gt; 0] = 255
79	
80	            elif mask_type == &quot;tight_bboxes&quot;:
81	                mask = np.zeros_like(mask)
82	                hand_bboxes = info[&quot;abs_boxes&quot;]
83	                for hand_bbox in hand_bboxes: 
84	                    x_min, x_max, y_min, y_max = hand_bbox
85	                    mask[y_min:y_max+1, x_min:x_max+1, :] = 255 #HWC
86	
87	            mask = mask[:, :, :1]
88	            depth_map_list.append(torch.from_numpy(depth_map.astype(np.float32) / 255.0))
89	            mask_list.append(torch.from_numpy(mask.astype(np.float32) / 255.0))
90	        depth_maps, masks = torch.stack(depth_map_list, dim=0), rearrange(torch.stack(mask_list, dim=0), &quot;n h w 1 -&gt; n 1 h w&quot;)
91	        return depth_maps, expand_mask(masks, mask_expand, tapered_corners=True)
92	
93	def normalize_size_base_64(w, h):
94	    short_side = min(w, h)
95	    remainder = short_side % 64
96	    return short_side - remainder + (64 if remainder &gt; 0 else 0)
97	
98	class Mesh_Graphormer_With_ImpactDetector_Depth_Map_Preprocessor:
99	    @classmethod
100	    def INPUT_TYPES(s):
101	        types = create_node_input_types(
102	            # Impact pack
103	            bbox_threshold=(&quot;FLOAT&quot;, {&quot;default&quot;: 0.5, &quot;min&quot;: 0.0, &quot;max&quot;: 1.0, &quot;step&quot;: 0.01}),
104	            bbox_dilation=(&quot;INT&quot;, {&quot;default&quot;: 10, &quot;min&quot;: -512, &quot;max&quot;: 512, &quot;step&quot;: 1}),
105	            bbox_crop_factor=(&quot;FLOAT&quot;, {&quot;default&quot;: 3.0, &quot;min&quot;: 1.0, &quot;max&quot;: 10, &quot;step&quot;: 0.1}),
106	            drop_size=(&quot;INT&quot;, {&quot;min&quot;: 1, &quot;max&quot;: MAX_RESOLUTION, &quot;step&quot;: 1, &quot;default&quot;: 10}),
107	            # Mesh Graphormer
108	            mask_bbox_padding=(&quot;INT&quot;, {&quot;default&quot;: 30, &quot;min&quot;: 0, &quot;max&quot;: 100}),
109	            mask_type=([&quot;based_on_depth&quot;, &quot;tight_bboxes&quot;, &quot;original&quot;], {&quot;default&quot;: &quot;based_on_depth&quot;}),
110	            mask_expand=(&quot;INT&quot;, {&quot;default&quot;: 5, &quot;min&quot;: -MAX_RESOLUTION, &quot;max&quot;: MAX_RESOLUTION, &quot;step&quot;: 1}),
111	            rand_seed=(&quot;INT&quot;, {&quot;default&quot;: 88, &quot;min&quot;: 0, &quot;max&quot;: 0xffffffffffffffff}),
112	        )
113	        types[&quot;required&quot;][&quot;bbox_detector&quot;] = (&quot;BBOX_DETECTOR&quot;, )
114	        return types
115	     
116	    RETURN_TYPES = (&quot;IMAGE&quot;, &quot;MASK&quot;)
117	    RETURN_NAMES = (&quot;IMAGE&quot;, &quot;INPAINTING_MASK&quot;)
118	    FUNCTION = &quot;execute&quot;
119	
120	    CATEGORY = &quot;ControlNet Preprocessors/Normal and Depth Estimators&quot;
</pre>
</div>


</div>
</div>

<div id="issue-2">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py</a><br>
    <b>Line number: </b>10<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) Meta Platforms, Inc. and affiliates.
2	# All rights reserved.
3	#
4	# This source code is licensed under the license found in the
5	# LICENSE file in the root directory of this source tree.
6	
7	import logging
8	import os
9	import random
10	import subprocess
11	from urllib.parse import urlparse
12	
13	import numpy as np
14	import torch
15	from torch import nn
16	
17	
18	logger = logging.getLogger(&quot;dinov2&quot;)
19	
20	
21	def load_pretrained_weights(model, pretrained_weights, checkpoint_key):
22	    if urlparse(pretrained_weights).scheme:  # If it looks like an URL
23	        state_dict = torch.hub.load_state_dict_from_url(pretrained_weights, map_location=&quot;cpu&quot;)
24	    else:
25	        state_dict = torch.load(pretrained_weights, map_location=&quot;cpu&quot;)
26	    if checkpoint_key is not None and checkpoint_key in state_dict:
27	        logger.info(f&quot;Take key {checkpoint_key} in provided checkpoint dict&quot;)
28	        state_dict = state_dict[checkpoint_key]
29	    # remove `module.` prefix
30	    state_dict = {k.replace(&quot;module.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
31	    # remove `backbone.` prefix induced by multicrop wrapper
32	    state_dict = {k.replace(&quot;backbone.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
33	    msg = model.load_state_dict(state_dict, strict=False)
34	    logger.info(&quot;Pretrained weights found at {} and loaded with msg: {}&quot;.format(pretrained_weights, msg))
35	
36	
37	def fix_random_seeds(seed=31):
38	    &quot;&quot;&quot;
39	    Fix random seeds.
40	    &quot;&quot;&quot;
41	    torch.manual_seed(seed)
42	    torch.cuda.manual_seed_all(seed)
43	    np.random.seed(seed)
44	    random.seed(seed)
45	
46	
47	def get_sha():
48	    cwd = os.path.dirname(os.path.abspath(__file__))
49	
50	    def _run(command):
51	        return subprocess.check_output(command, cwd=cwd).decode(&quot;ascii&quot;).strip()
52	
53	    sha = &quot;N/A&quot;
54	    diff = &quot;clean&quot;
55	    branch = &quot;N/A&quot;
56	    try:
57	        sha = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;HEAD&quot;])
58	        subprocess.check_output([&quot;git&quot;, &quot;diff&quot;], cwd=cwd)
59	        diff = _run([&quot;git&quot;, &quot;diff-index&quot;, &quot;HEAD&quot;])
60	        diff = &quot;has uncommitted changes&quot; if diff else &quot;clean&quot;
61	        branch = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;--abbrev-ref&quot;, &quot;HEAD&quot;])
62	    except Exception:
63	        pass
64	    message = f&quot;sha: {sha}, status: {diff}, branch: {branch}&quot;
65	    return message
66	
67	
68	class CosineScheduler(object):
69	    def __init__(self, base_value, final_value, total_iters, warmup_iters=0, start_warmup_value=0, freeze_iters=0):
70	        super().__init__()
71	        self.final_value = final_value
72	        self.total_iters = total_iters
73	
74	        freeze_schedule = np.zeros((freeze_iters))
75	
76	        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)
77	
78	        iters = np.arange(total_iters - warmup_iters - freeze_iters)
79	        schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))
80	        self.schedule = np.concatenate((freeze_schedule, warmup_schedule, schedule))
81	
82	        assert len(self.schedule) == self.total_iters
83	
84	    def __getitem__(self, it):
85	        if it &gt;= self.total_iters:
86	            return self.final_value
87	        else:
88	            return self.schedule[it]
89	
90	
91	def has_batchnorms(model):
92	    bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)
93	    for name, module in model.named_modules():
94	        if isinstance(module, bn_types):
95	            return True
96	    return False
</pre>
</div>


</div>
</div>

<div id="issue-3">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py</a><br>
    <b>Line number: </b>51<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) Meta Platforms, Inc. and affiliates.
2	# All rights reserved.
3	#
4	# This source code is licensed under the license found in the
5	# LICENSE file in the root directory of this source tree.
6	
7	import logging
8	import os
9	import random
10	import subprocess
11	from urllib.parse import urlparse
12	
13	import numpy as np
14	import torch
15	from torch import nn
16	
17	
18	logger = logging.getLogger(&quot;dinov2&quot;)
19	
20	
21	def load_pretrained_weights(model, pretrained_weights, checkpoint_key):
22	    if urlparse(pretrained_weights).scheme:  # If it looks like an URL
23	        state_dict = torch.hub.load_state_dict_from_url(pretrained_weights, map_location=&quot;cpu&quot;)
24	    else:
25	        state_dict = torch.load(pretrained_weights, map_location=&quot;cpu&quot;)
26	    if checkpoint_key is not None and checkpoint_key in state_dict:
27	        logger.info(f&quot;Take key {checkpoint_key} in provided checkpoint dict&quot;)
28	        state_dict = state_dict[checkpoint_key]
29	    # remove `module.` prefix
30	    state_dict = {k.replace(&quot;module.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
31	    # remove `backbone.` prefix induced by multicrop wrapper
32	    state_dict = {k.replace(&quot;backbone.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
33	    msg = model.load_state_dict(state_dict, strict=False)
34	    logger.info(&quot;Pretrained weights found at {} and loaded with msg: {}&quot;.format(pretrained_weights, msg))
35	
36	
37	def fix_random_seeds(seed=31):
38	    &quot;&quot;&quot;
39	    Fix random seeds.
40	    &quot;&quot;&quot;
41	    torch.manual_seed(seed)
42	    torch.cuda.manual_seed_all(seed)
43	    np.random.seed(seed)
44	    random.seed(seed)
45	
46	
47	def get_sha():
48	    cwd = os.path.dirname(os.path.abspath(__file__))
49	
50	    def _run(command):
51	        return subprocess.check_output(command, cwd=cwd).decode(&quot;ascii&quot;).strip()
52	
53	    sha = &quot;N/A&quot;
54	    diff = &quot;clean&quot;
55	    branch = &quot;N/A&quot;
56	    try:
57	        sha = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;HEAD&quot;])
58	        subprocess.check_output([&quot;git&quot;, &quot;diff&quot;], cwd=cwd)
59	        diff = _run([&quot;git&quot;, &quot;diff-index&quot;, &quot;HEAD&quot;])
60	        diff = &quot;has uncommitted changes&quot; if diff else &quot;clean&quot;
61	        branch = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;--abbrev-ref&quot;, &quot;HEAD&quot;])
62	    except Exception:
63	        pass
64	    message = f&quot;sha: {sha}, status: {diff}, branch: {branch}&quot;
65	    return message
66	
67	
68	class CosineScheduler(object):
69	    def __init__(self, base_value, final_value, total_iters, warmup_iters=0, start_warmup_value=0, freeze_iters=0):
70	        super().__init__()
71	        self.final_value = final_value
72	        self.total_iters = total_iters
73	
74	        freeze_schedule = np.zeros((freeze_iters))
75	
76	        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)
77	
78	        iters = np.arange(total_iters - warmup_iters - freeze_iters)
79	        schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))
80	        self.schedule = np.concatenate((freeze_schedule, warmup_schedule, schedule))
81	
82	        assert len(self.schedule) == self.total_iters
83	
84	    def __getitem__(self, it):
85	        if it &gt;= self.total_iters:
86	            return self.final_value
87	        else:
88	            return self.schedule[it]
89	
90	
91	def has_batchnorms(model):
92	    bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)
93	    for name, module in model.named_modules():
94	        if isinstance(module, bn_types):
95	            return True
96	    return False
</pre>
</div>


</div>
</div>

<div id="issue-4">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py</a><br>
    <b>Line number: </b>58<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) Meta Platforms, Inc. and affiliates.
2	# All rights reserved.
3	#
4	# This source code is licensed under the license found in the
5	# LICENSE file in the root directory of this source tree.
6	
7	import logging
8	import os
9	import random
10	import subprocess
11	from urllib.parse import urlparse
12	
13	import numpy as np
14	import torch
15	from torch import nn
16	
17	
18	logger = logging.getLogger(&quot;dinov2&quot;)
19	
20	
21	def load_pretrained_weights(model, pretrained_weights, checkpoint_key):
22	    if urlparse(pretrained_weights).scheme:  # If it looks like an URL
23	        state_dict = torch.hub.load_state_dict_from_url(pretrained_weights, map_location=&quot;cpu&quot;)
24	    else:
25	        state_dict = torch.load(pretrained_weights, map_location=&quot;cpu&quot;)
26	    if checkpoint_key is not None and checkpoint_key in state_dict:
27	        logger.info(f&quot;Take key {checkpoint_key} in provided checkpoint dict&quot;)
28	        state_dict = state_dict[checkpoint_key]
29	    # remove `module.` prefix
30	    state_dict = {k.replace(&quot;module.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
31	    # remove `backbone.` prefix induced by multicrop wrapper
32	    state_dict = {k.replace(&quot;backbone.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
33	    msg = model.load_state_dict(state_dict, strict=False)
34	    logger.info(&quot;Pretrained weights found at {} and loaded with msg: {}&quot;.format(pretrained_weights, msg))
35	
36	
37	def fix_random_seeds(seed=31):
38	    &quot;&quot;&quot;
39	    Fix random seeds.
40	    &quot;&quot;&quot;
41	    torch.manual_seed(seed)
42	    torch.cuda.manual_seed_all(seed)
43	    np.random.seed(seed)
44	    random.seed(seed)
45	
46	
47	def get_sha():
48	    cwd = os.path.dirname(os.path.abspath(__file__))
49	
50	    def _run(command):
51	        return subprocess.check_output(command, cwd=cwd).decode(&quot;ascii&quot;).strip()
52	
53	    sha = &quot;N/A&quot;
54	    diff = &quot;clean&quot;
55	    branch = &quot;N/A&quot;
56	    try:
57	        sha = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;HEAD&quot;])
58	        subprocess.check_output([&quot;git&quot;, &quot;diff&quot;], cwd=cwd)
59	        diff = _run([&quot;git&quot;, &quot;diff-index&quot;, &quot;HEAD&quot;])
60	        diff = &quot;has uncommitted changes&quot; if diff else &quot;clean&quot;
61	        branch = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;--abbrev-ref&quot;, &quot;HEAD&quot;])
62	    except Exception:
63	        pass
64	    message = f&quot;sha: {sha}, status: {diff}, branch: {branch}&quot;
65	    return message
66	
67	
68	class CosineScheduler(object):
69	    def __init__(self, base_value, final_value, total_iters, warmup_iters=0, start_warmup_value=0, freeze_iters=0):
70	        super().__init__()
71	        self.final_value = final_value
72	        self.total_iters = total_iters
73	
74	        freeze_schedule = np.zeros((freeze_iters))
75	
76	        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)
77	
78	        iters = np.arange(total_iters - warmup_iters - freeze_iters)
79	        schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))
80	        self.schedule = np.concatenate((freeze_schedule, warmup_schedule, schedule))
81	
82	        assert len(self.schedule) == self.total_iters
83	
84	    def __getitem__(self, it):
85	        if it &gt;= self.total_iters:
86	            return self.final_value
87	        else:
88	            return self.schedule[it]
89	
90	
91	def has_batchnorms(model):
92	    bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)
93	    for name, module in model.named_modules():
94	        if isinstance(module, bn_types):
95	            return True
96	    return False
</pre>
</div>


</div>
</div>

<div id="issue-5">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py</a><br>
    <b>Line number: </b>58<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) Meta Platforms, Inc. and affiliates.
2	# All rights reserved.
3	#
4	# This source code is licensed under the license found in the
5	# LICENSE file in the root directory of this source tree.
6	
7	import logging
8	import os
9	import random
10	import subprocess
11	from urllib.parse import urlparse
12	
13	import numpy as np
14	import torch
15	from torch import nn
16	
17	
18	logger = logging.getLogger(&quot;dinov2&quot;)
19	
20	
21	def load_pretrained_weights(model, pretrained_weights, checkpoint_key):
22	    if urlparse(pretrained_weights).scheme:  # If it looks like an URL
23	        state_dict = torch.hub.load_state_dict_from_url(pretrained_weights, map_location=&quot;cpu&quot;)
24	    else:
25	        state_dict = torch.load(pretrained_weights, map_location=&quot;cpu&quot;)
26	    if checkpoint_key is not None and checkpoint_key in state_dict:
27	        logger.info(f&quot;Take key {checkpoint_key} in provided checkpoint dict&quot;)
28	        state_dict = state_dict[checkpoint_key]
29	    # remove `module.` prefix
30	    state_dict = {k.replace(&quot;module.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
31	    # remove `backbone.` prefix induced by multicrop wrapper
32	    state_dict = {k.replace(&quot;backbone.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
33	    msg = model.load_state_dict(state_dict, strict=False)
34	    logger.info(&quot;Pretrained weights found at {} and loaded with msg: {}&quot;.format(pretrained_weights, msg))
35	
36	
37	def fix_random_seeds(seed=31):
38	    &quot;&quot;&quot;
39	    Fix random seeds.
40	    &quot;&quot;&quot;
41	    torch.manual_seed(seed)
42	    torch.cuda.manual_seed_all(seed)
43	    np.random.seed(seed)
44	    random.seed(seed)
45	
46	
47	def get_sha():
48	    cwd = os.path.dirname(os.path.abspath(__file__))
49	
50	    def _run(command):
51	        return subprocess.check_output(command, cwd=cwd).decode(&quot;ascii&quot;).strip()
52	
53	    sha = &quot;N/A&quot;
54	    diff = &quot;clean&quot;
55	    branch = &quot;N/A&quot;
56	    try:
57	        sha = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;HEAD&quot;])
58	        subprocess.check_output([&quot;git&quot;, &quot;diff&quot;], cwd=cwd)
59	        diff = _run([&quot;git&quot;, &quot;diff-index&quot;, &quot;HEAD&quot;])
60	        diff = &quot;has uncommitted changes&quot; if diff else &quot;clean&quot;
61	        branch = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;--abbrev-ref&quot;, &quot;HEAD&quot;])
62	    except Exception:
63	        pass
64	    message = f&quot;sha: {sha}, status: {diff}, branch: {branch}&quot;
65	    return message
66	
67	
68	class CosineScheduler(object):
69	    def __init__(self, base_value, final_value, total_iters, warmup_iters=0, start_warmup_value=0, freeze_iters=0):
70	        super().__init__()
71	        self.final_value = final_value
72	        self.total_iters = total_iters
73	
74	        freeze_schedule = np.zeros((freeze_iters))
75	
76	        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)
77	
78	        iters = np.arange(total_iters - warmup_iters - freeze_iters)
79	        schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))
80	        self.schedule = np.concatenate((freeze_schedule, warmup_schedule, schedule))
81	
82	        assert len(self.schedule) == self.total_iters
83	
84	    def __getitem__(self, it):
85	        if it &gt;= self.total_iters:
86	            return self.final_value
87	        else:
88	            return self.schedule[it]
89	
90	
91	def has_batchnorms(model):
92	    bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)
93	    for name, module in model.named_modules():
94	        if isinstance(module, bn_types):
95	            return True
96	    return False
</pre>
</div>


</div>
</div>

<div id="issue-6">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/depth_anything/torchhub/facebookresearch_dinov2_main/dinov2/utils/utils.py</a><br>
    <b>Line number: </b>62<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
2	# All rights reserved.
3	#
4	# This source code is licensed under the license found in the
5	# LICENSE file in the root directory of this source tree.
6	
7	import logging
8	import os
9	import random
10	import subprocess
11	from urllib.parse import urlparse
12	
13	import numpy as np
14	import torch
15	from torch import nn
16	
17	
18	logger = logging.getLogger(&quot;dinov2&quot;)
19	
20	
21	def load_pretrained_weights(model, pretrained_weights, checkpoint_key):
22	    if urlparse(pretrained_weights).scheme:  # If it looks like an URL
23	        state_dict = torch.hub.load_state_dict_from_url(pretrained_weights, map_location=&quot;cpu&quot;)
24	    else:
25	        state_dict = torch.load(pretrained_weights, map_location=&quot;cpu&quot;)
26	    if checkpoint_key is not None and checkpoint_key in state_dict:
27	        logger.info(f&quot;Take key {checkpoint_key} in provided checkpoint dict&quot;)
28	        state_dict = state_dict[checkpoint_key]
29	    # remove `module.` prefix
30	    state_dict = {k.replace(&quot;module.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
31	    # remove `backbone.` prefix induced by multicrop wrapper
32	    state_dict = {k.replace(&quot;backbone.&quot;, &quot;&quot;): v for k, v in state_dict.items()}
33	    msg = model.load_state_dict(state_dict, strict=False)
34	    logger.info(&quot;Pretrained weights found at {} and loaded with msg: {}&quot;.format(pretrained_weights, msg))
35	
36	
37	def fix_random_seeds(seed=31):
38	    &quot;&quot;&quot;
39	    Fix random seeds.
40	    &quot;&quot;&quot;
41	    torch.manual_seed(seed)
42	    torch.cuda.manual_seed_all(seed)
43	    np.random.seed(seed)
44	    random.seed(seed)
45	
46	
47	def get_sha():
48	    cwd = os.path.dirname(os.path.abspath(__file__))
49	
50	    def _run(command):
51	        return subprocess.check_output(command, cwd=cwd).decode(&quot;ascii&quot;).strip()
52	
53	    sha = &quot;N/A&quot;
54	    diff = &quot;clean&quot;
55	    branch = &quot;N/A&quot;
56	    try:
57	        sha = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;HEAD&quot;])
58	        subprocess.check_output([&quot;git&quot;, &quot;diff&quot;], cwd=cwd)
59	        diff = _run([&quot;git&quot;, &quot;diff-index&quot;, &quot;HEAD&quot;])
60	        diff = &quot;has uncommitted changes&quot; if diff else &quot;clean&quot;
61	        branch = _run([&quot;git&quot;, &quot;rev-parse&quot;, &quot;--abbrev-ref&quot;, &quot;HEAD&quot;])
62	    except Exception:
63	        pass
64	    message = f&quot;sha: {sha}, status: {diff}, branch: {branch}&quot;
65	    return message
66	
67	
68	class CosineScheduler(object):
69	    def __init__(self, base_value, final_value, total_iters, warmup_iters=0, start_warmup_value=0, freeze_iters=0):
70	        super().__init__()
71	        self.final_value = final_value
72	        self.total_iters = total_iters
73	
74	        freeze_schedule = np.zeros((freeze_iters))
75	
76	        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_iters)
77	
78	        iters = np.arange(total_iters - warmup_iters - freeze_iters)
79	        schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))
80	        self.schedule = np.concatenate((freeze_schedule, warmup_schedule, schedule))
81	
82	        assert len(self.schedule) == self.total_iters
83	
84	    def __getitem__(self, it):
85	        if it &gt;= self.total_iters:
86	            return self.final_value
87	        else:
88	            return self.schedule[it]
89	
90	
91	def has_batchnorms(model):
92	    bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)
93	    for name, module in model.named_modules():
94	        if isinstance(module, bn_types):
95	            return True
96	    return False
</pre>
</div>


</div>
</div>

<div id="issue-7">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/data.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/data.py</a><br>
    <b>Line number: </b>16<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	import torch
2	import torchvision.transforms as T
3	import torch.utils.data as data
4	import torch.nn as nn
5	from pathlib import Path
6	from functools import partial
7	from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.utils import exists, convert_image_to_fn, normalize_to_neg_one_to_one
8	from PIL import Image, ImageDraw
9	import torch.nn.functional as F
10	import math
11	import torchvision.transforms.functional as F2
12	import torchvision.transforms as transforms
13	import torchvision.datasets as datasets
14	from typing import Any, Callable, Optional, Tuple
15	import os
16	import pickle
17	import numpy as np
18	import copy
19	import custom_albumentations as albumentations
20	from torchvision.transforms.functional import InterpolationMode
21	
22	def get_imgs_list(imgs_dir):
23	    imgs_list = os.listdir(imgs_dir)
24	    imgs_list.sort()
25	    return [os.path.join(imgs_dir, f) for f in imgs_list if f.endswith(&#x27;.jpg&#x27;) or f.endswith(&#x27;.JPG&#x27;)or f.endswith(&#x27;.png&#x27;) or f.endswith(&#x27;.pgm&#x27;) or f.endswith(&#x27;.ppm&#x27;)]
26	
27	
28	def fit_img_postfix(img_path):
29	    if not os.path.exists(img_path) and img_path.endswith(&quot;.jpg&quot;):
30	        img_path = img_path[:-4] + &quot;.png&quot;
31	    if not os.path.exists(img_path) and img_path.endswith(&quot;.png&quot;):
32	        img_path = img_path[:-4] + &quot;.jpg&quot;
33	    return img_path
34	
35	
36	class AdaptEdgeDataset(data.Dataset):
37	    def __init__(
38	        self,
39	        data_root,
40	        # mask_folder,
41	        image_size,
42	        exts = [&#x27;png&#x27;, &#x27;jpg&#x27;],
43	        augment_horizontal_flip = False,
44	        convert_image_to = None,
45	        normalize_to_neg_one_to_one=True,
46	        split=&#x27;train&#x27;,
47	        # inter_type=&#x27;bicubic&#x27;,
48	        # down=4,
49	        threshold=0.3, use_uncertainty=False
50	    ):
51	        super().__init__()
52	        # self.img_folder = Path(img_folder)
53	        # self.edge_folder = Path(os.path.join(data_root, f&#x27;gt_imgs&#x27;))
54	        # self.img_folder = Path(os.path.join(data_root, f&#x27;imgs&#x27;))
55	        # self.edge_folder = Path(os.path.join(data_root, &quot;edge&quot;, &quot;aug&quot;))
56	        # self.img_folder = Path(os.path.join(data_root, &quot;image&quot;, &quot;aug&quot;))
57	        self.data_root = data_root
58	        self.image_size = image_size
59	
60	        # self.edge_paths = [p for ext in exts for p in self.edge_folder.rglob(f&#x27;*.{ext}&#x27;)]
61	        # self.img_paths = [(self.img_folder / item.parent.name / f&#x27;{item.stem}.jpg&#x27;) for item in self.edge_paths]
62	        # self.img_paths = [(self.img_folder / f&#x27;{item.stem}.jpg&#x27;) for item in self.edge_paths]
63	
64	        self.threshold = threshold * 256
65	        self.use_uncertainty = use_uncertainty
66	        self.normalize_to_neg_one_to_one = normalize_to_neg_one_to_one
67	
68	        maybe_convert_fn = partial(convert_image_to_fn, convert_image_to) if exists(convert_image_to) else Identity()
69	
70	        # self.normalize_to_neg_one_to_one = normalize_to_neg_one_to_one
71	        # self.random_crop = RandomCrop(size=image_size)
72	        # self.transform = Compose([
73	        #     # Lambda(maybe_convert_fn),
74	        #     # Resize(image_size, interpolation=3, interpolation2=0),
75	        #     Resize(image_size, interpolation=InterpolationMode.BILINEAR, interpolation2=InterpolationMode.NEAREST),
76	        #     RandomHorizontalFlip() if augment_horizontal_flip else Identity(),
77	        #     # RandomCrop(image_size),
78	        #     ToTensor()
79	        # ])
80	        self.data_list = self.build_list()
81	
82	        self.transform = transforms.Compose([
83	            # Resize(self.image_size, interpolation=InterpolationMode.BILINEAR, interpolation2=InterpolationMode.NEAREST),
84	            transforms.ToTensor()])
85	
86	    def __len__(self):
87	        return len(self.data_list)
88	
89	
90	    def read_img(self, image_path):
91	        with open(image_path, &#x27;rb&#x27;) as f:
92	            img = Image.open(f)
93	            img = img.convert(&#x27;RGB&#x27;)
94	
95	        raw_width, raw_height = img.size
96	        # width = int(raw_width / 32) * 32
97	        # height = int(raw_height / 32) * 32
98	        # img = img.resize((width, height), Image.Resampling.BILINEAR)
99	        # # print(&quot;img.size:&quot;, img.size)
100	        # img = self.transform(img)
101	
102	        return img, (raw_width, raw_height)
103	
104	    def read_lb(self, lb_path):
105	        lb_data = Image.open(lb_path)
106	
107	        width, height = lb_data.size
108	        width = int(width / 32) * 32
109	        height = int(height / 32) * 32
110	        lb_data = lb_data.resize((width, height), Image.Resampling.BILINEAR)
111	        # print(&quot;lb_data.size:&quot;, lb_data.size)
112	        lb = np.array(lb_data, dtype=np.float32)
113	        if lb.ndim == 3:
114	            lb = np.squeeze(lb[:, :, 0])
115	        assert lb.ndim == 2
116	        threshold = self.threshold
117	        lb = lb[np.newaxis, :, :]
118	
119	        lb[lb == 0] = 0
120	
</pre>
</div>


</div>
</div>

<div id="issue-8">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>1<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	import os, yaml, pickle, shutil, tarfile, glob
2	import cv2
3	import custom_albumentations as albumentations
4	import PIL
5	import numpy as np
6	import torchvision.transforms.functional as TF
7	# from omegaconf import OmegaConf
8	from functools import partial
9	from PIL import Image
10	from tqdm import tqdm
11	from torch.utils.data import Dataset, Subset
12	
13	import taming.data.utils as tdu
14	from controlnet_aux.diffusion_edge.taming.data.imagenet import str_to_indices, give_synsets_from_indices, download, retrieve
15	from controlnet_aux.diffusion_edge.taming.data.imagenet import ImagePaths
16	
17	# from ldm.modules.image_degradation import degradation_fn_bsr, degradation_fn_bsr_light
18	
19	
20	def synset2idx(path_to_yaml=&quot;data/index_synset.yaml&quot;):
21	    with open(path_to_yaml) as f:
22	        di2s = yaml.load(f)
23	    return dict((v,k) for k,v in di2s.items())
24	
25	
26	class ImageNetBase(Dataset):
27	    def __init__(self, config=None):
28	        self.config = config
29	        # if not type(self.config)==dict:
30	        #     self.config = OmegaConf.to_container(self.config)
31	        self.keep_orig_class_label = self.config.get(&quot;keep_orig_class_label&quot;, False)
32	        self.process_images = True  # if False we skip loading &amp; processing images and self.data contains filepaths
33	        self._prepare()
34	        self._prepare_synset_to_human()
35	        self._prepare_idx_to_synset()
36	        self._prepare_human_to_integer_label()
37	        self._load()
38	
39	    def __len__(self):
40	        return len(self.data)
41	
42	    def __getitem__(self, i):
43	        return self.data[i]
44	
45	    def _prepare(self):
46	        raise NotImplementedError()
47	
48	    def _filter_relpaths(self, relpaths):
49	        ignore = set([
50	            &quot;n06596364_9591.JPEG&quot;,
51	        ])
52	        relpaths = [rpath for rpath in relpaths if not rpath.split(&quot;/&quot;)[-1] in ignore]
53	        if &quot;sub_indices&quot; in self.config:
54	            indices = str_to_indices(self.config[&quot;sub_indices&quot;])
55	            synsets = give_synsets_from_indices(indices, path_to_yaml=self.idx2syn)  # returns a list of strings
56	            self.synset2idx = synset2idx(path_to_yaml=self.idx2syn)
57	            files = []
58	            for rpath in relpaths:
59	                syn = rpath.split(&quot;/&quot;)[0]
60	                if syn in synsets:
61	                    files.append(rpath)
62	            return files
63	        else:
64	            return relpaths
65	
66	    def _prepare_synset_to_human(self):
67	        SIZE = 2655750
68	        URL = &quot;https://heibox.uni-heidelberg.de/f/9f28e956cd304264bb82/?dl=1&quot;
69	        self.human_dict = os.path.join(self.root, &quot;synset_human.txt&quot;)
70	        if (not os.path.exists(self.human_dict) or
71	                not os.path.getsize(self.human_dict)==SIZE):
72	            download(URL, self.human_dict)
73	
74	    def _prepare_idx_to_synset(self):
75	        URL = &quot;https://heibox.uni-heidelberg.de/f/d835d5b6ceda4d3aa910/?dl=1&quot;
76	        self.idx2syn = os.path.join(self.root, &quot;index_synset.yaml&quot;)
77	        if (not os.path.exists(self.idx2syn)):
78	            download(URL, self.idx2syn)
79	
80	    def _prepare_human_to_integer_label(self):
81	        URL = &quot;https://heibox.uni-heidelberg.de/f/2362b797d5be43b883f6/?dl=1&quot;
82	        self.human2integer = os.path.join(self.root, &quot;imagenet1000_clsidx_to_labels.txt&quot;)
83	        if (not os.path.exists(self.human2integer)):
84	            download(URL, self.human2integer)
85	        with open(self.human2integer, &quot;r&quot;) as f:
86	            lines = f.read().splitlines()
87	            assert len(lines) == 1000
88	            self.human2integer_dict = dict()
89	            for line in lines:
90	                value, key = line.split(&quot;:&quot;)
91	                self.human2integer_dict[key] = int(value)
92	
93	    def _load(self):
94	        with open(self.txt_filelist, &quot;r&quot;) as f:
95	            self.relpaths = f.read().splitlines()
96	            l1 = len(self.relpaths)
97	            self.relpaths = self._filter_relpaths(self.relpaths)
98	            print(&quot;Removed {} files from filelist during filtering.&quot;.format(l1 - len(self.relpaths)))
99	
100	        self.synsets = [p.split(&quot;/&quot;)[0] for p in self.relpaths]
101	        self.abspaths = [os.path.join(self.datadir, p) for p in self.relpaths]
102	
103	        unique_synsets = np.unique(self.synsets)
104	        class_dict = dict((synset, i) for i, synset in enumerate(unique_synsets))
105	        if not self.keep_orig_class_label:
106	            self.class_labels = [class_dict[s] for s in self.synsets]
107	        else:
108	            self.class_labels = [self.synset2idx[s] for s in self.synsets]
109	
110	        with open(self.human_dict, &quot;r&quot;) as f:
111	            human_dict = f.read().splitlines()
112	            human_dict = dict(line.split(maxsplit=1) for line in human_dict)
113	
114	        self.human_labels = [human_dict[s] for s in self.synsets]
115	
116	        labels = {
117	            &quot;relpath&quot;: np.array(self.relpaths),
118	            &quot;synsets&quot;: np.array(self.synsets),
119	            &quot;class_label&quot;: np.array(self.class_labels),
120	            &quot;human_label&quot;: np.array(self.human_labels),
</pre>
</div>


</div>
</div>

<div id="issue-9">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>22<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	import os, yaml, pickle, shutil, tarfile, glob
2	import cv2
3	import custom_albumentations as albumentations
4	import PIL
5	import numpy as np
6	import torchvision.transforms.functional as TF
7	# from omegaconf import OmegaConf
8	from functools import partial
9	from PIL import Image
10	from tqdm import tqdm
11	from torch.utils.data import Dataset, Subset
12	
13	import taming.data.utils as tdu
14	from controlnet_aux.diffusion_edge.taming.data.imagenet import str_to_indices, give_synsets_from_indices, download, retrieve
15	from controlnet_aux.diffusion_edge.taming.data.imagenet import ImagePaths
16	
17	# from ldm.modules.image_degradation import degradation_fn_bsr, degradation_fn_bsr_light
18	
19	
20	def synset2idx(path_to_yaml=&quot;data/index_synset.yaml&quot;):
21	    with open(path_to_yaml) as f:
22	        di2s = yaml.load(f)
23	    return dict((v,k) for k,v in di2s.items())
24	
25	
26	class ImageNetBase(Dataset):
27	    def __init__(self, config=None):
28	        self.config = config
29	        # if not type(self.config)==dict:
30	        #     self.config = OmegaConf.to_container(self.config)
31	        self.keep_orig_class_label = self.config.get(&quot;keep_orig_class_label&quot;, False)
32	        self.process_images = True  # if False we skip loading &amp; processing images and self.data contains filepaths
33	        self._prepare()
34	        self._prepare_synset_to_human()
35	        self._prepare_idx_to_synset()
36	        self._prepare_human_to_integer_label()
37	        self._load()
38	
39	    def __len__(self):
40	        return len(self.data)
41	
42	    def __getitem__(self, i):
43	        return self.data[i]
44	
45	    def _prepare(self):
46	        raise NotImplementedError()
47	
48	    def _filter_relpaths(self, relpaths):
49	        ignore = set([
50	            &quot;n06596364_9591.JPEG&quot;,
51	        ])
52	        relpaths = [rpath for rpath in relpaths if not rpath.split(&quot;/&quot;)[-1] in ignore]
53	        if &quot;sub_indices&quot; in self.config:
54	            indices = str_to_indices(self.config[&quot;sub_indices&quot;])
55	            synsets = give_synsets_from_indices(indices, path_to_yaml=self.idx2syn)  # returns a list of strings
56	            self.synset2idx = synset2idx(path_to_yaml=self.idx2syn)
57	            files = []
58	            for rpath in relpaths:
59	                syn = rpath.split(&quot;/&quot;)[0]
60	                if syn in synsets:
61	                    files.append(rpath)
62	            return files
63	        else:
64	            return relpaths
65	
66	    def _prepare_synset_to_human(self):
67	        SIZE = 2655750
68	        URL = &quot;https://heibox.uni-heidelberg.de/f/9f28e956cd304264bb82/?dl=1&quot;
69	        self.human_dict = os.path.join(self.root, &quot;synset_human.txt&quot;)
70	        if (not os.path.exists(self.human_dict) or
71	                not os.path.getsize(self.human_dict)==SIZE):
72	            download(URL, self.human_dict)
73	
74	    def _prepare_idx_to_synset(self):
75	        URL = &quot;https://heibox.uni-heidelberg.de/f/d835d5b6ceda4d3aa910/?dl=1&quot;
76	        self.idx2syn = os.path.join(self.root, &quot;index_synset.yaml&quot;)
77	        if (not os.path.exists(self.idx2syn)):
78	            download(URL, self.idx2syn)
79	
80	    def _prepare_human_to_integer_label(self):
81	        URL = &quot;https://heibox.uni-heidelberg.de/f/2362b797d5be43b883f6/?dl=1&quot;
82	        self.human2integer = os.path.join(self.root, &quot;imagenet1000_clsidx_to_labels.txt&quot;)
83	        if (not os.path.exists(self.human2integer)):
84	            download(URL, self.human2integer)
85	        with open(self.human2integer, &quot;r&quot;) as f:
86	            lines = f.read().splitlines()
87	            assert len(lines) == 1000
88	            self.human2integer_dict = dict()
89	            for line in lines:
90	                value, key = line.split(&quot;:&quot;)
91	                self.human2integer_dict[key] = int(value)
92	
93	    def _load(self):
94	        with open(self.txt_filelist, &quot;r&quot;) as f:
95	            self.relpaths = f.read().splitlines()
96	            l1 = len(self.relpaths)
97	            self.relpaths = self._filter_relpaths(self.relpaths)
98	            print(&quot;Removed {} files from filelist during filtering.&quot;.format(l1 - len(self.relpaths)))
99	
100	        self.synsets = [p.split(&quot;/&quot;)[0] for p in self.relpaths]
101	        self.abspaths = [os.path.join(self.datadir, p) for p in self.relpaths]
102	
103	        unique_synsets = np.unique(self.synsets)
104	        class_dict = dict((synset, i) for i, synset in enumerate(unique_synsets))
105	        if not self.keep_orig_class_label:
106	            self.class_labels = [class_dict[s] for s in self.synsets]
107	        else:
108	            self.class_labels = [self.synset2idx[s] for s in self.synsets]
109	
110	        with open(self.human_dict, &quot;r&quot;) as f:
111	            human_dict = f.read().splitlines()
112	            human_dict = dict(line.split(maxsplit=1) for line in human_dict)
113	
114	        self.human_labels = [human_dict[s] for s in self.synsets]
115	
116	        labels = {
117	            &quot;relpath&quot;: np.array(self.relpaths),
118	            &quot;synsets&quot;: np.array(self.synsets),
119	            &quot;class_label&quot;: np.array(self.class_labels),
120	            &quot;human_label&quot;: np.array(self.human_labels),
</pre>
</div>


</div>
</div>

<div id="issue-10">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>178<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
118	            &quot;synsets&quot;: np.array(self.synsets),
119	            &quot;class_label&quot;: np.array(self.class_labels),
120	            &quot;human_label&quot;: np.array(self.human_labels),
121	        }
122	
123	        if self.process_images:
124	            # self.size = retrieve(self.config, &quot;size&quot;, default=256)
125	            self.size = self.config.get(&quot;size&quot;, default=256)
126	            self.data = ImagePaths(self.abspaths,
127	                                   labels=labels,
128	                                   size=self.size,
129	                                   random_crop=self.random_crop,
130	                                   )
131	        else:
132	            self.data = self.abspaths
133	
134	
135	class ImageNetTrain(ImageNetBase):
136	    NAME = &quot;ILSVRC2012_train&quot;
137	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
138	    AT_HASH = &quot;a306397ccf9c2ead27155983c254227c0fd938e2&quot;
139	    FILES = [
140	        &quot;ILSVRC2012_img_train.tar&quot;,
141	    ]
142	    SIZES = [
143	        147897477120,
144	    ]
145	
146	    def __init__(self, process_images=True, data_root=None, **kwargs):
147	        self.process_images = process_images
148	        self.data_root = data_root
149	        super().__init__(**kwargs)
150	
151	    def _prepare(self):
152	        if self.data_root:
153	            self.root = os.path.join(self.data_root, self.NAME)
154	        else:
155	            cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
156	            self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
157	
158	        self.datadir = os.path.join(self.root, &quot;data&quot;)
159	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
160	        self.expected_length = 1281167
161	        # self.random_crop = retrieve(self.config, &quot;ImageNetTrain/random_crop&quot;, default=True)
162	        self.random_crop = self.config.get(&quot;random_crop&quot;, default=True)
163	        if not tdu.is_prepared(self.root):
164	            # prep
165	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
166	
167	            datadir = self.datadir
168	            if not os.path.exists(datadir):
169	                path = os.path.join(self.root, self.FILES[0])
170	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
171	                    import academictorrents as at
172	                    atpath = at.get(self.AT_HASH, datastore=self.root)
173	                    assert atpath == path
174	
175	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
176	                os.makedirs(datadir, exist_ok=True)
177	                with tarfile.open(path, &quot;r:&quot;) as tar:
178	                    tar.extractall(path=datadir)
179	
180	                print(&quot;Extracting sub-tars.&quot;)
181	                subpaths = sorted(glob.glob(os.path.join(datadir, &quot;*.tar&quot;)))
182	                for subpath in tqdm(subpaths):
183	                    subdir = subpath[:-len(&quot;.tar&quot;)]
184	                    os.makedirs(subdir, exist_ok=True)
185	                    with tarfile.open(subpath, &quot;r:&quot;) as tar:
186	                        tar.extractall(path=subdir)
187	
188	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
189	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
190	            filelist = sorted(filelist)
191	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
192	            with open(self.txt_filelist, &quot;w&quot;) as f:
193	                f.write(filelist)
194	
195	            tdu.mark_prepared(self.root)
196	
197	
198	class ImageNetValidation(ImageNetBase):
199	    NAME = &quot;ILSVRC2012_validation&quot;
200	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
201	    AT_HASH = &quot;5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&quot;
202	    VS_URL = &quot;https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1&quot;
203	    FILES = [
204	        &quot;ILSVRC2012_img_val.tar&quot;,
205	        &quot;validation_synset.txt&quot;,
206	    ]
207	    SIZES = [
208	        6744924160,
209	        1950000,
210	    ]
211	
212	    def __init__(self, process_images=True, data_root=None, **kwargs):
213	        self.data_root = data_root
214	        self.process_images = process_images
215	        super().__init__(**kwargs)
216	
217	    def _prepare(self):
218	        if self.data_root:
219	            self.root = os.path.join(self.data_root, self.NAME)
220	        else:
221	            cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
222	            self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
223	        self.datadir = os.path.join(self.root, &quot;data&quot;)
224	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
225	        self.expected_length = 50000
226	        # self.random_crop = retrieve(self.config, &quot;ImageNetValidation/random_crop&quot;, default=False)
227	        self.random_crop = self.config.get(&quot;random_crop&quot;, default=False)
228	        if not tdu.is_prepared(self.root):
229	            # prep
230	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
231	
232	            datadir = self.datadir
233	            if not os.path.exists(datadir):
234	                path = os.path.join(self.root, self.FILES[0])
235	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
236	                    import academictorrents as at
237	                    atpath = at.get(self.AT_HASH, datastore=self.root)
</pre>
</div>


</div>
</div>

<div id="issue-11">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>186<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
126	            self.data = ImagePaths(self.abspaths,
127	                                   labels=labels,
128	                                   size=self.size,
129	                                   random_crop=self.random_crop,
130	                                   )
131	        else:
132	            self.data = self.abspaths
133	
134	
135	class ImageNetTrain(ImageNetBase):
136	    NAME = &quot;ILSVRC2012_train&quot;
137	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
138	    AT_HASH = &quot;a306397ccf9c2ead27155983c254227c0fd938e2&quot;
139	    FILES = [
140	        &quot;ILSVRC2012_img_train.tar&quot;,
141	    ]
142	    SIZES = [
143	        147897477120,
144	    ]
145	
146	    def __init__(self, process_images=True, data_root=None, **kwargs):
147	        self.process_images = process_images
148	        self.data_root = data_root
149	        super().__init__(**kwargs)
150	
151	    def _prepare(self):
152	        if self.data_root:
153	            self.root = os.path.join(self.data_root, self.NAME)
154	        else:
155	            cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
156	            self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
157	
158	        self.datadir = os.path.join(self.root, &quot;data&quot;)
159	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
160	        self.expected_length = 1281167
161	        # self.random_crop = retrieve(self.config, &quot;ImageNetTrain/random_crop&quot;, default=True)
162	        self.random_crop = self.config.get(&quot;random_crop&quot;, default=True)
163	        if not tdu.is_prepared(self.root):
164	            # prep
165	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
166	
167	            datadir = self.datadir
168	            if not os.path.exists(datadir):
169	                path = os.path.join(self.root, self.FILES[0])
170	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
171	                    import academictorrents as at
172	                    atpath = at.get(self.AT_HASH, datastore=self.root)
173	                    assert atpath == path
174	
175	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
176	                os.makedirs(datadir, exist_ok=True)
177	                with tarfile.open(path, &quot;r:&quot;) as tar:
178	                    tar.extractall(path=datadir)
179	
180	                print(&quot;Extracting sub-tars.&quot;)
181	                subpaths = sorted(glob.glob(os.path.join(datadir, &quot;*.tar&quot;)))
182	                for subpath in tqdm(subpaths):
183	                    subdir = subpath[:-len(&quot;.tar&quot;)]
184	                    os.makedirs(subdir, exist_ok=True)
185	                    with tarfile.open(subpath, &quot;r:&quot;) as tar:
186	                        tar.extractall(path=subdir)
187	
188	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
189	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
190	            filelist = sorted(filelist)
191	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
192	            with open(self.txt_filelist, &quot;w&quot;) as f:
193	                f.write(filelist)
194	
195	            tdu.mark_prepared(self.root)
196	
197	
198	class ImageNetValidation(ImageNetBase):
199	    NAME = &quot;ILSVRC2012_validation&quot;
200	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
201	    AT_HASH = &quot;5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&quot;
202	    VS_URL = &quot;https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1&quot;
203	    FILES = [
204	        &quot;ILSVRC2012_img_val.tar&quot;,
205	        &quot;validation_synset.txt&quot;,
206	    ]
207	    SIZES = [
208	        6744924160,
209	        1950000,
210	    ]
211	
212	    def __init__(self, process_images=True, data_root=None, **kwargs):
213	        self.data_root = data_root
214	        self.process_images = process_images
215	        super().__init__(**kwargs)
216	
217	    def _prepare(self):
218	        if self.data_root:
219	            self.root = os.path.join(self.data_root, self.NAME)
220	        else:
221	            cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
222	            self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
223	        self.datadir = os.path.join(self.root, &quot;data&quot;)
224	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
225	        self.expected_length = 50000
226	        # self.random_crop = retrieve(self.config, &quot;ImageNetValidation/random_crop&quot;, default=False)
227	        self.random_crop = self.config.get(&quot;random_crop&quot;, default=False)
228	        if not tdu.is_prepared(self.root):
229	            # prep
230	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
231	
232	            datadir = self.datadir
233	            if not os.path.exists(datadir):
234	                path = os.path.join(self.root, self.FILES[0])
235	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
236	                    import academictorrents as at
237	                    atpath = at.get(self.AT_HASH, datastore=self.root)
238	                    assert atpath == path
239	
240	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
241	                os.makedirs(datadir, exist_ok=True)
242	                with tarfile.open(path, &quot;r:&quot;) as tar:
243	                    tar.extractall(path=datadir)
244	
245	                vspath = os.path.join(self.root, self.FILES[1])
</pre>
</div>


</div>
</div>

<div id="issue-12">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>243<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
183	                    subdir = subpath[:-len(&quot;.tar&quot;)]
184	                    os.makedirs(subdir, exist_ok=True)
185	                    with tarfile.open(subpath, &quot;r:&quot;) as tar:
186	                        tar.extractall(path=subdir)
187	
188	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
189	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
190	            filelist = sorted(filelist)
191	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
192	            with open(self.txt_filelist, &quot;w&quot;) as f:
193	                f.write(filelist)
194	
195	            tdu.mark_prepared(self.root)
196	
197	
198	class ImageNetValidation(ImageNetBase):
199	    NAME = &quot;ILSVRC2012_validation&quot;
200	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
201	    AT_HASH = &quot;5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&quot;
202	    VS_URL = &quot;https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1&quot;
203	    FILES = [
204	        &quot;ILSVRC2012_img_val.tar&quot;,
205	        &quot;validation_synset.txt&quot;,
206	    ]
207	    SIZES = [
208	        6744924160,
209	        1950000,
210	    ]
211	
212	    def __init__(self, process_images=True, data_root=None, **kwargs):
213	        self.data_root = data_root
214	        self.process_images = process_images
215	        super().__init__(**kwargs)
216	
217	    def _prepare(self):
218	        if self.data_root:
219	            self.root = os.path.join(self.data_root, self.NAME)
220	        else:
221	            cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
222	            self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
223	        self.datadir = os.path.join(self.root, &quot;data&quot;)
224	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
225	        self.expected_length = 50000
226	        # self.random_crop = retrieve(self.config, &quot;ImageNetValidation/random_crop&quot;, default=False)
227	        self.random_crop = self.config.get(&quot;random_crop&quot;, default=False)
228	        if not tdu.is_prepared(self.root):
229	            # prep
230	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
231	
232	            datadir = self.datadir
233	            if not os.path.exists(datadir):
234	                path = os.path.join(self.root, self.FILES[0])
235	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
236	                    import academictorrents as at
237	                    atpath = at.get(self.AT_HASH, datastore=self.root)
238	                    assert atpath == path
239	
240	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
241	                os.makedirs(datadir, exist_ok=True)
242	                with tarfile.open(path, &quot;r:&quot;) as tar:
243	                    tar.extractall(path=datadir)
244	
245	                vspath = os.path.join(self.root, self.FILES[1])
246	                if not os.path.exists(vspath) or not os.path.getsize(vspath)==self.SIZES[1]:
247	                    download(self.VS_URL, vspath)
248	
249	                with open(vspath, &quot;r&quot;) as f:
250	                    synset_dict = f.read().splitlines()
251	                    synset_dict = dict(line.split() for line in synset_dict)
252	
253	                print(&quot;Reorganizing into synset folders&quot;)
254	                synsets = np.unique(list(synset_dict.values()))
255	                for s in synsets:
256	                    os.makedirs(os.path.join(datadir, s), exist_ok=True)
257	                for k, v in synset_dict.items():
258	                    src = os.path.join(datadir, k)
259	                    dst = os.path.join(datadir, v)
260	                    shutil.move(src, dst)
261	
262	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
263	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
264	            filelist = sorted(filelist)
265	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
266	            with open(self.txt_filelist, &quot;w&quot;) as f:
267	                f.write(filelist)
268	
269	            tdu.mark_prepared(self.root)
270	
271	
272	
273	class ImageNetSR(Dataset):
274	    def __init__(self, size=None,
275	                 degradation=None, downscale_f=4, min_crop_f=0.5, max_crop_f=1.,
276	                 random_crop=True):
277	        &quot;&quot;&quot;
278	        Imagenet Superresolution Dataloader
279	        Performs following ops in order:
280	        1.  crops a crop of size s from image either as random or center crop
281	        2.  resizes crop to size with cv2.area_interpolation
282	        3.  degrades resized crop with degradation_fn
283	
284	        :param size: resizing to size after cropping
285	        :param degradation: degradation_fn, e.g. cv_bicubic or bsrgan_light
286	        :param downscale_f: Low Resolution Downsample factor
287	        :param min_crop_f: determines crop size s,
288	          where s = c * min_img_side_len with c sampled from interval (min_crop_f, max_crop_f)
289	        :param max_crop_f: &quot;&quot;
290	        :param data_root:
291	        :param random_crop:
292	        &quot;&quot;&quot;
293	        self.base = self.get_base()
294	        assert size
295	        assert (size / downscale_f).is_integer()
296	        self.size = size
297	        self.LR_size = int(size / downscale_f)
298	        self.min_crop_f = min_crop_f
299	        self.max_crop_f = max_crop_f
300	        assert(max_crop_f &lt;= 1.)
301	        self.center_crop = not random_crop
302	
</pre>
</div>


</div>
</div>

<div id="issue-13">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>382<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
322	            &quot;pil_bicubic&quot;: PIL.Image.BICUBIC,
323	            &quot;pil_box&quot;: PIL.Image.BOX,
324	            &quot;pil_hamming&quot;: PIL.Image.HAMMING,
325	            &quot;pil_lanczos&quot;: PIL.Image.LANCZOS,
326	            }[degradation]
327	
328	            self.pil_interpolation = degradation.startswith(&quot;pil_&quot;)
329	
330	            if self.pil_interpolation:
331	                self.degradation_process = partial(TF.resize, size=self.LR_size, interpolation=interpolation_fn)
332	
333	            else:
334	                self.degradation_process = albumentations.SmallestMaxSize(max_size=self.LR_size,
335	                                                                          interpolation=interpolation_fn)
336	
337	    def __len__(self):
338	        return len(self.base)
339	
340	    def __getitem__(self, i):
341	        example = self.base[i]
342	        image = Image.open(example[&quot;file_path_&quot;])
343	
344	        if not image.mode == &quot;RGB&quot;:
345	            image = image.convert(&quot;RGB&quot;)
346	
347	        image = np.array(image).astype(np.uint8)
348	
349	        min_side_len = min(image.shape[:2])
350	        crop_side_len = min_side_len * np.random.uniform(self.min_crop_f, self.max_crop_f, size=None)
351	        crop_side_len = int(crop_side_len)
352	
353	        if self.center_crop:
354	            self.cropper = albumentations.CenterCrop(height=crop_side_len, width=crop_side_len)
355	
356	        else:
357	            self.cropper = albumentations.RandomCrop(height=crop_side_len, width=crop_side_len)
358	
359	        image = self.cropper(image=image)[&quot;image&quot;]
360	        image = self.image_rescaler(image=image)[&quot;image&quot;]
361	
362	        if self.pil_interpolation:
363	            image_pil = PIL.Image.fromarray(image)
364	            LR_image = self.degradation_process(image_pil)
365	            LR_image = np.array(LR_image).astype(np.uint8)
366	
367	        else:
368	            LR_image = self.degradation_process(image=image)[&quot;image&quot;]
369	
370	        example[&quot;image&quot;] = (image/127.5 - 1.0).astype(np.float32)
371	        example[&quot;LR_image&quot;] = (LR_image/127.5 - 1.0).astype(np.float32)
372	
373	        return example
374	
375	
376	class ImageNetSRTrain(ImageNetSR):
377	    def __init__(self, **kwargs):
378	        super().__init__(**kwargs)
379	
380	    def get_base(self):
381	        with open(&quot;data/imagenet_train_hr_indices.p&quot;, &quot;rb&quot;) as f:
382	            indices = pickle.load(f)
383	        dset = ImageNetTrain(process_images=False,)
384	        return Subset(dset, indices)
385	
386	
387	class ImageNetSRValidation(ImageNetSR):
388	    def __init__(self, **kwargs):
389	        super().__init__(**kwargs)
390	
391	    def get_base(self):
392	        with open(&quot;data/imagenet_val_hr_indices.p&quot;, &quot;rb&quot;) as f:
393	            indices = pickle.load(f)
394	        dset = ImageNetValidation(process_images=False,)
395	        return Subset(dset, indices)
</pre>
</div>


</div>
</div>

<div id="issue-14">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/denoising_diffusion_pytorch/imagenet.py</a><br>
    <b>Line number: </b>393<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
333	            else:
334	                self.degradation_process = albumentations.SmallestMaxSize(max_size=self.LR_size,
335	                                                                          interpolation=interpolation_fn)
336	
337	    def __len__(self):
338	        return len(self.base)
339	
340	    def __getitem__(self, i):
341	        example = self.base[i]
342	        image = Image.open(example[&quot;file_path_&quot;])
343	
344	        if not image.mode == &quot;RGB&quot;:
345	            image = image.convert(&quot;RGB&quot;)
346	
347	        image = np.array(image).astype(np.uint8)
348	
349	        min_side_len = min(image.shape[:2])
350	        crop_side_len = min_side_len * np.random.uniform(self.min_crop_f, self.max_crop_f, size=None)
351	        crop_side_len = int(crop_side_len)
352	
353	        if self.center_crop:
354	            self.cropper = albumentations.CenterCrop(height=crop_side_len, width=crop_side_len)
355	
356	        else:
357	            self.cropper = albumentations.RandomCrop(height=crop_side_len, width=crop_side_len)
358	
359	        image = self.cropper(image=image)[&quot;image&quot;]
360	        image = self.image_rescaler(image=image)[&quot;image&quot;]
361	
362	        if self.pil_interpolation:
363	            image_pil = PIL.Image.fromarray(image)
364	            LR_image = self.degradation_process(image_pil)
365	            LR_image = np.array(LR_image).astype(np.uint8)
366	
367	        else:
368	            LR_image = self.degradation_process(image=image)[&quot;image&quot;]
369	
370	        example[&quot;image&quot;] = (image/127.5 - 1.0).astype(np.float32)
371	        example[&quot;LR_image&quot;] = (LR_image/127.5 - 1.0).astype(np.float32)
372	
373	        return example
374	
375	
376	class ImageNetSRTrain(ImageNetSR):
377	    def __init__(self, **kwargs):
378	        super().__init__(**kwargs)
379	
380	    def get_base(self):
381	        with open(&quot;data/imagenet_train_hr_indices.p&quot;, &quot;rb&quot;) as f:
382	            indices = pickle.load(f)
383	        dset = ImageNetTrain(process_images=False,)
384	        return Subset(dset, indices)
385	
386	
387	class ImageNetSRValidation(ImageNetSR):
388	    def __init__(self, **kwargs):
389	        super().__init__(**kwargs)
390	
391	    def get_base(self):
392	        with open(&quot;data/imagenet_val_hr_indices.p&quot;, &quot;rb&quot;) as f:
393	            indices = pickle.load(f)
394	        dset = ImageNetValidation(process_images=False,)
395	        return Subset(dset, indices)
</pre>
</div>


</div>
</div>

<div id="issue-15">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/model.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/model.py</a><br>
    <b>Line number: </b>16<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	import numpy as np
2	import yaml
3	import argparse
4	import math
5	import torch
6	from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.utils import *
7	from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.encoder_decoder import AutoencoderKL
8	# from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.transmodel import TransModel
9	from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.uncond_unet import Unet
10	from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.data import *
11	from fvcore.common.config import CfgNode
12	from pathlib import Path
13	
14	def load_conf(config_file, conf={}):
15	    with open(config_file) as f:
16	        exp_conf = yaml.load(f, Loader=yaml.FullLoader)
17	        for k, v in exp_conf.items():
18	            conf[k] = v
19	    return conf
20	
21	def prepare_args(ckpt_path, sampling_timesteps=1):
22	    return argparse.Namespace(
23	        cfg=load_conf(Path(__file__).parent / &quot;default.yaml&quot;),
24	        pre_weight=ckpt_path,
25	        sampling_timesteps=sampling_timesteps
26	    )
27	
28	class DiffusionEdge:
29	    def __init__(self, args) -&gt; None:
30	        self.cfg = CfgNode(args.cfg)
31	        torch.manual_seed(42)
32	        np.random.seed(42)
33	        model_cfg = self.cfg.model
34	        first_stage_cfg = model_cfg.first_stage
35	        first_stage_model = AutoencoderKL(
36	            ddconfig=first_stage_cfg.ddconfig,
37	            lossconfig=first_stage_cfg.lossconfig,
38	            embed_dim=first_stage_cfg.embed_dim,
39	            ckpt_path=first_stage_cfg.ckpt_path,
40	        )
41	        if model_cfg.model_name == &#x27;cond_unet&#x27;:
42	            from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.mask_cond_unet import Unet
43	            unet_cfg = model_cfg.unet
44	            unet = Unet(dim=unet_cfg.dim,
45	                        channels=unet_cfg.channels,
46	                        dim_mults=unet_cfg.dim_mults,
47	                        learned_variance=unet_cfg.get(&#x27;learned_variance&#x27;, False),
48	                        out_mul=unet_cfg.out_mul,
49	                        cond_in_dim=unet_cfg.cond_in_dim,
50	                        cond_dim=unet_cfg.cond_dim,
51	                        cond_dim_mults=unet_cfg.cond_dim_mults,
52	                        window_sizes1=unet_cfg.window_sizes1,
53	                        window_sizes2=unet_cfg.window_sizes2,
54	                        fourier_scale=unet_cfg.fourier_scale,
55	                        cfg=unet_cfg,
56	                        )
57	        else:
58	            raise NotImplementedError
59	        if model_cfg.model_type == &#x27;const_sde&#x27;:
60	            from controlnet_aux.diffusion_edge.denoising_diffusion_pytorch.ddm_const_sde import LatentDiffusion
61	        else:
62	            raise NotImplementedError(f&#x27;{model_cfg.model_type} is not surportted !&#x27;)
63	        
64	        self.model = LatentDiffusion(
65	            model=unet,
66	            auto_encoder=first_stage_model,
67	            train_sample=model_cfg.train_sample,
68	            image_size=model_cfg.image_size,
69	            timesteps=model_cfg.timesteps,
70	            sampling_timesteps=args.sampling_timesteps,
71	            loss_type=model_cfg.loss_type,
72	            objective=model_cfg.objective,
73	            scale_factor=model_cfg.scale_factor,
74	            scale_by_std=model_cfg.scale_by_std,
75	            scale_by_softsign=model_cfg.scale_by_softsign,
76	            default_scale=model_cfg.get(&#x27;default_scale&#x27;, False),
77	            input_keys=model_cfg.input_keys,
78	            ckpt_path=model_cfg.ckpt_path,
79	            ignore_keys=model_cfg.ignore_keys,
80	            only_model=model_cfg.only_model,
81	            start_dist=model_cfg.start_dist,
82	            perceptual_weight=model_cfg.perceptual_weight,
83	            use_l1=model_cfg.get(&#x27;use_l1&#x27;, True),
84	            cfg=model_cfg,
85	        )
86	        self.cfg.sampler.ckpt_path = args.pre_weight
87	
88	        data = torch.load(self.cfg.sampler.ckpt_path, map_location=&quot;cpu&quot;)
89	        if self.cfg.sampler.use_ema:
90	            sd = data[&#x27;ema&#x27;]
91	            new_sd = {}
92	            for k in sd.keys():
93	                if k.startswith(&quot;ema_model.&quot;):
94	                    new_k = k[10:]  # remove ema_model.
95	                    new_sd[new_k] = sd[k]
96	            sd = new_sd
97	            self.model.load_state_dict(sd)
98	        else:
99	            self.model.load_state_dict(data[&#x27;model&#x27;])
100	        if &#x27;scale_factor&#x27; in data[&#x27;model&#x27;]:
101	            self.model.scale_factor = data[&#x27;model&#x27;][&#x27;scale_factor&#x27;]
102	
103	        self.model.eval()
104	        self.device = &quot;cpu&quot;
105	    
106	    def to(self, device):
107	        self.model.to(device)
108	        self.device = device
109	        return self
110	        
111	    def __call__(self, image, batch_size=8):
112	        image = normalize_to_neg_one_to_one(image).to(self.device)
113	        mask = None
114	        if self.cfg.sampler.sample_type == &#x27;whole&#x27;:
115	            return self.whole_sample(image, raw_size=image.shape[2:], mask=mask)
116	        elif self.cfg.sampler.sample_type == &#x27;slide&#x27;:
117	            return self.slide_sample(image, crop_size=self.cfg.sampler.get(&#x27;crop_size&#x27;, [320, 320]),
118	                                            stride=self.cfg.sampler.stride, mask=mask, bs=batch_size)
119	    
120	    def whole_sample(self, inputs, raw_size, mask=None):
</pre>
</div>


</div>
</div>

<div id="issue-16">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py</a><br>
    <b>Line number: </b>18<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	import os, tarfile, glob, shutil
2	import yaml
3	import numpy as np
4	from tqdm import tqdm
5	from PIL import Image
6	import custom_albumentations as albumentations
7	from omegaconf import OmegaConf
8	from torch.utils.data import Dataset
9	
10	from controlnet_aux.diffusion_edge.taming.data.base import ImagePaths
11	from controlnet_aux.diffusion_edge.taming.util import download, retrieve
12	import taming.data.utils as bdu
13	
14	
15	def give_synsets_from_indices(indices, path_to_yaml=&quot;data/imagenet_idx_to_synset.yaml&quot;):
16	    synsets = []
17	    with open(path_to_yaml) as f:
18	        di2s = yaml.load(f)
19	    for idx in indices:
20	        synsets.append(str(di2s[idx]))
21	    print(&quot;Using {} different synsets for construction of Restriced Imagenet.&quot;.format(len(synsets)))
22	    return synsets
23	
24	
25	def str_to_indices(string):
26	    &quot;&quot;&quot;Expects a string in the format &#x27;32-123, 256, 280-321&#x27;&quot;&quot;&quot;
27	    assert not string.endswith(&quot;,&quot;), &quot;provided string &#x27;{}&#x27; ends with a comma, pls remove it&quot;.format(string)
28	    subs = string.split(&quot;,&quot;)
29	    indices = []
30	    for sub in subs:
31	        subsubs = sub.split(&quot;-&quot;)
32	        assert len(subsubs) &gt; 0
33	        if len(subsubs) == 1:
34	            indices.append(int(subsubs[0]))
35	        else:
36	            rang = [j for j in range(int(subsubs[0]), int(subsubs[1]))]
37	            indices.extend(rang)
38	    return sorted(indices)
39	
40	
41	class ImageNetBase(Dataset):
42	    def __init__(self, config=None):
43	        self.config = config or OmegaConf.create()
44	        if not type(self.config)==dict:
45	            self.config = OmegaConf.to_container(self.config)
46	        self._prepare()
47	        self._prepare_synset_to_human()
48	        self._prepare_idx_to_synset()
49	        self._load()
50	
51	    def __len__(self):
52	        return len(self.data)
53	
54	    def __getitem__(self, i):
55	        return self.data[i]
56	
57	    def _prepare(self):
58	        raise NotImplementedError()
59	
60	    def _filter_relpaths(self, relpaths):
61	        ignore = set([
62	            &quot;n06596364_9591.JPEG&quot;,
63	        ])
64	        relpaths = [rpath for rpath in relpaths if not rpath.split(&quot;/&quot;)[-1] in ignore]
65	        if &quot;sub_indices&quot; in self.config:
66	            indices = str_to_indices(self.config[&quot;sub_indices&quot;])
67	            synsets = give_synsets_from_indices(indices, path_to_yaml=self.idx2syn)  # returns a list of strings
68	            files = []
69	            for rpath in relpaths:
70	                syn = rpath.split(&quot;/&quot;)[0]
71	                if syn in synsets:
72	                    files.append(rpath)
73	            return files
74	        else:
75	            return relpaths
76	
77	    def _prepare_synset_to_human(self):
78	        SIZE = 2655750
79	        URL = &quot;https://heibox.uni-heidelberg.de/f/9f28e956cd304264bb82/?dl=1&quot;
80	        self.human_dict = os.path.join(self.root, &quot;synset_human.txt&quot;)
81	        if (not os.path.exists(self.human_dict) or
82	                not os.path.getsize(self.human_dict)==SIZE):
83	            download(URL, self.human_dict)
84	
85	    def _prepare_idx_to_synset(self):
86	        URL = &quot;https://heibox.uni-heidelberg.de/f/d835d5b6ceda4d3aa910/?dl=1&quot;
87	        self.idx2syn = os.path.join(self.root, &quot;index_synset.yaml&quot;)
88	        if (not os.path.exists(self.idx2syn)):
89	            download(URL, self.idx2syn)
90	
91	    def _load(self):
92	        with open(self.txt_filelist, &quot;r&quot;) as f:
93	            self.relpaths = f.read().splitlines()
94	            l1 = len(self.relpaths)
95	            self.relpaths = self._filter_relpaths(self.relpaths)
96	            print(&quot;Removed {} files from filelist during filtering.&quot;.format(l1 - len(self.relpaths)))
97	
98	        self.synsets = [p.split(&quot;/&quot;)[0] for p in self.relpaths]
99	        self.abspaths = [os.path.join(self.datadir, p) for p in self.relpaths]
100	
101	        unique_synsets = np.unique(self.synsets)
102	        class_dict = dict((synset, i) for i, synset in enumerate(unique_synsets))
103	        self.class_labels = [class_dict[s] for s in self.synsets]
104	
105	        with open(self.human_dict, &quot;r&quot;) as f:
106	            human_dict = f.read().splitlines()
107	            human_dict = dict(line.split(maxsplit=1) for line in human_dict)
108	
109	        self.human_labels = [human_dict[s] for s in self.synsets]
110	
111	        labels = {
112	            &quot;relpath&quot;: np.array(self.relpaths),
113	            &quot;synsets&quot;: np.array(self.synsets),
114	            &quot;class_label&quot;: np.array(self.class_labels),
115	            &quot;human_label&quot;: np.array(self.human_labels),
116	        }
117	        self.data = ImagePaths(self.abspaths,
118	                               labels=labels,
119	                               size=retrieve(self.config, &quot;size&quot;, default=0),
120	                               random_crop=self.random_crop)
</pre>
</div>


</div>
</div>

<div id="issue-17">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py</a><br>
    <b>Line number: </b>157<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
97	
98	        self.synsets = [p.split(&quot;/&quot;)[0] for p in self.relpaths]
99	        self.abspaths = [os.path.join(self.datadir, p) for p in self.relpaths]
100	
101	        unique_synsets = np.unique(self.synsets)
102	        class_dict = dict((synset, i) for i, synset in enumerate(unique_synsets))
103	        self.class_labels = [class_dict[s] for s in self.synsets]
104	
105	        with open(self.human_dict, &quot;r&quot;) as f:
106	            human_dict = f.read().splitlines()
107	            human_dict = dict(line.split(maxsplit=1) for line in human_dict)
108	
109	        self.human_labels = [human_dict[s] for s in self.synsets]
110	
111	        labels = {
112	            &quot;relpath&quot;: np.array(self.relpaths),
113	            &quot;synsets&quot;: np.array(self.synsets),
114	            &quot;class_label&quot;: np.array(self.class_labels),
115	            &quot;human_label&quot;: np.array(self.human_labels),
116	        }
117	        self.data = ImagePaths(self.abspaths,
118	                               labels=labels,
119	                               size=retrieve(self.config, &quot;size&quot;, default=0),
120	                               random_crop=self.random_crop)
121	
122	
123	class ImageNetTrain(ImageNetBase):
124	    NAME = &quot;ILSVRC2012_train&quot;
125	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
126	    AT_HASH = &quot;a306397ccf9c2ead27155983c254227c0fd938e2&quot;
127	    FILES = [
128	        &quot;ILSVRC2012_img_train.tar&quot;,
129	    ]
130	    SIZES = [
131	        147897477120,
132	    ]
133	
134	    def _prepare(self):
135	        self.random_crop = retrieve(self.config, &quot;ImageNetTrain/random_crop&quot;,
136	                                    default=True)
137	        cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
138	        self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
139	        self.datadir = os.path.join(self.root, &quot;data&quot;)
140	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
141	        self.expected_length = 1281167
142	        if not bdu.is_prepared(self.root):
143	            # prep
144	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
145	
146	            datadir = self.datadir
147	            if not os.path.exists(datadir):
148	                path = os.path.join(self.root, self.FILES[0])
149	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
150	                    import academictorrents as at
151	                    atpath = at.get(self.AT_HASH, datastore=self.root)
152	                    assert atpath == path
153	
154	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
155	                os.makedirs(datadir, exist_ok=True)
156	                with tarfile.open(path, &quot;r:&quot;) as tar:
157	                    tar.extractall(path=datadir)
158	
159	                print(&quot;Extracting sub-tars.&quot;)
160	                subpaths = sorted(glob.glob(os.path.join(datadir, &quot;*.tar&quot;)))
161	                for subpath in tqdm(subpaths):
162	                    subdir = subpath[:-len(&quot;.tar&quot;)]
163	                    os.makedirs(subdir, exist_ok=True)
164	                    with tarfile.open(subpath, &quot;r:&quot;) as tar:
165	                        tar.extractall(path=subdir)
166	
167	
168	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
169	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
170	            filelist = sorted(filelist)
171	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
172	            with open(self.txt_filelist, &quot;w&quot;) as f:
173	                f.write(filelist)
174	
175	            bdu.mark_prepared(self.root)
176	
177	
178	class ImageNetValidation(ImageNetBase):
179	    NAME = &quot;ILSVRC2012_validation&quot;
180	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
181	    AT_HASH = &quot;5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&quot;
182	    VS_URL = &quot;https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1&quot;
183	    FILES = [
184	        &quot;ILSVRC2012_img_val.tar&quot;,
185	        &quot;validation_synset.txt&quot;,
186	    ]
187	    SIZES = [
188	        6744924160,
189	        1950000,
190	    ]
191	
192	    def _prepare(self):
193	        self.random_crop = retrieve(self.config, &quot;ImageNetValidation/random_crop&quot;,
194	                                    default=False)
195	        cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
196	        self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
197	        self.datadir = os.path.join(self.root, &quot;data&quot;)
198	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
199	        self.expected_length = 50000
200	        if not bdu.is_prepared(self.root):
201	            # prep
202	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
203	
204	            datadir = self.datadir
205	            if not os.path.exists(datadir):
206	                path = os.path.join(self.root, self.FILES[0])
207	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
208	                    import academictorrents as at
209	                    atpath = at.get(self.AT_HASH, datastore=self.root)
210	                    assert atpath == path
211	
212	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
213	                os.makedirs(datadir, exist_ok=True)
214	                with tarfile.open(path, &quot;r:&quot;) as tar:
215	                    tar.extractall(path=datadir)
216	
</pre>
</div>


</div>
</div>

<div id="issue-18">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py</a><br>
    <b>Line number: </b>165<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
105	        with open(self.human_dict, &quot;r&quot;) as f:
106	            human_dict = f.read().splitlines()
107	            human_dict = dict(line.split(maxsplit=1) for line in human_dict)
108	
109	        self.human_labels = [human_dict[s] for s in self.synsets]
110	
111	        labels = {
112	            &quot;relpath&quot;: np.array(self.relpaths),
113	            &quot;synsets&quot;: np.array(self.synsets),
114	            &quot;class_label&quot;: np.array(self.class_labels),
115	            &quot;human_label&quot;: np.array(self.human_labels),
116	        }
117	        self.data = ImagePaths(self.abspaths,
118	                               labels=labels,
119	                               size=retrieve(self.config, &quot;size&quot;, default=0),
120	                               random_crop=self.random_crop)
121	
122	
123	class ImageNetTrain(ImageNetBase):
124	    NAME = &quot;ILSVRC2012_train&quot;
125	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
126	    AT_HASH = &quot;a306397ccf9c2ead27155983c254227c0fd938e2&quot;
127	    FILES = [
128	        &quot;ILSVRC2012_img_train.tar&quot;,
129	    ]
130	    SIZES = [
131	        147897477120,
132	    ]
133	
134	    def _prepare(self):
135	        self.random_crop = retrieve(self.config, &quot;ImageNetTrain/random_crop&quot;,
136	                                    default=True)
137	        cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
138	        self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
139	        self.datadir = os.path.join(self.root, &quot;data&quot;)
140	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
141	        self.expected_length = 1281167
142	        if not bdu.is_prepared(self.root):
143	            # prep
144	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
145	
146	            datadir = self.datadir
147	            if not os.path.exists(datadir):
148	                path = os.path.join(self.root, self.FILES[0])
149	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
150	                    import academictorrents as at
151	                    atpath = at.get(self.AT_HASH, datastore=self.root)
152	                    assert atpath == path
153	
154	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
155	                os.makedirs(datadir, exist_ok=True)
156	                with tarfile.open(path, &quot;r:&quot;) as tar:
157	                    tar.extractall(path=datadir)
158	
159	                print(&quot;Extracting sub-tars.&quot;)
160	                subpaths = sorted(glob.glob(os.path.join(datadir, &quot;*.tar&quot;)))
161	                for subpath in tqdm(subpaths):
162	                    subdir = subpath[:-len(&quot;.tar&quot;)]
163	                    os.makedirs(subdir, exist_ok=True)
164	                    with tarfile.open(subpath, &quot;r:&quot;) as tar:
165	                        tar.extractall(path=subdir)
166	
167	
168	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
169	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
170	            filelist = sorted(filelist)
171	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
172	            with open(self.txt_filelist, &quot;w&quot;) as f:
173	                f.write(filelist)
174	
175	            bdu.mark_prepared(self.root)
176	
177	
178	class ImageNetValidation(ImageNetBase):
179	    NAME = &quot;ILSVRC2012_validation&quot;
180	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
181	    AT_HASH = &quot;5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&quot;
182	    VS_URL = &quot;https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1&quot;
183	    FILES = [
184	        &quot;ILSVRC2012_img_val.tar&quot;,
185	        &quot;validation_synset.txt&quot;,
186	    ]
187	    SIZES = [
188	        6744924160,
189	        1950000,
190	    ]
191	
192	    def _prepare(self):
193	        self.random_crop = retrieve(self.config, &quot;ImageNetValidation/random_crop&quot;,
194	                                    default=False)
195	        cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
196	        self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
197	        self.datadir = os.path.join(self.root, &quot;data&quot;)
198	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
199	        self.expected_length = 50000
200	        if not bdu.is_prepared(self.root):
201	            # prep
202	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
203	
204	            datadir = self.datadir
205	            if not os.path.exists(datadir):
206	                path = os.path.join(self.root, self.FILES[0])
207	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
208	                    import academictorrents as at
209	                    atpath = at.get(self.AT_HASH, datastore=self.root)
210	                    assert atpath == path
211	
212	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
213	                os.makedirs(datadir, exist_ok=True)
214	                with tarfile.open(path, &quot;r:&quot;) as tar:
215	                    tar.extractall(path=datadir)
216	
217	                vspath = os.path.join(self.root, self.FILES[1])
218	                if not os.path.exists(vspath) or not os.path.getsize(vspath)==self.SIZES[1]:
219	                    download(self.VS_URL, vspath)
220	
221	                with open(vspath, &quot;r&quot;) as f:
222	                    synset_dict = f.read().splitlines()
223	                    synset_dict = dict(line.split() for line in synset_dict)
224	
</pre>
</div>


</div>
</div>

<div id="issue-19">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/imagenet.py</a><br>
    <b>Line number: </b>215<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
155	                os.makedirs(datadir, exist_ok=True)
156	                with tarfile.open(path, &quot;r:&quot;) as tar:
157	                    tar.extractall(path=datadir)
158	
159	                print(&quot;Extracting sub-tars.&quot;)
160	                subpaths = sorted(glob.glob(os.path.join(datadir, &quot;*.tar&quot;)))
161	                for subpath in tqdm(subpaths):
162	                    subdir = subpath[:-len(&quot;.tar&quot;)]
163	                    os.makedirs(subdir, exist_ok=True)
164	                    with tarfile.open(subpath, &quot;r:&quot;) as tar:
165	                        tar.extractall(path=subdir)
166	
167	
168	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
169	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
170	            filelist = sorted(filelist)
171	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
172	            with open(self.txt_filelist, &quot;w&quot;) as f:
173	                f.write(filelist)
174	
175	            bdu.mark_prepared(self.root)
176	
177	
178	class ImageNetValidation(ImageNetBase):
179	    NAME = &quot;ILSVRC2012_validation&quot;
180	    URL = &quot;http://www.image-net.org/challenges/LSVRC/2012/&quot;
181	    AT_HASH = &quot;5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&quot;
182	    VS_URL = &quot;https://heibox.uni-heidelberg.de/f/3e0f6e9c624e45f2bd73/?dl=1&quot;
183	    FILES = [
184	        &quot;ILSVRC2012_img_val.tar&quot;,
185	        &quot;validation_synset.txt&quot;,
186	    ]
187	    SIZES = [
188	        6744924160,
189	        1950000,
190	    ]
191	
192	    def _prepare(self):
193	        self.random_crop = retrieve(self.config, &quot;ImageNetValidation/random_crop&quot;,
194	                                    default=False)
195	        cachedir = os.environ.get(&quot;XDG_CACHE_HOME&quot;, os.path.expanduser(&quot;~/.cache&quot;))
196	        self.root = os.path.join(cachedir, &quot;autoencoders/data&quot;, self.NAME)
197	        self.datadir = os.path.join(self.root, &quot;data&quot;)
198	        self.txt_filelist = os.path.join(self.root, &quot;filelist.txt&quot;)
199	        self.expected_length = 50000
200	        if not bdu.is_prepared(self.root):
201	            # prep
202	            print(&quot;Preparing dataset {} in {}&quot;.format(self.NAME, self.root))
203	
204	            datadir = self.datadir
205	            if not os.path.exists(datadir):
206	                path = os.path.join(self.root, self.FILES[0])
207	                if not os.path.exists(path) or not os.path.getsize(path)==self.SIZES[0]:
208	                    import academictorrents as at
209	                    atpath = at.get(self.AT_HASH, datastore=self.root)
210	                    assert atpath == path
211	
212	                print(&quot;Extracting {} to {}&quot;.format(path, datadir))
213	                os.makedirs(datadir, exist_ok=True)
214	                with tarfile.open(path, &quot;r:&quot;) as tar:
215	                    tar.extractall(path=datadir)
216	
217	                vspath = os.path.join(self.root, self.FILES[1])
218	                if not os.path.exists(vspath) or not os.path.getsize(vspath)==self.SIZES[1]:
219	                    download(self.VS_URL, vspath)
220	
221	                with open(vspath, &quot;r&quot;) as f:
222	                    synset_dict = f.read().splitlines()
223	                    synset_dict = dict(line.split() for line in synset_dict)
224	
225	                print(&quot;Reorganizing into synset folders&quot;)
226	                synsets = np.unique(list(synset_dict.values()))
227	                for s in synsets:
228	                    os.makedirs(os.path.join(datadir, s), exist_ok=True)
229	                for k, v in synset_dict.items():
230	                    src = os.path.join(datadir, k)
231	                    dst = os.path.join(datadir, v)
232	                    shutil.move(src, dst)
233	
234	            filelist = glob.glob(os.path.join(datadir, &quot;**&quot;, &quot;*.JPEG&quot;))
235	            filelist = [os.path.relpath(p, start=datadir) for p in filelist]
236	            filelist = sorted(filelist)
237	            filelist = &quot;\n&quot;.join(filelist)+&quot;\n&quot;
238	            with open(self.txt_filelist, &quot;w&quot;) as f:
239	                f.write(filelist)
240	
241	            bdu.mark_prepared(self.root)
242	
243	
244	def get_preprocessor(size=None, random_crop=False, additional_targets=None,
245	                     crop_size=None):
246	    if size is not None and size &gt; 0:
247	        transforms = list()
248	        rescaler = albumentations.SmallestMaxSize(max_size = size)
249	        transforms.append(rescaler)
250	        if not random_crop:
251	            cropper = albumentations.CenterCrop(height=size,width=size)
252	            transforms.append(cropper)
253	        else:
254	            cropper = albumentations.RandomCrop(height=size,width=size)
255	            transforms.append(cropper)
256	            flipper = albumentations.HorizontalFlip()
257	            transforms.append(flipper)
258	        preprocessor = albumentations.Compose(transforms,
259	                                              additional_targets=additional_targets)
260	    elif crop_size is not None and crop_size &gt; 0:
261	        if not random_crop:
262	            cropper = albumentations.CenterCrop(height=crop_size,width=crop_size)
263	        else:
264	            cropper = albumentations.RandomCrop(height=crop_size,width=crop_size)
265	        transforms = [cropper]
266	        preprocessor = albumentations.Compose(transforms,
267	                                              additional_targets=additional_targets)
268	    else:
269	        preprocessor = lambda **kwargs: kwargs
270	    return preprocessor
271	
272	
273	def rgba_to_depth(x):
274	    assert x.dtype == np.uint8
</pre>
</div>


</div>
</div>

<div id="issue-20">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py</a><br>
    <b>Line number: </b>19<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
1	import collections
2	import os
3	import tarfile
4	import urllib
5	import zipfile
6	from pathlib import Path
7	
8	import numpy as np
9	import torch
10	from controlnet_aux.diffusion_edge.taming.data.helper_types import Annotation
11	from torch._six import string_classes
12	from torch.utils.data._utils.collate import np_str_obj_array_pattern, default_collate_err_msg_format
13	from tqdm import tqdm
14	
15	
16	def unpack(path):
17	    if path.endswith(&quot;tar.gz&quot;):
18	        with tarfile.open(path, &quot;r:gz&quot;) as tar:
19	            tar.extractall(path=os.path.split(path)[0])
20	    elif path.endswith(&quot;tar&quot;):
21	        with tarfile.open(path, &quot;r:&quot;) as tar:
22	            tar.extractall(path=os.path.split(path)[0])
23	    elif path.endswith(&quot;zip&quot;):
24	        with zipfile.ZipFile(path, &quot;r&quot;) as f:
25	            f.extractall(path=os.path.split(path)[0])
26	    else:
27	        raise NotImplementedError(
28	            &quot;Unknown file extension: {}&quot;.format(os.path.splitext(path)[1])
29	        )
30	
31	
32	def reporthook(bar):
33	    &quot;&quot;&quot;tqdm progress bar for downloads.&quot;&quot;&quot;
34	
35	    def hook(b=1, bsize=1, tsize=None):
36	        if tsize is not None:
37	            bar.total = tsize
38	        bar.update(b * bsize - bar.n)
39	
40	    return hook
41	
42	
43	def get_root(name):
44	    base = &quot;data/&quot;
45	    root = os.path.join(base, name)
46	    os.makedirs(root, exist_ok=True)
47	    return root
48	
49	
50	def is_prepared(root):
51	    return Path(root).joinpath(&quot;.ready&quot;).exists()
52	
53	
54	def mark_prepared(root):
55	    Path(root).joinpath(&quot;.ready&quot;).touch()
56	
57	
58	def prompt_download(file_, source, target_dir, content_dir=None):
59	    targetpath = os.path.join(target_dir, file_)
60	    while not os.path.exists(targetpath):
61	        if content_dir is not None and os.path.exists(
62	            os.path.join(target_dir, content_dir)
63	        ):
64	            break
65	        print(
66	            &quot;Please download &#x27;{}&#x27; from &#x27;{}&#x27; to &#x27;{}&#x27;.&quot;.format(file_, source, targetpath)
67	        )
68	        if content_dir is not None:
69	            print(
70	                &quot;Or place its content into &#x27;{}&#x27;.&quot;.format(
71	                    os.path.join(target_dir, content_dir)
72	                )
73	            )
74	        input(&quot;Press Enter when done...&quot;)
75	    return targetpath
76	
77	
78	def download_url(file_, url, target_dir):
79	    targetpath = os.path.join(target_dir, file_)
80	    os.makedirs(target_dir, exist_ok=True)
81	    with tqdm(
82	        unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1, desc=file_
83	    ) as bar:
84	        urllib.request.urlretrieve(url, targetpath, reporthook=reporthook(bar))
85	    return targetpath
86	
87	
88	def download_urls(urls, target_dir):
89	    paths = dict()
90	    for fname, url in urls.items():
91	        outpath = download_url(fname, url, target_dir)
92	        paths[fname] = outpath
93	    return paths
94	
95	
96	def quadratic_crop(x, bbox, alpha=1.0):
97	    &quot;&quot;&quot;bbox is xmin, ymin, xmax, ymax&quot;&quot;&quot;
98	    im_h, im_w = x.shape[:2]
99	    bbox = np.array(bbox, dtype=np.float32)
100	    bbox = np.clip(bbox, 0, max(im_h, im_w))
101	    center = 0.5 * (bbox[0] + bbox[2]), 0.5 * (bbox[1] + bbox[3])
102	    w = bbox[2] - bbox[0]
103	    h = bbox[3] - bbox[1]
104	    l = int(alpha * max(w, h))
105	    l = max(l, 2)
106	
107	    required_padding = -1 * min(
108	        center[0] - l, center[1] - l, im_w - (center[0] + l), im_h - (center[1] + l)
109	    )
110	    required_padding = int(np.ceil(required_padding))
111	    if required_padding &gt; 0:
112	        padding = [
113	            [required_padding, required_padding],
114	            [required_padding, required_padding],
115	        ]
116	        padding += [[0, 0]] * (len(x.shape) - 2)
117	        x = np.pad(x, padding, &quot;reflect&quot;)
118	        center = center[0] + required_padding, center[1] + required_padding
119	    xmin = int(center[0] - l / 2)
120	    ymin = int(center[1] - l / 2)
</pre>
</div>


</div>
</div>

<div id="issue-21">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py</a><br>
    <b>Line number: </b>22<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
1	import collections
2	import os
3	import tarfile
4	import urllib
5	import zipfile
6	from pathlib import Path
7	
8	import numpy as np
9	import torch
10	from controlnet_aux.diffusion_edge.taming.data.helper_types import Annotation
11	from torch._six import string_classes
12	from torch.utils.data._utils.collate import np_str_obj_array_pattern, default_collate_err_msg_format
13	from tqdm import tqdm
14	
15	
16	def unpack(path):
17	    if path.endswith(&quot;tar.gz&quot;):
18	        with tarfile.open(path, &quot;r:gz&quot;) as tar:
19	            tar.extractall(path=os.path.split(path)[0])
20	    elif path.endswith(&quot;tar&quot;):
21	        with tarfile.open(path, &quot;r:&quot;) as tar:
22	            tar.extractall(path=os.path.split(path)[0])
23	    elif path.endswith(&quot;zip&quot;):
24	        with zipfile.ZipFile(path, &quot;r&quot;) as f:
25	            f.extractall(path=os.path.split(path)[0])
26	    else:
27	        raise NotImplementedError(
28	            &quot;Unknown file extension: {}&quot;.format(os.path.splitext(path)[1])
29	        )
30	
31	
32	def reporthook(bar):
33	    &quot;&quot;&quot;tqdm progress bar for downloads.&quot;&quot;&quot;
34	
35	    def hook(b=1, bsize=1, tsize=None):
36	        if tsize is not None:
37	            bar.total = tsize
38	        bar.update(b * bsize - bar.n)
39	
40	    return hook
41	
42	
43	def get_root(name):
44	    base = &quot;data/&quot;
45	    root = os.path.join(base, name)
46	    os.makedirs(root, exist_ok=True)
47	    return root
48	
49	
50	def is_prepared(root):
51	    return Path(root).joinpath(&quot;.ready&quot;).exists()
52	
53	
54	def mark_prepared(root):
55	    Path(root).joinpath(&quot;.ready&quot;).touch()
56	
57	
58	def prompt_download(file_, source, target_dir, content_dir=None):
59	    targetpath = os.path.join(target_dir, file_)
60	    while not os.path.exists(targetpath):
61	        if content_dir is not None and os.path.exists(
62	            os.path.join(target_dir, content_dir)
63	        ):
64	            break
65	        print(
66	            &quot;Please download &#x27;{}&#x27; from &#x27;{}&#x27; to &#x27;{}&#x27;.&quot;.format(file_, source, targetpath)
67	        )
68	        if content_dir is not None:
69	            print(
70	                &quot;Or place its content into &#x27;{}&#x27;.&quot;.format(
71	                    os.path.join(target_dir, content_dir)
72	                )
73	            )
74	        input(&quot;Press Enter when done...&quot;)
75	    return targetpath
76	
77	
78	def download_url(file_, url, target_dir):
79	    targetpath = os.path.join(target_dir, file_)
80	    os.makedirs(target_dir, exist_ok=True)
81	    with tqdm(
82	        unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1, desc=file_
83	    ) as bar:
84	        urllib.request.urlretrieve(url, targetpath, reporthook=reporthook(bar))
85	    return targetpath
86	
87	
88	def download_urls(urls, target_dir):
89	    paths = dict()
90	    for fname, url in urls.items():
91	        outpath = download_url(fname, url, target_dir)
92	        paths[fname] = outpath
93	    return paths
94	
95	
96	def quadratic_crop(x, bbox, alpha=1.0):
97	    &quot;&quot;&quot;bbox is xmin, ymin, xmax, ymax&quot;&quot;&quot;
98	    im_h, im_w = x.shape[:2]
99	    bbox = np.array(bbox, dtype=np.float32)
100	    bbox = np.clip(bbox, 0, max(im_h, im_w))
101	    center = 0.5 * (bbox[0] + bbox[2]), 0.5 * (bbox[1] + bbox[3])
102	    w = bbox[2] - bbox[0]
103	    h = bbox[3] - bbox[1]
104	    l = int(alpha * max(w, h))
105	    l = max(l, 2)
106	
107	    required_padding = -1 * min(
108	        center[0] - l, center[1] - l, im_w - (center[0] + l), im_h - (center[1] + l)
109	    )
110	    required_padding = int(np.ceil(required_padding))
111	    if required_padding &gt; 0:
112	        padding = [
113	            [required_padding, required_padding],
114	            [required_padding, required_padding],
115	        ]
116	        padding += [[0, 0]] * (len(x.shape) - 2)
117	        x = np.pad(x, padding, &quot;reflect&quot;)
118	        center = center[0] + required_padding, center[1] + required_padding
119	    xmin = int(center[0] - l / 2)
120	    ymin = int(center[1] - l / 2)
</pre>
</div>


</div>
</div>

<div id="issue-22">
<div class="issue-block issue-sev-high">
    <b>tarfile_unsafe_members: </b> tarfile.extractall used without any validation. Please check and discard dangerous members.<br>
    <b>Test ID:</b> B202<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py</a><br>
    <b>Line number: </b>25<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b202_tarfile_unsafe_members.html</a><br>

<div class="code">
<pre>
1	import collections
2	import os
3	import tarfile
4	import urllib
5	import zipfile
6	from pathlib import Path
7	
8	import numpy as np
9	import torch
10	from controlnet_aux.diffusion_edge.taming.data.helper_types import Annotation
11	from torch._six import string_classes
12	from torch.utils.data._utils.collate import np_str_obj_array_pattern, default_collate_err_msg_format
13	from tqdm import tqdm
14	
15	
16	def unpack(path):
17	    if path.endswith(&quot;tar.gz&quot;):
18	        with tarfile.open(path, &quot;r:gz&quot;) as tar:
19	            tar.extractall(path=os.path.split(path)[0])
20	    elif path.endswith(&quot;tar&quot;):
21	        with tarfile.open(path, &quot;r:&quot;) as tar:
22	            tar.extractall(path=os.path.split(path)[0])
23	    elif path.endswith(&quot;zip&quot;):
24	        with zipfile.ZipFile(path, &quot;r&quot;) as f:
25	            f.extractall(path=os.path.split(path)[0])
26	    else:
27	        raise NotImplementedError(
28	            &quot;Unknown file extension: {}&quot;.format(os.path.splitext(path)[1])
29	        )
30	
31	
32	def reporthook(bar):
33	    &quot;&quot;&quot;tqdm progress bar for downloads.&quot;&quot;&quot;
34	
35	    def hook(b=1, bsize=1, tsize=None):
36	        if tsize is not None:
37	            bar.total = tsize
38	        bar.update(b * bsize - bar.n)
39	
40	    return hook
41	
42	
43	def get_root(name):
44	    base = &quot;data/&quot;
45	    root = os.path.join(base, name)
46	    os.makedirs(root, exist_ok=True)
47	    return root
48	
49	
50	def is_prepared(root):
51	    return Path(root).joinpath(&quot;.ready&quot;).exists()
52	
53	
54	def mark_prepared(root):
55	    Path(root).joinpath(&quot;.ready&quot;).touch()
56	
57	
58	def prompt_download(file_, source, target_dir, content_dir=None):
59	    targetpath = os.path.join(target_dir, file_)
60	    while not os.path.exists(targetpath):
61	        if content_dir is not None and os.path.exists(
62	            os.path.join(target_dir, content_dir)
63	        ):
64	            break
65	        print(
66	            &quot;Please download &#x27;{}&#x27; from &#x27;{}&#x27; to &#x27;{}&#x27;.&quot;.format(file_, source, targetpath)
67	        )
68	        if content_dir is not None:
69	            print(
70	                &quot;Or place its content into &#x27;{}&#x27;.&quot;.format(
71	                    os.path.join(target_dir, content_dir)
72	                )
73	            )
74	        input(&quot;Press Enter when done...&quot;)
75	    return targetpath
76	
77	
78	def download_url(file_, url, target_dir):
79	    targetpath = os.path.join(target_dir, file_)
80	    os.makedirs(target_dir, exist_ok=True)
81	    with tqdm(
82	        unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1, desc=file_
83	    ) as bar:
84	        urllib.request.urlretrieve(url, targetpath, reporthook=reporthook(bar))
85	    return targetpath
86	
87	
88	def download_urls(urls, target_dir):
89	    paths = dict()
90	    for fname, url in urls.items():
91	        outpath = download_url(fname, url, target_dir)
92	        paths[fname] = outpath
93	    return paths
94	
95	
96	def quadratic_crop(x, bbox, alpha=1.0):
97	    &quot;&quot;&quot;bbox is xmin, ymin, xmax, ymax&quot;&quot;&quot;
98	    im_h, im_w = x.shape[:2]
99	    bbox = np.array(bbox, dtype=np.float32)
100	    bbox = np.clip(bbox, 0, max(im_h, im_w))
101	    center = 0.5 * (bbox[0] + bbox[2]), 0.5 * (bbox[1] + bbox[3])
102	    w = bbox[2] - bbox[0]
103	    h = bbox[3] - bbox[1]
104	    l = int(alpha * max(w, h))
105	    l = max(l, 2)
106	
107	    required_padding = -1 * min(
108	        center[0] - l, center[1] - l, im_w - (center[0] + l), im_h - (center[1] + l)
109	    )
110	    required_padding = int(np.ceil(required_padding))
111	    if required_padding &gt; 0:
112	        padding = [
113	            [required_padding, required_padding],
114	            [required_padding, required_padding],
115	        ]
116	        padding += [[0, 0]] * (len(x.shape) - 2)
117	        x = np.pad(x, padding, &quot;reflect&quot;)
118	        center = center[0] + required_padding, center[1] + required_padding
119	    xmin = int(center[0] - l / 2)
120	    ymin = int(center[1] - l / 2)
</pre>
</div>


</div>
</div>

<div id="issue-23">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Audit url open for permitted schemes. Allowing use of file:/ or custom schemes is often unexpected.<br>
    <b>Test ID:</b> B310<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/data/utils.py</a><br>
    <b>Line number: </b>84<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen</a><br>

<div class="code">
<pre>
24	        with zipfile.ZipFile(path, &quot;r&quot;) as f:
25	            f.extractall(path=os.path.split(path)[0])
26	    else:
27	        raise NotImplementedError(
28	            &quot;Unknown file extension: {}&quot;.format(os.path.splitext(path)[1])
29	        )
30	
31	
32	def reporthook(bar):
33	    &quot;&quot;&quot;tqdm progress bar for downloads.&quot;&quot;&quot;
34	
35	    def hook(b=1, bsize=1, tsize=None):
36	        if tsize is not None:
37	            bar.total = tsize
38	        bar.update(b * bsize - bar.n)
39	
40	    return hook
41	
42	
43	def get_root(name):
44	    base = &quot;data/&quot;
45	    root = os.path.join(base, name)
46	    os.makedirs(root, exist_ok=True)
47	    return root
48	
49	
50	def is_prepared(root):
51	    return Path(root).joinpath(&quot;.ready&quot;).exists()
52	
53	
54	def mark_prepared(root):
55	    Path(root).joinpath(&quot;.ready&quot;).touch()
56	
57	
58	def prompt_download(file_, source, target_dir, content_dir=None):
59	    targetpath = os.path.join(target_dir, file_)
60	    while not os.path.exists(targetpath):
61	        if content_dir is not None and os.path.exists(
62	            os.path.join(target_dir, content_dir)
63	        ):
64	            break
65	        print(
66	            &quot;Please download &#x27;{}&#x27; from &#x27;{}&#x27; to &#x27;{}&#x27;.&quot;.format(file_, source, targetpath)
67	        )
68	        if content_dir is not None:
69	            print(
70	                &quot;Or place its content into &#x27;{}&#x27;.&quot;.format(
71	                    os.path.join(target_dir, content_dir)
72	                )
73	            )
74	        input(&quot;Press Enter when done...&quot;)
75	    return targetpath
76	
77	
78	def download_url(file_, url, target_dir):
79	    targetpath = os.path.join(target_dir, file_)
80	    os.makedirs(target_dir, exist_ok=True)
81	    with tqdm(
82	        unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1, desc=file_
83	    ) as bar:
84	        urllib.request.urlretrieve(url, targetpath, reporthook=reporthook(bar))
85	    return targetpath
86	
87	
88	def download_urls(urls, target_dir):
89	    paths = dict()
90	    for fname, url in urls.items():
91	        outpath = download_url(fname, url, target_dir)
92	        paths[fname] = outpath
93	    return paths
94	
95	
96	def quadratic_crop(x, bbox, alpha=1.0):
97	    &quot;&quot;&quot;bbox is xmin, ymin, xmax, ymax&quot;&quot;&quot;
98	    im_h, im_w = x.shape[:2]
99	    bbox = np.array(bbox, dtype=np.float32)
100	    bbox = np.clip(bbox, 0, max(im_h, im_w))
101	    center = 0.5 * (bbox[0] + bbox[2]), 0.5 * (bbox[1] + bbox[3])
102	    w = bbox[2] - bbox[0]
103	    h = bbox[3] - bbox[1]
104	    l = int(alpha * max(w, h))
105	    l = max(l, 2)
106	
107	    required_padding = -1 * min(
108	        center[0] - l, center[1] - l, im_w - (center[0] + l), im_h - (center[1] + l)
109	    )
110	    required_padding = int(np.ceil(required_padding))
111	    if required_padding &gt; 0:
112	        padding = [
113	            [required_padding, required_padding],
114	            [required_padding, required_padding],
115	        ]
116	        padding += [[0, 0]] * (len(x.shape) - 2)
117	        x = np.pad(x, padding, &quot;reflect&quot;)
118	        center = center[0] + required_padding, center[1] + required_padding
119	    xmin = int(center[0] - l / 2)
120	    ymin = int(center[1] - l / 2)
121	    return np.array(x[ymin : ymin + l, xmin : xmin + l, ...])
122	
123	
124	def custom_collate(batch):
125	    r&quot;&quot;&quot;source: pytorch 1.9.0, only one modification to original code &quot;&quot;&quot;
126	
127	    elem = batch[0]
128	    elem_type = type(elem)
129	    if isinstance(elem, torch.Tensor):
130	        out = None
131	        if torch.utils.data.get_worker_info() is not None:
132	            # If we&#x27;re in a background process, concatenate directly into a
133	            # shared memory tensor to avoid an extra copy
134	            numel = sum([x.numel() for x in batch])
135	            storage = elem.storage()._new_shared(numel)
136	            out = elem.new(storage)
137	        return torch.stack(batch, 0, out=out)
138	    elif elem_type.__module__ == &#x27;numpy&#x27; and elem_type.__name__ != &#x27;str_&#x27; \
139	            and elem_type.__name__ != &#x27;string_&#x27;:
140	        if elem_type.__name__ == &#x27;ndarray&#x27; or elem_type.__name__ == &#x27;memmap&#x27;:
141	            # array of string classes and object
142	            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:
143	                raise TypeError(default_collate_err_msg_format.format(elem.dtype))
</pre>
</div>


</div>
</div>

<div id="issue-24">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/modules/losses/util.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/modules/losses/util.py</a><br>
    <b>Line number: </b>20<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
1	import os, hashlib
2	import requests
3	from tqdm import tqdm
4	
5	URL_MAP = {
6	    &quot;vgg_lpips&quot;: &quot;https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1&quot;
7	}
8	
9	CKPT_MAP = {
10	    &quot;vgg_lpips&quot;: &quot;vgg.pth&quot;
11	}
12	
13	MD5_MAP = {
14	    &quot;vgg_lpips&quot;: &quot;d507d7349b931f0638a25a48a722f98a&quot;
15	}
16	
17	
18	def download(url, local_path, chunk_size=1024):
19	    os.makedirs(os.path.split(local_path)[0], exist_ok=True)
20	    with requests.get(url, stream=True) as r:
21	        total_size = int(r.headers.get(&quot;content-length&quot;, 0))
22	        with tqdm(total=total_size, unit=&quot;B&quot;, unit_scale=True) as pbar:
23	            with open(local_path, &quot;wb&quot;) as f:
24	                for data in r.iter_content(chunk_size=chunk_size):
25	                    if data:
26	                        f.write(data)
27	                        pbar.update(chunk_size)
28	
29	
30	def md5_hash(path):
31	    with open(path, &quot;rb&quot;) as f:
32	        content = f.read()
33	    return hashlib.md5(content).hexdigest()
34	
35	
36	def get_ckpt_path(name, root, check=False):
37	    assert name in URL_MAP
38	    path = os.path.join(root, CKPT_MAP[name])
39	    if not os.path.exists(path) or (check and not md5_hash(path) == MD5_MAP[name]):
40	        print(&quot;Downloading {} model from {} to {}&quot;.format(name, URL_MAP[name], path))
41	        download(URL_MAP[name], path)
42	        md5 = md5_hash(path)
43	        assert md5 == MD5_MAP[name], md5
44	    return path
45	
46	
47	class KeyNotFoundError(Exception):
48	    def __init__(self, cause, keys=None, visited=None):
49	        self.cause = cause
50	        self.keys = keys
51	        self.visited = visited
52	        messages = list()
53	        if keys is not None:
54	            messages.append(&quot;Key not found: {}&quot;.format(keys))
55	        if visited is not None:
56	            messages.append(&quot;Visited: {}&quot;.format(visited))
57	        messages.append(&quot;Cause:\n{}&quot;.format(cause))
58	        message = &quot;\n&quot;.join(messages)
59	        super().__init__(message)
60	
61	
62	def retrieve(
63	    list_or_dict, key, splitval=&quot;/&quot;, default=None, expand=True, pass_success=False
64	):
65	    &quot;&quot;&quot;Given a nested list or dict return the desired value at key expanding
66	    callable nodes if necessary and :attr:`expand` is ``True``. The expansion
67	    is done in-place.
68	
69	    Parameters
70	    ----------
71	        list_or_dict : list or dict
72	            Possibly nested list or dictionary.
73	        key : str
74	            key/to/value, path like string describing all keys necessary to
75	            consider to get to the desired value. List indices can also be
76	            passed here.
77	        splitval : str
78	            String that defines the delimiter between keys of the
79	            different depth levels in `key`.
80	        default : obj
81	            Value returned if :attr:`key` is not found.
82	        expand : bool
83	            Whether to expand callable nodes on the path or not.
84	
85	    Returns
86	    -------
87	        The desired value or if :attr:`default` is not ``None`` and the
88	        :attr:`key` is not found returns ``default``.
89	
90	    Raises
91	    ------
92	        Exception if ``key`` not in ``list_or_dict`` and :attr:`default` is
93	        ``None``.
94	    &quot;&quot;&quot;
95	
96	    keys = key.split(splitval)
97	
98	    success = True
99	    try:
100	        visited = []
101	        parent = None
102	        last_key = None
103	        for key in keys:
104	            if callable(list_or_dict):
105	                if not expand:
106	                    raise KeyNotFoundError(
107	                        ValueError(
108	                            &quot;Trying to get past callable node with expand=False.&quot;
109	                        ),
110	                        keys=keys,
111	                        visited=visited,
112	                    )
113	                list_or_dict = list_or_dict()
114	                parent[last_key] = list_or_dict
115	
116	            last_key = key
117	            parent = list_or_dict
118	
119	            try:
120	                if isinstance(list_or_dict, dict):
</pre>
</div>


</div>
</div>

<div id="issue-25">
<div class="issue-block issue-sev-high">
    <b>hashlib: </b> Use of weak MD5 hash for security. Consider usedforsecurity=False<br>
    <b>Test ID:</b> B324<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/327.html" target="_blank">CWE-327</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/modules/losses/util.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/modules/losses/util.py</a><br>
    <b>Line number: </b>33<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b324_hashlib.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b324_hashlib.html</a><br>

<div class="code">
<pre>
1	import os, hashlib
2	import requests
3	from tqdm import tqdm
4	
5	URL_MAP = {
6	    &quot;vgg_lpips&quot;: &quot;https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1&quot;
7	}
8	
9	CKPT_MAP = {
10	    &quot;vgg_lpips&quot;: &quot;vgg.pth&quot;
11	}
12	
13	MD5_MAP = {
14	    &quot;vgg_lpips&quot;: &quot;d507d7349b931f0638a25a48a722f98a&quot;
15	}
16	
17	
18	def download(url, local_path, chunk_size=1024):
19	    os.makedirs(os.path.split(local_path)[0], exist_ok=True)
20	    with requests.get(url, stream=True) as r:
21	        total_size = int(r.headers.get(&quot;content-length&quot;, 0))
22	        with tqdm(total=total_size, unit=&quot;B&quot;, unit_scale=True) as pbar:
23	            with open(local_path, &quot;wb&quot;) as f:
24	                for data in r.iter_content(chunk_size=chunk_size):
25	                    if data:
26	                        f.write(data)
27	                        pbar.update(chunk_size)
28	
29	
30	def md5_hash(path):
31	    with open(path, &quot;rb&quot;) as f:
32	        content = f.read()
33	    return hashlib.md5(content).hexdigest()
34	
35	
36	def get_ckpt_path(name, root, check=False):
37	    assert name in URL_MAP
38	    path = os.path.join(root, CKPT_MAP[name])
39	    if not os.path.exists(path) or (check and not md5_hash(path) == MD5_MAP[name]):
40	        print(&quot;Downloading {} model from {} to {}&quot;.format(name, URL_MAP[name], path))
41	        download(URL_MAP[name], path)
42	        md5 = md5_hash(path)
43	        assert md5 == MD5_MAP[name], md5
44	    return path
45	
46	
47	class KeyNotFoundError(Exception):
48	    def __init__(self, cause, keys=None, visited=None):
49	        self.cause = cause
50	        self.keys = keys
51	        self.visited = visited
52	        messages = list()
53	        if keys is not None:
54	            messages.append(&quot;Key not found: {}&quot;.format(keys))
55	        if visited is not None:
56	            messages.append(&quot;Visited: {}&quot;.format(visited))
57	        messages.append(&quot;Cause:\n{}&quot;.format(cause))
58	        message = &quot;\n&quot;.join(messages)
59	        super().__init__(message)
60	
61	
62	def retrieve(
63	    list_or_dict, key, splitval=&quot;/&quot;, default=None, expand=True, pass_success=False
64	):
65	    &quot;&quot;&quot;Given a nested list or dict return the desired value at key expanding
66	    callable nodes if necessary and :attr:`expand` is ``True``. The expansion
67	    is done in-place.
68	
69	    Parameters
70	    ----------
71	        list_or_dict : list or dict
72	            Possibly nested list or dictionary.
73	        key : str
74	            key/to/value, path like string describing all keys necessary to
75	            consider to get to the desired value. List indices can also be
76	            passed here.
77	        splitval : str
78	            String that defines the delimiter between keys of the
79	            different depth levels in `key`.
80	        default : obj
81	            Value returned if :attr:`key` is not found.
82	        expand : bool
83	            Whether to expand callable nodes on the path or not.
84	
85	    Returns
86	    -------
87	        The desired value or if :attr:`default` is not ``None`` and the
88	        :attr:`key` is not found returns ``default``.
89	
90	    Raises
91	    ------
92	        Exception if ``key`` not in ``list_or_dict`` and :attr:`default` is
93	        ``None``.
94	    &quot;&quot;&quot;
95	
96	    keys = key.split(splitval)
97	
98	    success = True
99	    try:
100	        visited = []
101	        parent = None
102	        last_key = None
103	        for key in keys:
104	            if callable(list_or_dict):
105	                if not expand:
106	                    raise KeyNotFoundError(
107	                        ValueError(
108	                            &quot;Trying to get past callable node with expand=False.&quot;
109	                        ),
110	                        keys=keys,
111	                        visited=visited,
112	                    )
113	                list_or_dict = list_or_dict()
114	                parent[last_key] = list_or_dict
115	
116	            last_key = key
117	            parent = list_or_dict
118	
119	            try:
120	                if isinstance(list_or_dict, dict):
</pre>
</div>


</div>
</div>

<div id="issue-26">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/util.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/util.py</a><br>
    <b>Line number: </b>20<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
1	import os, hashlib
2	import requests
3	from tqdm import tqdm
4	
5	URL_MAP = {
6	    &quot;vgg_lpips&quot;: &quot;https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1&quot;
7	}
8	
9	CKPT_MAP = {
10	    &quot;vgg_lpips&quot;: &quot;vgg.pth&quot;
11	}
12	
13	MD5_MAP = {
14	    &quot;vgg_lpips&quot;: &quot;d507d7349b931f0638a25a48a722f98a&quot;
15	}
16	
17	
18	def download(url, local_path, chunk_size=1024):
19	    os.makedirs(os.path.split(local_path)[0], exist_ok=True)
20	    with requests.get(url, stream=True) as r:
21	        total_size = int(r.headers.get(&quot;content-length&quot;, 0))
22	        with tqdm(total=total_size, unit=&quot;B&quot;, unit_scale=True) as pbar:
23	            with open(local_path, &quot;wb&quot;) as f:
24	                for data in r.iter_content(chunk_size=chunk_size):
25	                    if data:
26	                        f.write(data)
27	                        pbar.update(chunk_size)
28	
29	
30	def md5_hash(path):
31	    with open(path, &quot;rb&quot;) as f:
32	        content = f.read()
33	    return hashlib.md5(content).hexdigest()
34	
35	
36	def get_ckpt_path(name, root, check=False):
37	    assert name in URL_MAP
38	    path = os.path.join(root, CKPT_MAP[name])
39	    if not os.path.exists(path) or (check and not md5_hash(path) == MD5_MAP[name]):
40	        print(&quot;Downloading {} model from {} to {}&quot;.format(name, URL_MAP[name], path))
41	        download(URL_MAP[name], path)
42	        md5 = md5_hash(path)
43	        assert md5 == MD5_MAP[name], md5
44	    return path
45	
46	
47	class KeyNotFoundError(Exception):
48	    def __init__(self, cause, keys=None, visited=None):
49	        self.cause = cause
50	        self.keys = keys
51	        self.visited = visited
52	        messages = list()
53	        if keys is not None:
54	            messages.append(&quot;Key not found: {}&quot;.format(keys))
55	        if visited is not None:
56	            messages.append(&quot;Visited: {}&quot;.format(visited))
57	        messages.append(&quot;Cause:\n{}&quot;.format(cause))
58	        message = &quot;\n&quot;.join(messages)
59	        super().__init__(message)
60	
61	
62	def retrieve(
63	    list_or_dict, key, splitval=&quot;/&quot;, default=None, expand=True, pass_success=False
64	):
65	    &quot;&quot;&quot;Given a nested list or dict return the desired value at key expanding
66	    callable nodes if necessary and :attr:`expand` is ``True``. The expansion
67	    is done in-place.
68	
69	    Parameters
70	    ----------
71	        list_or_dict : list or dict
72	            Possibly nested list or dictionary.
73	        key : str
74	            key/to/value, path like string describing all keys necessary to
75	            consider to get to the desired value. List indices can also be
76	            passed here.
77	        splitval : str
78	            String that defines the delimiter between keys of the
79	            different depth levels in `key`.
80	        default : obj
81	            Value returned if :attr:`key` is not found.
82	        expand : bool
83	            Whether to expand callable nodes on the path or not.
84	
85	    Returns
86	    -------
87	        The desired value or if :attr:`default` is not ``None`` and the
88	        :attr:`key` is not found returns ``default``.
89	
90	    Raises
91	    ------
92	        Exception if ``key`` not in ``list_or_dict`` and :attr:`default` is
93	        ``None``.
94	    &quot;&quot;&quot;
95	
96	    keys = key.split(splitval)
97	
98	    success = True
99	    try:
100	        visited = []
101	        parent = None
102	        last_key = None
103	        for key in keys:
104	            if callable(list_or_dict):
105	                if not expand:
106	                    raise KeyNotFoundError(
107	                        ValueError(
108	                            &quot;Trying to get past callable node with expand=False.&quot;
109	                        ),
110	                        keys=keys,
111	                        visited=visited,
112	                    )
113	                list_or_dict = list_or_dict()
114	                parent[last_key] = list_or_dict
115	
116	            last_key = key
117	            parent = list_or_dict
118	
119	            try:
120	                if isinstance(list_or_dict, dict):
</pre>
</div>


</div>
</div>

<div id="issue-27">
<div class="issue-block issue-sev-high">
    <b>hashlib: </b> Use of weak MD5 hash for security. Consider usedforsecurity=False<br>
    <b>Test ID:</b> B324<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/327.html" target="_blank">CWE-327</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/util.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/diffusion_edge/taming/util.py</a><br>
    <b>Line number: </b>33<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b324_hashlib.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b324_hashlib.html</a><br>

<div class="code">
<pre>
1	import os, hashlib
2	import requests
3	from tqdm import tqdm
4	
5	URL_MAP = {
6	    &quot;vgg_lpips&quot;: &quot;https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1&quot;
7	}
8	
9	CKPT_MAP = {
10	    &quot;vgg_lpips&quot;: &quot;vgg.pth&quot;
11	}
12	
13	MD5_MAP = {
14	    &quot;vgg_lpips&quot;: &quot;d507d7349b931f0638a25a48a722f98a&quot;
15	}
16	
17	
18	def download(url, local_path, chunk_size=1024):
19	    os.makedirs(os.path.split(local_path)[0], exist_ok=True)
20	    with requests.get(url, stream=True) as r:
21	        total_size = int(r.headers.get(&quot;content-length&quot;, 0))
22	        with tqdm(total=total_size, unit=&quot;B&quot;, unit_scale=True) as pbar:
23	            with open(local_path, &quot;wb&quot;) as f:
24	                for data in r.iter_content(chunk_size=chunk_size):
25	                    if data:
26	                        f.write(data)
27	                        pbar.update(chunk_size)
28	
29	
30	def md5_hash(path):
31	    with open(path, &quot;rb&quot;) as f:
32	        content = f.read()
33	    return hashlib.md5(content).hexdigest()
34	
35	
36	def get_ckpt_path(name, root, check=False):
37	    assert name in URL_MAP
38	    path = os.path.join(root, CKPT_MAP[name])
39	    if not os.path.exists(path) or (check and not md5_hash(path) == MD5_MAP[name]):
40	        print(&quot;Downloading {} model from {} to {}&quot;.format(name, URL_MAP[name], path))
41	        download(URL_MAP[name], path)
42	        md5 = md5_hash(path)
43	        assert md5 == MD5_MAP[name], md5
44	    return path
45	
46	
47	class KeyNotFoundError(Exception):
48	    def __init__(self, cause, keys=None, visited=None):
49	        self.cause = cause
50	        self.keys = keys
51	        self.visited = visited
52	        messages = list()
53	        if keys is not None:
54	            messages.append(&quot;Key not found: {}&quot;.format(keys))
55	        if visited is not None:
56	            messages.append(&quot;Visited: {}&quot;.format(visited))
57	        messages.append(&quot;Cause:\n{}&quot;.format(cause))
58	        message = &quot;\n&quot;.join(messages)
59	        super().__init__(message)
60	
61	
62	def retrieve(
63	    list_or_dict, key, splitval=&quot;/&quot;, default=None, expand=True, pass_success=False
64	):
65	    &quot;&quot;&quot;Given a nested list or dict return the desired value at key expanding
66	    callable nodes if necessary and :attr:`expand` is ``True``. The expansion
67	    is done in-place.
68	
69	    Parameters
70	    ----------
71	        list_or_dict : list or dict
72	            Possibly nested list or dictionary.
73	        key : str
74	            key/to/value, path like string describing all keys necessary to
75	            consider to get to the desired value. List indices can also be
76	            passed here.
77	        splitval : str
78	            String that defines the delimiter between keys of the
79	            different depth levels in `key`.
80	        default : obj
81	            Value returned if :attr:`key` is not found.
82	        expand : bool
83	            Whether to expand callable nodes on the path or not.
84	
85	    Returns
86	    -------
87	        The desired value or if :attr:`default` is not ``None`` and the
88	        :attr:`key` is not found returns ``default``.
89	
90	    Raises
91	    ------
92	        Exception if ``key`` not in ``list_or_dict`` and :attr:`default` is
93	        ``None``.
94	    &quot;&quot;&quot;
95	
96	    keys = key.split(splitval)
97	
98	    success = True
99	    try:
100	        visited = []
101	        parent = None
102	        last_key = None
103	        for key in keys:
104	            if callable(list_or_dict):
105	                if not expand:
106	                    raise KeyNotFoundError(
107	                        ValueError(
108	                            &quot;Trying to get past callable node with expand=False.&quot;
109	                        ),
110	                        keys=keys,
111	                        visited=visited,
112	                    )
113	                list_or_dict = list_or_dict()
114	                parent[last_key] = list_or_dict
115	
116	            last_key = key
117	            parent = list_or_dict
118	
119	            try:
120	                if isinstance(list_or_dict, dict):
</pre>
</div>


</div>
</div>

<div id="issue-28">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/dsine/models/submodules/efficientnet_repo/setup.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/dsine/models/submodules/efficientnet_repo/setup.py</a><br>
    <b>Line number: </b>13<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot; Setup
2	&quot;&quot;&quot;
3	from setuptools import setup, find_packages
4	from codecs import open
5	from os import path
6	
7	here = path.abspath(path.dirname(__file__))
8	
9	# Get the long description from the README file
10	with open(path.join(here, &#x27;README.md&#x27;), encoding=&#x27;utf-8&#x27;) as f:
11	    long_description = f.read()
12	
13	exec(open(&#x27;geffnet/version.py&#x27;).read())
14	setup(
15	    name=&#x27;geffnet&#x27;,
16	    version=__version__,
17	    description=&#x27;(Generic) EfficientNets for PyTorch&#x27;,
18	    long_description=long_description,
19	    long_description_content_type=&#x27;text/markdown&#x27;,
20	    url=&#x27;https://github.com/rwightman/gen-efficientnet-pytorch&#x27;,
21	    author=&#x27;Ross Wightman&#x27;,
22	    author_email=&#x27;hello@rwightman.com&#x27;,
23	    classifiers=[
24	        # How mature is this project? Common values are
25	        #   3 - Alpha
26	        #   4 - Beta
27	        #   5 - Production/Stable
28	        &#x27;Development Status :: 3 - Alpha&#x27;,
29	        &#x27;Intended Audience :: Education&#x27;,
30	        &#x27;Intended Audience :: Science/Research&#x27;,
31	        &#x27;License :: OSI Approved :: Apache Software License&#x27;,
32	        &#x27;Programming Language :: Python :: 3.6&#x27;,
33	        &#x27;Programming Language :: Python :: 3.7&#x27;,
34	        &#x27;Programming Language :: Python :: 3.8&#x27;,
35	        &#x27;Topic :: Scientific/Engineering&#x27;,
36	        &#x27;Topic :: Scientific/Engineering :: Artificial Intelligence&#x27;,
37	        &#x27;Topic :: Software Development&#x27;,
38	        &#x27;Topic :: Software Development :: Libraries&#x27;,
39	        &#x27;Topic :: Software Development :: Libraries :: Python Modules&#x27;,
40	    ],
41	
42	    # Note that this is a string of words separated by whitespace, not a list.
43	    keywords=&#x27;pytorch pretrained models efficientnet mixnet mobilenetv3 mnasnet&#x27;,
44	    packages=find_packages(exclude=[&#x27;data&#x27;]),
45	    install_requires=[&#x27;torch &gt;= 1.4&#x27;, &#x27;torchvision&#x27;],
46	    python_requires=&#x27;&gt;=3.6&#x27;,
47	)
</pre>
</div>


</div>
</div>

<div id="issue-29">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/mlsd/__init__.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/mlsd/__init__.py</a><br>
    <b>Line number: </b>43<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
1	import os
2	import warnings
3	
4	import cv2
5	import numpy as np
6	import torch
7	from PIL import Image
8	
9	from controlnet_aux.util import HWC3, common_input_validate, resize_image_with_pad, custom_hf_download, HF_MODEL_NAME
10	from .models.mbv2_mlsd_large import MobileV2_MLSD_Large
11	from .utils import pred_lines
12	
13	
14	class MLSDdetector:
15	    def __init__(self, model):
16	        self.model = model
17	
18	    @classmethod
19	    def from_pretrained(cls, pretrained_model_or_path=HF_MODEL_NAME, filename=&quot;mlsd_large_512_fp32.pth&quot;):
20	        subfolder = &quot;annotator/ckpts&quot; if pretrained_model_or_path == &quot;lllyasviel/ControlNet&quot; else &#x27;&#x27;
21	        model_path = custom_hf_download(pretrained_model_or_path, filename, subfolder=subfolder)
22	        model = MobileV2_MLSD_Large()
23	        model.load_state_dict(torch.load(model_path), strict=True)
24	        model.eval()
25	
26	        return cls(model)
27	
28	    def to(self, device):
29	        self.model.to(device)
30	        return self
31	    
32	    def __call__(self, input_image, thr_v=0.1, thr_d=0.1, detect_resolution=512, output_type=&quot;pil&quot;, upscale_method=&quot;INTER_AREA&quot;, **kwargs):
33	        input_image, output_type = common_input_validate(input_image, output_type, **kwargs)
34	        detected_map, remove_pad = resize_image_with_pad(input_image, detect_resolution, upscale_method)
35	        img = detected_map
36	        img_output = np.zeros_like(img)
37	        try:
38	            with torch.no_grad():
39	                lines = pred_lines(img, self.model, [img.shape[0], img.shape[1]], thr_v, thr_d)
40	                for line in lines:
41	                    x_start, y_start, x_end, y_end = [int(val) for val in line]
42	                    cv2.line(img_output, (x_start, y_start), (x_end, y_end), [255, 255, 255], 1)
43	        except Exception as e:
44	            pass
45	
46	        detected_map = remove_pad(HWC3(img_output[:, :, 0]))
47	
48	        if output_type == &quot;pil&quot;:
49	            detected_map = Image.fromarray(detected_map)
50	            
51	        return detected_map
</pre>
</div>


</div>
</div>

<div id="issue-30">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/mlsd/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/mlsd/utils.py</a><br>
    <b>Line number: </b>555<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
495	            if deg_ratio1 &gt; 1.0:
496	                deg_ratio1 = 1 / deg_ratio1
497	            deg_ratio2 = deg1 / deg3
498	            if deg_ratio2 &gt; 1.0:
499	                deg_ratio2 = 1 / deg_ratio2
500	            degree_scores.append((deg_ratio1 + deg_ratio2) / 2)
501	            ######################################
502	            ###################################### LENGTH SCORES
503	            &#x27;&#x27;&#x27;
504	            len0 vs len2
505	            len1 vs len3
506	            &#x27;&#x27;&#x27;
507	            len0, len1, len2, len3 = square_length
508	            len_ratio1 = len0 / len2 if len2 &gt; len0 else len2 / len0
509	            len_ratio2 = len1 / len3 if len3 &gt; len1 else len3 / len1
510	            length_scores.append((len_ratio1 + len_ratio2) / 2)
511	
512	            ######################################
513	
514	        overlap_scores = np.array(overlap_scores)
515	        overlap_scores /= np.max(overlap_scores)
516	
517	        degree_scores = np.array(degree_scores)
518	        # degree_scores /= np.max(degree_scores)
519	
520	        length_scores = np.array(length_scores)
521	
522	        ###################################### AREA SCORES
523	        area_scores = np.reshape(squares, [-1, 4, 2])
524	        area_x = area_scores[:, :, 0]
525	        area_y = area_scores[:, :, 1]
526	        correction = area_x[:, -1] * area_y[:, 0] - area_y[:, -1] * area_x[:, 0]
527	        area_scores = np.sum(area_x[:, :-1] * area_y[:, 1:], axis=-1) - np.sum(area_y[:, :-1] * area_x[:, 1:], axis=-1)
528	        area_scores = 0.5 * np.abs(area_scores + correction)
529	        area_scores /= (map_size * map_size)  # np.max(area_scores)
530	        ######################################
531	
532	        ###################################### CENTER SCORES
533	        centers = np.array([[256 // 2, 256 // 2]], dtype=&#x27;float32&#x27;)  # [1, 2]
534	        # squares: [n, 4, 2]
535	        square_centers = np.mean(squares, axis=1)  # [n, 2]
536	        center2center = np.sqrt(np.sum((centers - square_centers) ** 2))
537	        center_scores = center2center / (map_size / np.sqrt(2.0))
538	
539	        &#x27;&#x27;&#x27;
540	        score_w = [overlap, degree, area, center, length]
541	        &#x27;&#x27;&#x27;
542	        score_w = [0.0, 1.0, 10.0, 0.5, 1.0]
543	        score_array = params[&#x27;w_overlap&#x27;] * overlap_scores \
544	                      + params[&#x27;w_degree&#x27;] * degree_scores \
545	                      + params[&#x27;w_area&#x27;] * area_scores \
546	                      - params[&#x27;w_center&#x27;] * center_scores \
547	                      + params[&#x27;w_length&#x27;] * length_scores
548	
549	        best_square = []
550	
551	        sorted_idx = np.argsort(score_array)[::-1]
552	        score_array = score_array[sorted_idx]
553	        squares = squares[sorted_idx]
554	
555	    except Exception as e:
556	        pass
557	
558	    &#x27;&#x27;&#x27;return list
559	    merged_lines, squares, scores
560	    &#x27;&#x27;&#x27;
561	
562	    try:
563	        new_segments[:, 0] = new_segments[:, 0] * 2 / input_shape[1] * original_shape[1]
564	        new_segments[:, 1] = new_segments[:, 1] * 2 / input_shape[0] * original_shape[0]
565	        new_segments[:, 2] = new_segments[:, 2] * 2 / input_shape[1] * original_shape[1]
566	        new_segments[:, 3] = new_segments[:, 3] * 2 / input_shape[0] * original_shape[0]
567	    except:
568	        new_segments = []
569	
570	    try:
571	        squares[:, :, 0] = squares[:, :, 0] * 2 / input_shape[1] * original_shape[1]
572	        squares[:, :, 1] = squares[:, :, 1] * 2 / input_shape[0] * original_shape[0]
573	    except:
574	        squares = []
575	        score_array = []
576	
577	    try:
578	        inter_points = np.array(inter_points)
579	        inter_points[:, 0] = inter_points[:, 0] * 2 / input_shape[1] * original_shape[1]
580	        inter_points[:, 1] = inter_points[:, 1] * 2 / input_shape[0] * original_shape[0]
581	    except:
582	        inter_points = []
583	
584	    return new_segments, squares, score_array, inter_points
</pre>
</div>


</div>
</div>

<div id="issue-31">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/normalbae/nets/submodules/efficientnet_repo/setup.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/normalbae/nets/submodules/efficientnet_repo/setup.py</a><br>
    <b>Line number: </b>13<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot; Setup
2	&quot;&quot;&quot;
3	from setuptools import setup, find_packages
4	from codecs import open
5	from os import path
6	
7	here = path.abspath(path.dirname(__file__))
8	
9	# Get the long description from the README file
10	with open(path.join(here, &#x27;README.md&#x27;), encoding=&#x27;utf-8&#x27;) as f:
11	    long_description = f.read()
12	
13	exec(open(&#x27;geffnet/version.py&#x27;).read())
14	setup(
15	    name=&#x27;geffnet&#x27;,
16	    version=__version__,
17	    description=&#x27;(Generic) EfficientNets for PyTorch&#x27;,
18	    long_description=long_description,
19	    long_description_content_type=&#x27;text/markdown&#x27;,
20	    url=&#x27;https://github.com/rwightman/gen-efficientnet-pytorch&#x27;,
21	    author=&#x27;Ross Wightman&#x27;,
22	    author_email=&#x27;hello@rwightman.com&#x27;,
23	    classifiers=[
24	        # How mature is this project? Common values are
25	        #   3 - Alpha
26	        #   4 - Beta
27	        #   5 - Production/Stable
28	        &#x27;Development Status :: 3 - Alpha&#x27;,
29	        &#x27;Intended Audience :: Education&#x27;,
30	        &#x27;Intended Audience :: Science/Research&#x27;,
31	        &#x27;License :: OSI Approved :: Apache Software License&#x27;,
32	        &#x27;Programming Language :: Python :: 3.6&#x27;,
33	        &#x27;Programming Language :: Python :: 3.7&#x27;,
34	        &#x27;Programming Language :: Python :: 3.8&#x27;,
35	        &#x27;Topic :: Scientific/Engineering&#x27;,
36	        &#x27;Topic :: Scientific/Engineering :: Artificial Intelligence&#x27;,
37	        &#x27;Topic :: Software Development&#x27;,
38	        &#x27;Topic :: Software Development :: Libraries&#x27;,
39	        &#x27;Topic :: Software Development :: Libraries :: Python Modules&#x27;,
40	    ],
41	
42	    # Note that this is a string of words separated by whitespace, not a list.
43	    keywords=&#x27;pytorch pretrained models efficientnet mixnet mobilenetv3 mnasnet&#x27;,
44	    packages=find_packages(exclude=[&#x27;data&#x27;]),
45	    install_requires=[&#x27;torch &gt;= 1.4&#x27;, &#x27;torchvision&#x27;],
46	    python_requires=&#x27;&gt;=3.6&#x27;,
47	)
</pre>
</div>


</div>
</div>

<div id="issue-32">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/unimatch/utils/dist_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/unimatch/utils/dist_utils.py</a><br>
    <b>Line number: </b>5<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	# https://github.com/open-mmlab/mmcv/blob/7540cf73ac7e5d1e14d0ffbd9b6759e83929ecfc/mmcv/runner/dist_utils.py
3	
4	import os
5	import subprocess
6	
7	import torch
8	import torch.multiprocessing as mp
9	from torch import distributed as dist
10	
11	
12	def init_dist(launcher, backend=&#x27;nccl&#x27;, **kwargs):
13	    if mp.get_start_method(allow_none=True) is None:
14	        mp.set_start_method(&#x27;spawn&#x27;)
15	    if launcher == &#x27;pytorch&#x27;:
16	        _init_dist_pytorch(backend, **kwargs)
17	    elif launcher == &#x27;mpi&#x27;:
18	        _init_dist_mpi(backend, **kwargs)
19	    elif launcher == &#x27;slurm&#x27;:
20	        _init_dist_slurm(backend, **kwargs)
21	    else:
22	        raise ValueError(f&#x27;Invalid launcher type: {launcher}&#x27;)
23	
24	
25	def _init_dist_pytorch(backend, **kwargs):
26	    # TODO: use local_rank instead of rank % num_gpus
27	    rank = int(os.environ[&#x27;RANK&#x27;])
28	    num_gpus = torch.cuda.device_count()
29	    torch.cuda.set_device(rank % num_gpus)
30	    dist.init_process_group(backend=backend, **kwargs)
31	
32	
33	def _init_dist_mpi(backend, **kwargs):
34	    # TODO: use local_rank instead of rank % num_gpus
35	    rank = int(os.environ[&#x27;OMPI_COMM_WORLD_RANK&#x27;])
36	    num_gpus = torch.cuda.device_count()
37	    torch.cuda.set_device(rank % num_gpus)
38	    dist.init_process_group(backend=backend, **kwargs)
39	
40	
41	def _init_dist_slurm(backend, port=None):
42	    &quot;&quot;&quot;Initialize slurm distributed training environment.
43	    If argument ``port`` is not specified, then the master port will be system
44	    environment variable ``MASTER_PORT``. If ``MASTER_PORT`` is not in system
45	    environment variable, then a default port ``29500`` will be used.
46	    Args:
47	        backend (str): Backend of torch.distributed.
48	        port (int, optional): Master port. Defaults to None.
49	    &quot;&quot;&quot;
50	    proc_id = int(os.environ[&#x27;SLURM_PROCID&#x27;])
51	    ntasks = int(os.environ[&#x27;SLURM_NTASKS&#x27;])
52	    node_list = os.environ[&#x27;SLURM_NODELIST&#x27;]
53	    num_gpus = torch.cuda.device_count()
54	    torch.cuda.set_device(proc_id % num_gpus)
55	    addr = subprocess.getoutput(
56	        f&#x27;scontrol show hostname {node_list} | head -n1&#x27;)
57	    # specify master port
58	    if port is not None:
59	        os.environ[&#x27;MASTER_PORT&#x27;] = str(port)
60	    elif &#x27;MASTER_PORT&#x27; in os.environ:
61	        pass  # use MASTER_PORT in the environment variable
62	    else:
63	        # 29500 is torch.distributed default port
64	        os.environ[&#x27;MASTER_PORT&#x27;] = &#x27;29500&#x27;
65	    # use MASTER_ADDR in the environment variable if it already exists
66	    if &#x27;MASTER_ADDR&#x27; not in os.environ:
67	        os.environ[&#x27;MASTER_ADDR&#x27;] = addr
68	    os.environ[&#x27;WORLD_SIZE&#x27;] = str(ntasks)
69	    os.environ[&#x27;LOCAL_RANK&#x27;] = str(proc_id % num_gpus)
70	    os.environ[&#x27;RANK&#x27;] = str(proc_id)
71	    dist.init_process_group(backend=backend)
72	
73	
74	def get_dist_info():
75	    # if (TORCH_VERSION != &#x27;parrots&#x27;
76	    #         and digit_version(TORCH_VERSION) &lt; digit_version(&#x27;1.0&#x27;)):
77	    #     initialized = dist._initialized
78	    # else:
79	    if dist.is_available():
80	        initialized = dist.is_initialized()
81	    else:
82	        initialized = False
83	    if initialized:
84	        rank = dist.get_rank()
85	        world_size = dist.get_world_size()
86	    else:
87	        rank = 0
88	        world_size = 1
89	    return rank, world_size
90	
91	
92	# from DETR repo
93	def setup_for_distributed(is_master):
94	    &quot;&quot;&quot;
95	    This function disables printing when not in master process
96	    &quot;&quot;&quot;
97	    import builtins as __builtin__
98	    builtin_print = __builtin__.print
99	
100	    def print(*args, **kwargs):
101	        force = kwargs.pop(&#x27;force&#x27;, False)
102	        if is_master or force:
103	            builtin_print(*args, **kwargs)
104	
105	    __builtin__.print = print
</pre>
</div>


</div>
</div>

<div id="issue-33">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/unimatch/utils/dist_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/controlnet_aux/unimatch/utils/dist_utils.py</a><br>
    <b>Line number: </b>55<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	# https://github.com/open-mmlab/mmcv/blob/7540cf73ac7e5d1e14d0ffbd9b6759e83929ecfc/mmcv/runner/dist_utils.py
3	
4	import os
5	import subprocess
6	
7	import torch
8	import torch.multiprocessing as mp
9	from torch import distributed as dist
10	
11	
12	def init_dist(launcher, backend=&#x27;nccl&#x27;, **kwargs):
13	    if mp.get_start_method(allow_none=True) is None:
14	        mp.set_start_method(&#x27;spawn&#x27;)
15	    if launcher == &#x27;pytorch&#x27;:
16	        _init_dist_pytorch(backend, **kwargs)
17	    elif launcher == &#x27;mpi&#x27;:
18	        _init_dist_mpi(backend, **kwargs)
19	    elif launcher == &#x27;slurm&#x27;:
20	        _init_dist_slurm(backend, **kwargs)
21	    else:
22	        raise ValueError(f&#x27;Invalid launcher type: {launcher}&#x27;)
23	
24	
25	def _init_dist_pytorch(backend, **kwargs):
26	    # TODO: use local_rank instead of rank % num_gpus
27	    rank = int(os.environ[&#x27;RANK&#x27;])
28	    num_gpus = torch.cuda.device_count()
29	    torch.cuda.set_device(rank % num_gpus)
30	    dist.init_process_group(backend=backend, **kwargs)
31	
32	
33	def _init_dist_mpi(backend, **kwargs):
34	    # TODO: use local_rank instead of rank % num_gpus
35	    rank = int(os.environ[&#x27;OMPI_COMM_WORLD_RANK&#x27;])
36	    num_gpus = torch.cuda.device_count()
37	    torch.cuda.set_device(rank % num_gpus)
38	    dist.init_process_group(backend=backend, **kwargs)
39	
40	
41	def _init_dist_slurm(backend, port=None):
42	    &quot;&quot;&quot;Initialize slurm distributed training environment.
43	    If argument ``port`` is not specified, then the master port will be system
44	    environment variable ``MASTER_PORT``. If ``MASTER_PORT`` is not in system
45	    environment variable, then a default port ``29500`` will be used.
46	    Args:
47	        backend (str): Backend of torch.distributed.
48	        port (int, optional): Master port. Defaults to None.
49	    &quot;&quot;&quot;
50	    proc_id = int(os.environ[&#x27;SLURM_PROCID&#x27;])
51	    ntasks = int(os.environ[&#x27;SLURM_NTASKS&#x27;])
52	    node_list = os.environ[&#x27;SLURM_NODELIST&#x27;]
53	    num_gpus = torch.cuda.device_count()
54	    torch.cuda.set_device(proc_id % num_gpus)
55	    addr = subprocess.getoutput(
56	        f&#x27;scontrol show hostname {node_list} | head -n1&#x27;)
57	    # specify master port
58	    if port is not None:
59	        os.environ[&#x27;MASTER_PORT&#x27;] = str(port)
60	    elif &#x27;MASTER_PORT&#x27; in os.environ:
61	        pass  # use MASTER_PORT in the environment variable
62	    else:
63	        # 29500 is torch.distributed default port
64	        os.environ[&#x27;MASTER_PORT&#x27;] = &#x27;29500&#x27;
65	    # use MASTER_ADDR in the environment variable if it already exists
66	    if &#x27;MASTER_ADDR&#x27; not in os.environ:
67	        os.environ[&#x27;MASTER_ADDR&#x27;] = addr
68	    os.environ[&#x27;WORLD_SIZE&#x27;] = str(ntasks)
69	    os.environ[&#x27;LOCAL_RANK&#x27;] = str(proc_id % num_gpus)
70	    os.environ[&#x27;RANK&#x27;] = str(proc_id)
71	    dist.init_process_group(backend=backend)
72	
73	
74	def get_dist_info():
75	    # if (TORCH_VERSION != &#x27;parrots&#x27;
76	    #         and digit_version(TORCH_VERSION) &lt; digit_version(&#x27;1.0&#x27;)):
77	    #     initialized = dist._initialized
78	    # else:
79	    if dist.is_available():
80	        initialized = dist.is_initialized()
81	    else:
82	        initialized = False
83	    if initialized:
84	        rank = dist.get_rank()
85	        world_size = dist.get_world_size()
86	    else:
87	        rank = 0
88	        world_size = 1
89	    return rank, world_size
90	
91	
92	# from DETR repo
93	def setup_for_distributed(is_master):
94	    &quot;&quot;&quot;
95	    This function disables printing when not in master process
96	    &quot;&quot;&quot;
97	    import builtins as __builtin__
98	    builtin_print = __builtin__.print
99	
100	    def print(*args, **kwargs):
101	        force = kwargs.pop(&#x27;force&#x27;, False)
102	        if is_master or force:
103	            builtin_print(*args, **kwargs)
104	
105	    __builtin__.print = print
</pre>
</div>


</div>
</div>

<div id="issue-34">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/checkpoint/detection_checkpoint.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/checkpoint/detection_checkpoint.py</a><br>
    <b>Line number: </b>4<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import logging
3	import os
4	import pickle
5	from urllib.parse import parse_qs, urlparse
6	import torch
7	from fvcore.common.checkpoint import Checkpointer
8	from torch.nn.parallel import DistributedDataParallel
9	
10	import custom_detectron2.utils.comm as comm
11	from custom_detectron2.utils.file_io import PathManager
12	
13	from .c2_model_loading import align_and_update_state_dicts
14	
15	
16	class DetectionCheckpointer(Checkpointer):
17	    &quot;&quot;&quot;
18	    Same as :class:`Checkpointer`, but is able to:
19	    1. handle models in detectron &amp; detectron2 model zoo, and apply conversions for legacy models.
20	    2. correctly load checkpoints that are only available on the master worker
21	    &quot;&quot;&quot;
22	
23	    def __init__(self, model, save_dir=&quot;&quot;, *, save_to_disk=None, **checkpointables):
24	        is_main_process = comm.is_main_process()
25	        super().__init__(
26	            model,
27	            save_dir,
28	            save_to_disk=is_main_process if save_to_disk is None else save_to_disk,
29	            **checkpointables,
30	        )
31	        self.path_manager = PathManager
32	        self._parsed_url_during_load = None
33	
34	    def load(self, path, *args, **kwargs):
35	        assert self._parsed_url_during_load is None
36	        need_sync = False
37	        logger = logging.getLogger(__name__)
38	        logger.info(&quot;[DetectionCheckpointer] Loading from {} ...&quot;.format(path))
39	
40	        if path and isinstance(self.model, DistributedDataParallel):
41	            path = self.path_manager.get_local_path(path)
42	            has_file = os.path.isfile(path)
43	            all_has_file = comm.all_gather(has_file)
44	            if not all_has_file[0]:
45	                raise OSError(f&quot;File {path} not found on main worker.&quot;)
46	            if not all(all_has_file):
47	                logger.warning(
48	                    f&quot;Not all workers can read checkpoint {path}. &quot;
49	                    &quot;Training may fail to fully resume.&quot;
50	                )
51	                # TODO: broadcast the checkpoint file contents from main
52	                # worker, and load from it instead.
53	                need_sync = True
54	            if not has_file:
55	                path = None  # don&#x27;t load if not readable
56	
57	        if path:
58	            parsed_url = urlparse(path)
59	            self._parsed_url_during_load = parsed_url
60	            path = parsed_url._replace(query=&quot;&quot;).geturl()  # remove query from filename
61	            path = self.path_manager.get_local_path(path)
62	
63	        self.logger.setLevel(&#x27;CRITICAL&#x27;)
64	        ret = super().load(path, *args, **kwargs)
65	
66	        if need_sync:
67	            logger.info(&quot;Broadcasting model states from main worker ...&quot;)
68	            self.model._sync_params_and_buffers()
69	        self._parsed_url_during_load = None  # reset to None
70	        return ret
71	
72	    def _load_file(self, filename):
73	        if filename.endswith(&quot;.pkl&quot;):
74	            with PathManager.open(filename, &quot;rb&quot;) as f:
75	                data = pickle.load(f, encoding=&quot;latin1&quot;)
76	            if &quot;model&quot; in data and &quot;__author__&quot; in data:
77	                # file is in Detectron2 model zoo format
78	                self.logger.info(&quot;Reading a file from &#x27;{}&#x27;&quot;.format(data[&quot;__author__&quot;]))
79	                return data
80	            else:
81	                # assume file is from Caffe2 / Detectron1 model zoo
82	                if &quot;blobs&quot; in data:
83	                    # Detection models have &quot;blobs&quot;, but ImageNet models don&#x27;t
84	                    data = data[&quot;blobs&quot;]
85	                data = {k: v for k, v in data.items() if not k.endswith(&quot;_momentum&quot;)}
86	                return {&quot;model&quot;: data, &quot;__author__&quot;: &quot;Caffe2&quot;, &quot;matching_heuristics&quot;: True}
87	        elif filename.endswith(&quot;.pyth&quot;):
88	            # assume file is from pycls; no one else seems to use the &quot;.pyth&quot; extension
89	            with PathManager.open(filename, &quot;rb&quot;) as f:
90	                data = torch.load(f)
91	            assert (
92	                &quot;model_state&quot; in data
93	            ), f&quot;Cannot load .pyth file {filename}; pycls checkpoints must contain &#x27;model_state&#x27;.&quot;
94	            model_state = {
95	                k: v
96	                for k, v in data[&quot;model_state&quot;].items()
97	                if not k.endswith(&quot;num_batches_tracked&quot;)
98	            }
99	            return {&quot;model&quot;: model_state, &quot;__author__&quot;: &quot;pycls&quot;, &quot;matching_heuristics&quot;: True}
100	
101	        loaded = self._torch_load(filename)
102	        if &quot;model&quot; not in loaded:
103	            loaded = {&quot;model&quot;: loaded}
104	        assert self._parsed_url_during_load is not None, &quot;`_load_file` must be called inside `load`&quot;
105	        parsed_url = self._parsed_url_during_load
106	        queries = parse_qs(parsed_url.query)
107	        if queries.pop(&quot;matching_heuristics&quot;, &quot;False&quot;) == [&quot;True&quot;]:
108	            loaded[&quot;matching_heuristics&quot;] = True
109	        if len(queries) &gt; 0:
110	            raise ValueError(
111	                f&quot;Unsupported query remaining: f{queries}, orginal filename: {parsed_url.geturl()}&quot;
112	            )
113	        return loaded
114	
115	    def _torch_load(self, f):
116	        return super()._load_file(f)
117	
118	    def _load_model(self, checkpoint):
119	        if checkpoint.get(&quot;matching_heuristics&quot;, False):
120	            self._convert_ndarray_to_tensor(checkpoint[&quot;model&quot;])
</pre>
</div>


</div>
</div>

<div id="issue-35">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/checkpoint/detection_checkpoint.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/checkpoint/detection_checkpoint.py</a><br>
    <b>Line number: </b>75<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
15	
16	class DetectionCheckpointer(Checkpointer):
17	    &quot;&quot;&quot;
18	    Same as :class:`Checkpointer`, but is able to:
19	    1. handle models in detectron &amp; detectron2 model zoo, and apply conversions for legacy models.
20	    2. correctly load checkpoints that are only available on the master worker
21	    &quot;&quot;&quot;
22	
23	    def __init__(self, model, save_dir=&quot;&quot;, *, save_to_disk=None, **checkpointables):
24	        is_main_process = comm.is_main_process()
25	        super().__init__(
26	            model,
27	            save_dir,
28	            save_to_disk=is_main_process if save_to_disk is None else save_to_disk,
29	            **checkpointables,
30	        )
31	        self.path_manager = PathManager
32	        self._parsed_url_during_load = None
33	
34	    def load(self, path, *args, **kwargs):
35	        assert self._parsed_url_during_load is None
36	        need_sync = False
37	        logger = logging.getLogger(__name__)
38	        logger.info(&quot;[DetectionCheckpointer] Loading from {} ...&quot;.format(path))
39	
40	        if path and isinstance(self.model, DistributedDataParallel):
41	            path = self.path_manager.get_local_path(path)
42	            has_file = os.path.isfile(path)
43	            all_has_file = comm.all_gather(has_file)
44	            if not all_has_file[0]:
45	                raise OSError(f&quot;File {path} not found on main worker.&quot;)
46	            if not all(all_has_file):
47	                logger.warning(
48	                    f&quot;Not all workers can read checkpoint {path}. &quot;
49	                    &quot;Training may fail to fully resume.&quot;
50	                )
51	                # TODO: broadcast the checkpoint file contents from main
52	                # worker, and load from it instead.
53	                need_sync = True
54	            if not has_file:
55	                path = None  # don&#x27;t load if not readable
56	
57	        if path:
58	            parsed_url = urlparse(path)
59	            self._parsed_url_during_load = parsed_url
60	            path = parsed_url._replace(query=&quot;&quot;).geturl()  # remove query from filename
61	            path = self.path_manager.get_local_path(path)
62	
63	        self.logger.setLevel(&#x27;CRITICAL&#x27;)
64	        ret = super().load(path, *args, **kwargs)
65	
66	        if need_sync:
67	            logger.info(&quot;Broadcasting model states from main worker ...&quot;)
68	            self.model._sync_params_and_buffers()
69	        self._parsed_url_during_load = None  # reset to None
70	        return ret
71	
72	    def _load_file(self, filename):
73	        if filename.endswith(&quot;.pkl&quot;):
74	            with PathManager.open(filename, &quot;rb&quot;) as f:
75	                data = pickle.load(f, encoding=&quot;latin1&quot;)
76	            if &quot;model&quot; in data and &quot;__author__&quot; in data:
77	                # file is in Detectron2 model zoo format
78	                self.logger.info(&quot;Reading a file from &#x27;{}&#x27;&quot;.format(data[&quot;__author__&quot;]))
79	                return data
80	            else:
81	                # assume file is from Caffe2 / Detectron1 model zoo
82	                if &quot;blobs&quot; in data:
83	                    # Detection models have &quot;blobs&quot;, but ImageNet models don&#x27;t
84	                    data = data[&quot;blobs&quot;]
85	                data = {k: v for k, v in data.items() if not k.endswith(&quot;_momentum&quot;)}
86	                return {&quot;model&quot;: data, &quot;__author__&quot;: &quot;Caffe2&quot;, &quot;matching_heuristics&quot;: True}
87	        elif filename.endswith(&quot;.pyth&quot;):
88	            # assume file is from pycls; no one else seems to use the &quot;.pyth&quot; extension
89	            with PathManager.open(filename, &quot;rb&quot;) as f:
90	                data = torch.load(f)
91	            assert (
92	                &quot;model_state&quot; in data
93	            ), f&quot;Cannot load .pyth file {filename}; pycls checkpoints must contain &#x27;model_state&#x27;.&quot;
94	            model_state = {
95	                k: v
96	                for k, v in data[&quot;model_state&quot;].items()
97	                if not k.endswith(&quot;num_batches_tracked&quot;)
98	            }
99	            return {&quot;model&quot;: model_state, &quot;__author__&quot;: &quot;pycls&quot;, &quot;matching_heuristics&quot;: True}
100	
101	        loaded = self._torch_load(filename)
102	        if &quot;model&quot; not in loaded:
103	            loaded = {&quot;model&quot;: loaded}
104	        assert self._parsed_url_during_load is not None, &quot;`_load_file` must be called inside `load`&quot;
105	        parsed_url = self._parsed_url_during_load
106	        queries = parse_qs(parsed_url.query)
107	        if queries.pop(&quot;matching_heuristics&quot;, &quot;False&quot;) == [&quot;True&quot;]:
108	            loaded[&quot;matching_heuristics&quot;] = True
109	        if len(queries) &gt; 0:
110	            raise ValueError(
111	                f&quot;Unsupported query remaining: f{queries}, orginal filename: {parsed_url.geturl()}&quot;
112	            )
113	        return loaded
114	
115	    def _torch_load(self, f):
116	        return super()._load_file(f)
117	
118	    def _load_model(self, checkpoint):
119	        if checkpoint.get(&quot;matching_heuristics&quot;, False):
120	            self._convert_ndarray_to_tensor(checkpoint[&quot;model&quot;])
121	            # convert weights by name-matching heuristics
122	            checkpoint[&quot;model&quot;] = align_and_update_state_dicts(
123	                self.model.state_dict(),
124	                checkpoint[&quot;model&quot;],
125	                c2_conversion=checkpoint.get(&quot;__author__&quot;, None) == &quot;Caffe2&quot;,
126	            )
127	        # for non-caffe2 models, use standard ways to load it
128	        incompatible = super()._load_model(checkpoint)
129	
130	        model_buffers = dict(self.model.named_buffers(recurse=False))
131	        for k in [&quot;pixel_mean&quot;, &quot;pixel_std&quot;]:
132	            # Ignore missing key message about pixel_mean/std.
133	            # Though they may be missing in old checkpoints, they will be correctly
134	            # initialized from config anyway.
</pre>
</div>


</div>
</div>

<div id="issue-36">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py</a><br>
    <b>Line number: </b>161<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
101	@contextmanager
102	def _patch_import():
103	    &quot;&quot;&quot;
104	    Enhance relative import statements in config files, so that they:
105	    1. locate files purely based on relative location, regardless of packages.
106	       e.g. you can import file without having __init__
107	    2. do not cache modules globally; modifications of module states has no side effect
108	    3. support other storage system through PathManager, so config files can be in the cloud
109	    4. imported dict are turned into omegaconf.DictConfig automatically
110	    &quot;&quot;&quot;
111	    old_import = builtins.__import__
112	
113	    def find_relative_file(original_file, relative_import_path, level):
114	        # NOTE: &quot;from . import x&quot; is not handled. Because then it&#x27;s unclear
115	        # if such import should produce `x` as a python module or DictConfig.
116	        # This can be discussed further if needed.
117	        relative_import_err = &quot;&quot;&quot;
118	Relative import of directories is not allowed within config files.
119	Within a config file, relative import can only import other config files.
120	&quot;&quot;&quot;.replace(
121	            &quot;\n&quot;, &quot; &quot;
122	        )
123	        if not len(relative_import_path):
124	            raise ImportError(relative_import_err)
125	
126	        cur_file = os.path.dirname(original_file)
127	        for _ in range(level - 1):
128	            cur_file = os.path.dirname(cur_file)
129	        cur_name = relative_import_path.lstrip(&quot;.&quot;)
130	        for part in cur_name.split(&quot;.&quot;):
131	            cur_file = os.path.join(cur_file, part)
132	        if not cur_file.endswith(&quot;.py&quot;):
133	            cur_file += &quot;.py&quot;
134	        if not PathManager.isfile(cur_file):
135	            cur_file_no_suffix = cur_file[: -len(&quot;.py&quot;)]
136	            if PathManager.isdir(cur_file_no_suffix):
137	                raise ImportError(f&quot;Cannot import from {cur_file_no_suffix}.&quot; + relative_import_err)
138	            else:
139	                raise ImportError(
140	                    f&quot;Cannot import name {relative_import_path} from &quot;
141	                    f&quot;{original_file}: {cur_file} does not exist.&quot;
142	                )
143	        return cur_file
144	
145	    def new_import(name, globals=None, locals=None, fromlist=(), level=0):
146	        if (
147	            # Only deal with relative imports inside config files
148	            level != 0
149	            and globals is not None
150	            and (globals.get(&quot;__package__&quot;, &quot;&quot;) or &quot;&quot;).startswith(_CFG_PACKAGE_NAME)
151	        ):
152	            cur_file = find_relative_file(globals[&quot;__file__&quot;], name, level)
153	            _validate_py_syntax(cur_file)
154	            spec = importlib.machinery.ModuleSpec(
155	                _random_package_name(cur_file), None, origin=cur_file
156	            )
157	            module = importlib.util.module_from_spec(spec)
158	            module.__file__ = cur_file
159	            with PathManager.open(cur_file) as f:
160	                content = f.read()
161	            exec(compile(content, cur_file, &quot;exec&quot;), module.__dict__)
162	            for name in fromlist:  # turn imported dict into DictConfig automatically
163	                val = _cast_to_config(module.__dict__[name])
164	                module.__dict__[name] = val
165	            return module
166	        return old_import(name, globals, locals, fromlist=fromlist, level=level)
167	
168	    builtins.__import__ = new_import
169	    yield new_import
170	    builtins.__import__ = old_import
171	
172	
173	class LazyConfig:
174	    &quot;&quot;&quot;
175	    Provide methods to save, load, and overrides an omegaconf config object
176	    which may contain definition of lazily-constructed objects.
177	    &quot;&quot;&quot;
178	
179	    @staticmethod
180	    def load_rel(filename: str, keys: Union[None, str, Tuple[str, ...]] = None):
181	        &quot;&quot;&quot;
182	        Similar to :meth:`load()`, but load path relative to the caller&#x27;s
183	        source file.
184	
185	        This has the same functionality as a relative import, except that this method
186	        accepts filename as a string, so more characters are allowed in the filename.
187	        &quot;&quot;&quot;
188	        caller_frame = inspect.stack()[1]
189	        caller_fname = caller_frame[0].f_code.co_filename
190	        assert caller_fname != &quot;&lt;string&gt;&quot;, &quot;load_rel Unable to find caller&quot;
191	        caller_dir = os.path.dirname(caller_fname)
192	        filename = os.path.join(caller_dir, filename)
193	        return LazyConfig.load(filename, keys)
194	
195	    @staticmethod
196	    def load(filename: str, keys: Union[None, str, Tuple[str, ...]] = None):
197	        &quot;&quot;&quot;
198	        Load a config file.
199	
200	        Args:
201	            filename: absolute path or relative path w.r.t. the current working directory
202	            keys: keys to load and return. If not given, return all keys
203	                (whose values are config objects) in a dict.
204	        &quot;&quot;&quot;
205	        has_keys = keys is not None
206	        filename = filename.replace(&quot;/./&quot;, &quot;/&quot;)  # redundant
207	        if os.path.splitext(filename)[1] not in [&quot;.py&quot;, &quot;.yaml&quot;, &quot;.yml&quot;]:
208	            raise ValueError(f&quot;Config file {filename} has to be a python or yaml file.&quot;)
209	        if filename.endswith(&quot;.py&quot;):
210	            _validate_py_syntax(filename)
211	
212	            with _patch_import():
213	                # Record the filename
214	                module_namespace = {
215	                    &quot;__file__&quot;: filename,
216	                    &quot;__package__&quot;: _random_package_name(filename),
217	                }
218	                with PathManager.open(filename) as f:
219	                    content = f.read()
220	                # Compile first with filename to:
</pre>
</div>


</div>
</div>

<div id="issue-37">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py</a><br>
    <b>Line number: </b>223<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
163	                val = _cast_to_config(module.__dict__[name])
164	                module.__dict__[name] = val
165	            return module
166	        return old_import(name, globals, locals, fromlist=fromlist, level=level)
167	
168	    builtins.__import__ = new_import
169	    yield new_import
170	    builtins.__import__ = old_import
171	
172	
173	class LazyConfig:
174	    &quot;&quot;&quot;
175	    Provide methods to save, load, and overrides an omegaconf config object
176	    which may contain definition of lazily-constructed objects.
177	    &quot;&quot;&quot;
178	
179	    @staticmethod
180	    def load_rel(filename: str, keys: Union[None, str, Tuple[str, ...]] = None):
181	        &quot;&quot;&quot;
182	        Similar to :meth:`load()`, but load path relative to the caller&#x27;s
183	        source file.
184	
185	        This has the same functionality as a relative import, except that this method
186	        accepts filename as a string, so more characters are allowed in the filename.
187	        &quot;&quot;&quot;
188	        caller_frame = inspect.stack()[1]
189	        caller_fname = caller_frame[0].f_code.co_filename
190	        assert caller_fname != &quot;&lt;string&gt;&quot;, &quot;load_rel Unable to find caller&quot;
191	        caller_dir = os.path.dirname(caller_fname)
192	        filename = os.path.join(caller_dir, filename)
193	        return LazyConfig.load(filename, keys)
194	
195	    @staticmethod
196	    def load(filename: str, keys: Union[None, str, Tuple[str, ...]] = None):
197	        &quot;&quot;&quot;
198	        Load a config file.
199	
200	        Args:
201	            filename: absolute path or relative path w.r.t. the current working directory
202	            keys: keys to load and return. If not given, return all keys
203	                (whose values are config objects) in a dict.
204	        &quot;&quot;&quot;
205	        has_keys = keys is not None
206	        filename = filename.replace(&quot;/./&quot;, &quot;/&quot;)  # redundant
207	        if os.path.splitext(filename)[1] not in [&quot;.py&quot;, &quot;.yaml&quot;, &quot;.yml&quot;]:
208	            raise ValueError(f&quot;Config file {filename} has to be a python or yaml file.&quot;)
209	        if filename.endswith(&quot;.py&quot;):
210	            _validate_py_syntax(filename)
211	
212	            with _patch_import():
213	                # Record the filename
214	                module_namespace = {
215	                    &quot;__file__&quot;: filename,
216	                    &quot;__package__&quot;: _random_package_name(filename),
217	                }
218	                with PathManager.open(filename) as f:
219	                    content = f.read()
220	                # Compile first with filename to:
221	                # 1. make filename appears in stacktrace
222	                # 2. make load_rel able to find its parent&#x27;s (possibly remote) location
223	                exec(compile(content, filename, &quot;exec&quot;), module_namespace)
224	
225	            ret = module_namespace
226	        else:
227	            with PathManager.open(filename) as f:
228	                obj = yaml.unsafe_load(f)
229	            ret = OmegaConf.create(obj, flags={&quot;allow_objects&quot;: True})
230	
231	        if has_keys:
232	            if isinstance(keys, str):
233	                return _cast_to_config(ret[keys])
234	            else:
235	                return tuple(_cast_to_config(ret[a]) for a in keys)
236	        else:
237	            if filename.endswith(&quot;.py&quot;):
238	                # when not specified, only load those that are config objects
239	                ret = DictConfig(
240	                    {
241	                        name: _cast_to_config(value)
242	                        for name, value in ret.items()
243	                        if isinstance(value, (DictConfig, ListConfig, dict))
244	                        and not name.startswith(&quot;_&quot;)
245	                    },
246	                    flags={&quot;allow_objects&quot;: True},
247	                )
248	            return ret
249	
250	    @staticmethod
251	    def save(cfg, filename: str):
252	        &quot;&quot;&quot;
253	        Save a config object to a yaml file.
254	        Note that when the config dictionary contains complex objects (e.g. lambda),
255	        it can&#x27;t be saved to yaml. In that case we will print an error and
256	        attempt to save to a pkl file instead.
257	
258	        Args:
259	            cfg: an omegaconf config object
260	            filename: yaml file name to save the config file
261	        &quot;&quot;&quot;
262	        logger = logging.getLogger(__name__)
263	        try:
264	            cfg = deepcopy(cfg)
265	        except Exception:
266	            pass
267	        else:
268	            # if it&#x27;s deep-copyable, then...
269	            def _replace_type_by_name(x):
270	                if &quot;_target_&quot; in x and callable(x._target_):
271	                    try:
272	                        x._target_ = _convert_target_to_string(x._target_)
273	                    except AttributeError:
274	                        pass
275	
276	            # not necessary, but makes yaml looks nicer
277	            _visit_dict_config(cfg, _replace_type_by_name)
278	
279	        save_pkl = False
280	        try:
281	            dict = OmegaConf.to_container(
282	                cfg,
</pre>
</div>


</div>
</div>

<div id="issue-38">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py</a><br>
    <b>Line number: </b>265<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
205	        has_keys = keys is not None
206	        filename = filename.replace(&quot;/./&quot;, &quot;/&quot;)  # redundant
207	        if os.path.splitext(filename)[1] not in [&quot;.py&quot;, &quot;.yaml&quot;, &quot;.yml&quot;]:
208	            raise ValueError(f&quot;Config file {filename} has to be a python or yaml file.&quot;)
209	        if filename.endswith(&quot;.py&quot;):
210	            _validate_py_syntax(filename)
211	
212	            with _patch_import():
213	                # Record the filename
214	                module_namespace = {
215	                    &quot;__file__&quot;: filename,
216	                    &quot;__package__&quot;: _random_package_name(filename),
217	                }
218	                with PathManager.open(filename) as f:
219	                    content = f.read()
220	                # Compile first with filename to:
221	                # 1. make filename appears in stacktrace
222	                # 2. make load_rel able to find its parent&#x27;s (possibly remote) location
223	                exec(compile(content, filename, &quot;exec&quot;), module_namespace)
224	
225	            ret = module_namespace
226	        else:
227	            with PathManager.open(filename) as f:
228	                obj = yaml.unsafe_load(f)
229	            ret = OmegaConf.create(obj, flags={&quot;allow_objects&quot;: True})
230	
231	        if has_keys:
232	            if isinstance(keys, str):
233	                return _cast_to_config(ret[keys])
234	            else:
235	                return tuple(_cast_to_config(ret[a]) for a in keys)
236	        else:
237	            if filename.endswith(&quot;.py&quot;):
238	                # when not specified, only load those that are config objects
239	                ret = DictConfig(
240	                    {
241	                        name: _cast_to_config(value)
242	                        for name, value in ret.items()
243	                        if isinstance(value, (DictConfig, ListConfig, dict))
244	                        and not name.startswith(&quot;_&quot;)
245	                    },
246	                    flags={&quot;allow_objects&quot;: True},
247	                )
248	            return ret
249	
250	    @staticmethod
251	    def save(cfg, filename: str):
252	        &quot;&quot;&quot;
253	        Save a config object to a yaml file.
254	        Note that when the config dictionary contains complex objects (e.g. lambda),
255	        it can&#x27;t be saved to yaml. In that case we will print an error and
256	        attempt to save to a pkl file instead.
257	
258	        Args:
259	            cfg: an omegaconf config object
260	            filename: yaml file name to save the config file
261	        &quot;&quot;&quot;
262	        logger = logging.getLogger(__name__)
263	        try:
264	            cfg = deepcopy(cfg)
265	        except Exception:
266	            pass
267	        else:
268	            # if it&#x27;s deep-copyable, then...
269	            def _replace_type_by_name(x):
270	                if &quot;_target_&quot; in x and callable(x._target_):
271	                    try:
272	                        x._target_ = _convert_target_to_string(x._target_)
273	                    except AttributeError:
274	                        pass
275	
276	            # not necessary, but makes yaml looks nicer
277	            _visit_dict_config(cfg, _replace_type_by_name)
278	
279	        save_pkl = False
280	        try:
281	            dict = OmegaConf.to_container(
282	                cfg,
283	                # Do not resolve interpolation when saving, i.e. do not turn ${a} into
284	                # actual values when saving.
285	                resolve=False,
286	                # Save structures (dataclasses) in a format that can be instantiated later.
287	                # Without this option, the type information of the dataclass will be erased.
288	                structured_config_mode=SCMode.INSTANTIATE,
289	            )
290	            dumped = yaml.dump(dict, default_flow_style=None, allow_unicode=True, width=9999)
291	            with PathManager.open(filename, &quot;w&quot;) as f:
292	                f.write(dumped)
293	
294	            try:
295	                _ = yaml.unsafe_load(dumped)  # test that it is loadable
296	            except Exception:
297	                logger.warning(
298	                    &quot;The config contains objects that cannot serialize to a valid yaml. &quot;
299	                    f&quot;{filename} is human-readable but cannot be loaded.&quot;
300	                )
301	                save_pkl = True
302	        except Exception:
303	            logger.exception(&quot;Unable to serialize the config to yaml. Error:&quot;)
304	            save_pkl = True
305	
306	        if save_pkl:
307	            new_filename = filename + &quot;.pkl&quot;
308	            # try:
309	            #     # retry by pickle
310	            #     with PathManager.open(new_filename, &quot;wb&quot;) as f:
311	            #         cloudpickle.dump(cfg, f)
312	            #     logger.warning(f&quot;Config is saved using cloudpickle at {new_filename}.&quot;)
313	            # except Exception:
314	            #     pass
315	
316	    @staticmethod
317	    def apply_overrides(cfg, overrides: List[str]):
318	        &quot;&quot;&quot;
319	        In-place override contents of cfg.
320	
321	        Args:
322	            cfg: an omegaconf config object
323	            overrides: list of strings in the format of &quot;a=b&quot; to override configs.
324	                See https://hydra.cc/docs/next/advanced/override_grammar/basic/
325	                for syntax.
</pre>
</div>


</div>
</div>

<div id="issue-39">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Use of possibly insecure function - consider using safer ast.literal_eval.<br>
    <b>Test ID:</b> B307<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/config/lazy.py</a><br>
    <b>Line number: </b>367<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval</a><br>

<div class="code">
<pre>
307	            new_filename = filename + &quot;.pkl&quot;
308	            # try:
309	            #     # retry by pickle
310	            #     with PathManager.open(new_filename, &quot;wb&quot;) as f:
311	            #         cloudpickle.dump(cfg, f)
312	            #     logger.warning(f&quot;Config is saved using cloudpickle at {new_filename}.&quot;)
313	            # except Exception:
314	            #     pass
315	
316	    @staticmethod
317	    def apply_overrides(cfg, overrides: List[str]):
318	        &quot;&quot;&quot;
319	        In-place override contents of cfg.
320	
321	        Args:
322	            cfg: an omegaconf config object
323	            overrides: list of strings in the format of &quot;a=b&quot; to override configs.
324	                See https://hydra.cc/docs/next/advanced/override_grammar/basic/
325	                for syntax.
326	
327	        Returns:
328	            the cfg object
329	        &quot;&quot;&quot;
330	
331	        def safe_update(cfg, key, value):
332	            parts = key.split(&quot;.&quot;)
333	            for idx in range(1, len(parts)):
334	                prefix = &quot;.&quot;.join(parts[:idx])
335	                v = OmegaConf.select(cfg, prefix, default=None)
336	                if v is None:
337	                    break
338	                if not OmegaConf.is_config(v):
339	                    raise KeyError(
340	                        f&quot;Trying to update key {key}, but {prefix} &quot;
341	                        f&quot;is not a config, but has type {type(v)}.&quot;
342	                    )
343	            OmegaConf.update(cfg, key, value, merge=True)
344	
345	        try:
346	            from hydra.core.override_parser.overrides_parser import OverridesParser
347	
348	            has_hydra = True
349	        except ImportError:
350	            has_hydra = False
351	
352	        if has_hydra:
353	            parser = OverridesParser.create()
354	            overrides = parser.parse_overrides(overrides)
355	            for o in overrides:
356	                key = o.key_or_group
357	                value = o.value()
358	                if o.is_delete():
359	                    # TODO support this
360	                    raise NotImplementedError(&quot;deletion is not yet a supported override&quot;)
361	                safe_update(cfg, key, value)
362	        else:
363	            # Fallback. Does not support all the features and error checking like hydra.
364	            for o in overrides:
365	                key, value = o.split(&quot;=&quot;)
366	                try:
367	                    value = eval(value, {})
368	                except NameError:
369	                    pass
370	                safe_update(cfg, key, value)
371	        return cfg
372	
373	    # @staticmethod
374	    # def to_py(cfg, prefix: str = &quot;cfg.&quot;):
375	    #     &quot;&quot;&quot;
376	    #     Try to convert a config object into Python-like psuedo code.
377	    #
378	    #     Note that perfect conversion is not always possible. So the returned
379	    #     results are mainly meant to be human-readable, and not meant to be executed.
380	    #
381	    #     Args:
382	    #         cfg: an omegaconf config object
383	    #         prefix: root name for the resulting code (default: &quot;cfg.&quot;)
384	    #
385	    #
386	    #     Returns:
387	    #         str of formatted Python code
388	    #     &quot;&quot;&quot;
389	    #     import black
390	    #
391	    #     cfg = OmegaConf.to_container(cfg, resolve=True)
392	    #
393	    #     def _to_str(obj, prefix=None, inside_call=False):
394	    #         if prefix is None:
395	    #             prefix = []
396	    #         if isinstance(obj, abc.Mapping) and &quot;_target_&quot; in obj:
397	    #             # Dict representing a function call
398	    #             target = _convert_target_to_string(obj.pop(&quot;_target_&quot;))
399	    #             args = []
400	    #             for k, v in sorted(obj.items()):
401	    #                 args.append(f&quot;{k}={_to_str(v, inside_call=True)}&quot;)
402	    #             args = &quot;, &quot;.join(args)
403	    #             call = f&quot;{target}({args})&quot;
404	    #             return &quot;&quot;.join(prefix) + call
405	    #         elif isinstance(obj, abc.Mapping) and not inside_call:
406	    #             # Dict that is not inside a call is a list of top-level config objects that we
407	    #             # render as one object per line with dot separated prefixes
408	    #             key_list = []
409	    #             for k, v in sorted(obj.items()):
410	    #                 if isinstance(v, abc.Mapping) and &quot;_target_&quot; not in v:
411	    #                     key_list.append(_to_str(v, prefix=prefix + [k + &quot;.&quot;]))
412	    #                 else:
413	    #                     key = &quot;&quot;.join(prefix) + k
414	    #                     key_list.append(f&quot;{key}={_to_str(v)}&quot;)
415	    #             return &quot;\n&quot;.join(key_list)
416	    #         elif isinstance(obj, abc.Mapping):
417	    #             # Dict that is inside a call is rendered as a regular dict
418	    #             return (
419	    #                 &quot;{&quot;
420	    #                 + &quot;,&quot;.join(
421	    #                     f&quot;{repr(k)}: {_to_str(v, inside_call=inside_call)}&quot;
422	    #                     for k, v in sorted(obj.items())
423	    #                 )
424	    #                 + &quot;}&quot;
425	    #             )
426	    #         elif isinstance(obj, list):
</pre>
</div>


</div>
</div>

<div id="issue-40">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/build.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/build.py</a><br>
    <b>Line number: </b>6<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import itertools
3	import logging
4	import numpy as np
5	import operator
6	import pickle
7	from typing import Any, Callable, Dict, List, Optional, Union
8	import torch
9	import torch.utils.data as torchdata
10	from tabulate import tabulate
11	from termcolor import colored
12	
13	from custom_detectron2.config import configurable
14	from custom_detectron2.structures import BoxMode
15	from custom_detectron2.utils.comm import get_world_size
16	from custom_detectron2.utils.env import seed_all_rng
17	from custom_detectron2.utils.file_io import PathManager
18	from custom_detectron2.utils.logger import _log_api_usage, log_first_n
19	
20	from .catalog import DatasetCatalog, MetadataCatalog
21	from .common import AspectRatioGroupedDataset, DatasetFromList, MapDataset, ToIterableDataset
22	from .dataset_mapper import DatasetMapper
23	from .detection_utils import check_metadata_consistency
24	from .samplers import (
25	    InferenceSampler,
26	    RandomSubsetTrainingSampler,
27	    RepeatFactorTrainingSampler,
28	    TrainingSampler,
29	)
30	
31	&quot;&quot;&quot;
32	This file contains the default logic to build a dataloader for training or testing.
33	&quot;&quot;&quot;
34	
35	__all__ = [
36	    &quot;build_batch_data_loader&quot;,
37	    &quot;build_detection_train_loader&quot;,
38	    &quot;build_detection_test_loader&quot;,
39	    &quot;get_detection_dataset_dicts&quot;,
40	    &quot;load_proposals_into_dataset&quot;,
41	    &quot;print_instances_class_histogram&quot;,
42	]
43	
44	
45	def filter_images_with_only_crowd_annotations(dataset_dicts):
46	    &quot;&quot;&quot;
47	    Filter out images with none annotations or only crowd annotations
48	    (i.e., images without non-crowd annotations).
49	    A common training-time preprocessing on COCO dataset.
50	
51	    Args:
52	        dataset_dicts (list[dict]): annotations in Detectron2 Dataset format.
53	
54	    Returns:
55	        list[dict]: the same format, but filtered.
56	    &quot;&quot;&quot;
57	    num_before = len(dataset_dicts)
58	
59	    def valid(anns):
60	        for ann in anns:
61	            if ann.get(&quot;iscrowd&quot;, 0) == 0:
62	                return True
63	        return False
64	
65	    dataset_dicts = [x for x in dataset_dicts if valid(x[&quot;annotations&quot;])]
66	    num_after = len(dataset_dicts)
67	    logger = logging.getLogger(__name__)
68	    logger.info(
69	        &quot;Removed {} images with no usable annotations. {} images left.&quot;.format(
70	            num_before - num_after, num_after
71	        )
72	    )
73	    return dataset_dicts
74	
75	
76	def filter_images_with_few_keypoints(dataset_dicts, min_keypoints_per_image):
77	    &quot;&quot;&quot;
78	    Filter out images with too few number of keypoints.
79	
80	    Args:
81	        dataset_dicts (list[dict]): annotations in Detectron2 Dataset format.
82	
83	    Returns:
84	        list[dict]: the same format as dataset_dicts, but filtered.
85	    &quot;&quot;&quot;
86	    num_before = len(dataset_dicts)
87	
88	    def visible_keypoints_in_image(dic):
89	        # Each keypoints field has the format [x1, y1, v1, ...], where v is visibility
90	        annotations = dic[&quot;annotations&quot;]
91	        return sum(
92	            (np.array(ann[&quot;keypoints&quot;][2::3]) &gt; 0).sum()
93	            for ann in annotations
94	            if &quot;keypoints&quot; in ann
95	        )
96	
97	    dataset_dicts = [
98	        x for x in dataset_dicts if visible_keypoints_in_image(x) &gt;= min_keypoints_per_image
99	    ]
100	    num_after = len(dataset_dicts)
101	    logger = logging.getLogger(__name__)
102	    logger.info(
103	        &quot;Removed {} images with fewer than {} keypoints.&quot;.format(
104	            num_before - num_after, min_keypoints_per_image
105	        )
106	    )
107	    return dataset_dicts
108	
109	
110	def load_proposals_into_dataset(dataset_dicts, proposal_file):
111	    &quot;&quot;&quot;
112	    Load precomputed object proposals into the dataset.
113	
114	    The proposal file should be a pickled dict with the following keys:
115	
116	    - &quot;ids&quot;: list[int] or list[str], the image ids
117	    - &quot;boxes&quot;: list[np.ndarray], each is an Nx4 array of boxes corresponding to the image id
118	    - &quot;objectness_logits&quot;: list[np.ndarray], each is an N sized array of objectness scores
119	      corresponding to the boxes.
120	    - &quot;bbox_mode&quot;: the BoxMode of the boxes array. Defaults to ``BoxMode.XYXY_ABS``.
</pre>
</div>


</div>
</div>

<div id="issue-41">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/build.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/build.py</a><br>
    <b>Line number: </b>133<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
73	    return dataset_dicts
74	
75	
76	def filter_images_with_few_keypoints(dataset_dicts, min_keypoints_per_image):
77	    &quot;&quot;&quot;
78	    Filter out images with too few number of keypoints.
79	
80	    Args:
81	        dataset_dicts (list[dict]): annotations in Detectron2 Dataset format.
82	
83	    Returns:
84	        list[dict]: the same format as dataset_dicts, but filtered.
85	    &quot;&quot;&quot;
86	    num_before = len(dataset_dicts)
87	
88	    def visible_keypoints_in_image(dic):
89	        # Each keypoints field has the format [x1, y1, v1, ...], where v is visibility
90	        annotations = dic[&quot;annotations&quot;]
91	        return sum(
92	            (np.array(ann[&quot;keypoints&quot;][2::3]) &gt; 0).sum()
93	            for ann in annotations
94	            if &quot;keypoints&quot; in ann
95	        )
96	
97	    dataset_dicts = [
98	        x for x in dataset_dicts if visible_keypoints_in_image(x) &gt;= min_keypoints_per_image
99	    ]
100	    num_after = len(dataset_dicts)
101	    logger = logging.getLogger(__name__)
102	    logger.info(
103	        &quot;Removed {} images with fewer than {} keypoints.&quot;.format(
104	            num_before - num_after, min_keypoints_per_image
105	        )
106	    )
107	    return dataset_dicts
108	
109	
110	def load_proposals_into_dataset(dataset_dicts, proposal_file):
111	    &quot;&quot;&quot;
112	    Load precomputed object proposals into the dataset.
113	
114	    The proposal file should be a pickled dict with the following keys:
115	
116	    - &quot;ids&quot;: list[int] or list[str], the image ids
117	    - &quot;boxes&quot;: list[np.ndarray], each is an Nx4 array of boxes corresponding to the image id
118	    - &quot;objectness_logits&quot;: list[np.ndarray], each is an N sized array of objectness scores
119	      corresponding to the boxes.
120	    - &quot;bbox_mode&quot;: the BoxMode of the boxes array. Defaults to ``BoxMode.XYXY_ABS``.
121	
122	    Args:
123	        dataset_dicts (list[dict]): annotations in Detectron2 Dataset format.
124	        proposal_file (str): file path of pre-computed proposals, in pkl format.
125	
126	    Returns:
127	        list[dict]: the same format as dataset_dicts, but added proposal field.
128	    &quot;&quot;&quot;
129	    logger = logging.getLogger(__name__)
130	    logger.info(&quot;Loading proposals from: {}&quot;.format(proposal_file))
131	
132	    with PathManager.open(proposal_file, &quot;rb&quot;) as f:
133	        proposals = pickle.load(f, encoding=&quot;latin1&quot;)
134	
135	    # Rename the key names in D1 proposal files
136	    rename_keys = {&quot;indexes&quot;: &quot;ids&quot;, &quot;scores&quot;: &quot;objectness_logits&quot;}
137	    for key in rename_keys:
138	        if key in proposals:
139	            proposals[rename_keys[key]] = proposals.pop(key)
140	
141	    # Fetch the indexes of all proposals that are in the dataset
142	    # Convert image_id to str since they could be int.
143	    img_ids = set({str(record[&quot;image_id&quot;]) for record in dataset_dicts})
144	    id_to_index = {str(id): i for i, id in enumerate(proposals[&quot;ids&quot;]) if str(id) in img_ids}
145	
146	    # Assuming default bbox_mode of precomputed proposals are &#x27;XYXY_ABS&#x27;
147	    bbox_mode = BoxMode(proposals[&quot;bbox_mode&quot;]) if &quot;bbox_mode&quot; in proposals else BoxMode.XYXY_ABS
148	
149	    for record in dataset_dicts:
150	        # Get the index of the proposal
151	        i = id_to_index[str(record[&quot;image_id&quot;])]
152	
153	        boxes = proposals[&quot;boxes&quot;][i]
154	        objectness_logits = proposals[&quot;objectness_logits&quot;][i]
155	        # Sort the proposals in descending order of the scores
156	        inds = objectness_logits.argsort()[::-1]
157	        record[&quot;proposal_boxes&quot;] = boxes[inds]
158	        record[&quot;proposal_objectness_logits&quot;] = objectness_logits[inds]
159	        record[&quot;proposal_bbox_mode&quot;] = bbox_mode
160	
161	    return dataset_dicts
162	
163	
164	def print_instances_class_histogram(dataset_dicts, class_names):
165	    &quot;&quot;&quot;
166	    Args:
167	        dataset_dicts (list[dict]): list of dataset dicts.
168	        class_names (list[str]): list of class names (zero-indexed).
169	    &quot;&quot;&quot;
170	    num_classes = len(class_names)
171	    hist_bins = np.arange(num_classes + 1)
172	    histogram = np.zeros((num_classes,), dtype=np.int)
173	    for entry in dataset_dicts:
174	        annos = entry[&quot;annotations&quot;]
175	        classes = np.asarray(
176	            [x[&quot;category_id&quot;] for x in annos if not x.get(&quot;iscrowd&quot;, 0)], dtype=np.int
177	        )
178	        if len(classes):
179	            assert classes.min() &gt;= 0, f&quot;Got an invalid category_id={classes.min()}&quot;
180	            assert (
181	                classes.max() &lt; num_classes
182	            ), f&quot;Got an invalid category_id={classes.max()} for a dataset of {num_classes} classes&quot;
183	        histogram += np.histogram(classes, bins=hist_bins)[0]
184	
185	    N_COLS = min(6, len(class_names) * 2)
186	
187	    def short_name(x):
188	        # make long class names shorter. useful for lvis
189	        if len(x) &gt; 13:
190	            return x[:11] + &quot;..&quot;
191	        return x
192	
</pre>
</div>


</div>
</div>

<div id="issue-42">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/common.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/common.py</a><br>
    <b>Line number: </b>7<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import contextlib
3	import copy
4	import itertools
5	import logging
6	import numpy as np
7	import pickle
8	import random
9	from typing import Callable, Union
10	import torch
11	import torch.utils.data as data
12	from torch.utils.data.sampler import Sampler
13	
14	from custom_detectron2.utils.serialize import PicklableWrapper
15	
16	__all__ = [&quot;MapDataset&quot;, &quot;DatasetFromList&quot;, &quot;AspectRatioGroupedDataset&quot;, &quot;ToIterableDataset&quot;]
17	
18	logger = logging.getLogger(__name__)
19	
20	
21	def _shard_iterator_dataloader_worker(iterable):
22	    # Shard the iterable if we&#x27;re currently inside pytorch dataloader worker.
23	    worker_info = data.get_worker_info()
24	    if worker_info is None or worker_info.num_workers == 1:
25	        # do nothing
26	        yield from iterable
27	    else:
28	        yield from itertools.islice(iterable, worker_info.id, None, worker_info.num_workers)
29	
30	
31	class _MapIterableDataset(data.IterableDataset):
32	    &quot;&quot;&quot;
33	    Map a function over elements in an IterableDataset.
34	
35	    Similar to pytorch&#x27;s MapIterDataPipe, but support filtering when map_func
36	    returns None.
37	
38	    This class is not public-facing. Will be called by `MapDataset`.
39	    &quot;&quot;&quot;
40	
41	    def __init__(self, dataset, map_func):
42	        self._dataset = dataset
43	        self._map_func = PicklableWrapper(map_func)  # wrap so that a lambda will work
44	
45	    def __len__(self):
46	        return len(self._dataset)
47	
48	    def __iter__(self):
49	        for x in map(self._map_func, self._dataset):
50	            if x is not None:
51	                yield x
52	
53	
54	class MapDataset(data.Dataset):
55	    &quot;&quot;&quot;
56	    Map a function over the elements in a dataset.
57	    &quot;&quot;&quot;
58	
59	    def __init__(self, dataset, map_func):
60	        &quot;&quot;&quot;
61	        Args:
62	            dataset: a dataset where map function is applied. Can be either
63	                map-style or iterable dataset. When given an iterable dataset,
64	                the returned object will also be an iterable dataset.
65	            map_func: a callable which maps the element in dataset. map_func can
66	                return None to skip the data (e.g. in case of errors).
67	                How None is handled depends on the style of `dataset`.
68	                If `dataset` is map-style, it randomly tries other elements.
69	                If `dataset` is iterable, it skips the data and tries the next.
70	        &quot;&quot;&quot;
71	        self._dataset = dataset
72	        self._map_func = PicklableWrapper(map_func)  # wrap so that a lambda will work
73	
74	        self._rng = random.Random(42)
75	        self._fallback_candidates = set(range(len(dataset)))
76	
77	    def __new__(cls, dataset, map_func):
78	        is_iterable = isinstance(dataset, data.IterableDataset)
79	        if is_iterable:
80	            return _MapIterableDataset(dataset, map_func)
81	        else:
82	            return super().__new__(cls)
83	
84	    def __getnewargs__(self):
85	        return self._dataset, self._map_func
86	
87	    def __len__(self):
88	        return len(self._dataset)
89	
90	    def __getitem__(self, idx):
91	        retry_count = 0
92	        cur_idx = int(idx)
93	
94	        while True:
95	            data = self._map_func(self._dataset[cur_idx])
96	            if data is not None:
97	                self._fallback_candidates.add(cur_idx)
98	                return data
99	
100	            # _map_func fails for this idx, use a random new index from the pool
101	            retry_count += 1
102	            self._fallback_candidates.discard(cur_idx)
103	            cur_idx = self._rng.sample(self._fallback_candidates, k=1)[0]
104	
105	            if retry_count &gt;= 3:
106	                logger = logging.getLogger(__name__)
107	                logger.warning(
108	                    &quot;Failed to apply `_map_func` for idx: {}, retry count: {}&quot;.format(
109	                        idx, retry_count
110	                    )
111	                )
112	
113	
114	class _TorchSerializedList(object):
115	    &quot;&quot;&quot;
116	    A list-like object whose items are serialized and stored in a torch tensor. When
117	    launching a process that uses TorchSerializedList with &quot;fork&quot; start method,
118	    the subprocess can read the same buffer without triggering copy-on-access. When
119	    launching a process that uses TorchSerializedList with &quot;spawn/forkserver&quot; start
120	    method, the list will be pickled by a special ForkingPickler registered by PyTorch
</pre>
</div>


</div>
</div>

<div id="issue-43">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/common.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/common.py</a><br>
    <b>Line number: </b>156<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
96	            if data is not None:
97	                self._fallback_candidates.add(cur_idx)
98	                return data
99	
100	            # _map_func fails for this idx, use a random new index from the pool
101	            retry_count += 1
102	            self._fallback_candidates.discard(cur_idx)
103	            cur_idx = self._rng.sample(self._fallback_candidates, k=1)[0]
104	
105	            if retry_count &gt;= 3:
106	                logger = logging.getLogger(__name__)
107	                logger.warning(
108	                    &quot;Failed to apply `_map_func` for idx: {}, retry count: {}&quot;.format(
109	                        idx, retry_count
110	                    )
111	                )
112	
113	
114	class _TorchSerializedList(object):
115	    &quot;&quot;&quot;
116	    A list-like object whose items are serialized and stored in a torch tensor. When
117	    launching a process that uses TorchSerializedList with &quot;fork&quot; start method,
118	    the subprocess can read the same buffer without triggering copy-on-access. When
119	    launching a process that uses TorchSerializedList with &quot;spawn/forkserver&quot; start
120	    method, the list will be pickled by a special ForkingPickler registered by PyTorch
121	    that moves data to shared memory. In both cases, this allows parent and child
122	    processes to share RAM for the list data, hence avoids the issue in
123	    https://github.com/pytorch/pytorch/issues/13246.
124	
125	    See also https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/
126	    on how it works.
127	    &quot;&quot;&quot;
128	
129	    def __init__(self, lst: list):
130	        self._lst = lst
131	
132	        def _serialize(data):
133	            buffer = pickle.dumps(data, protocol=-1)
134	            return np.frombuffer(buffer, dtype=np.uint8)
135	
136	        logger.info(
137	            &quot;Serializing {} elements to byte tensors and concatenating them all ...&quot;.format(
138	                len(self._lst)
139	            )
140	        )
141	        self._lst = [_serialize(x) for x in self._lst]
142	        self._addr = np.asarray([len(x) for x in self._lst], dtype=np.int64)
143	        self._addr = torch.from_numpy(np.cumsum(self._addr))
144	        self._lst = torch.from_numpy(np.concatenate(self._lst))
145	        logger.info(&quot;Serialized dataset takes {:.2f} MiB&quot;.format(len(self._lst) / 1024**2))
146	
147	    def __len__(self):
148	        return len(self._addr)
149	
150	    def __getitem__(self, idx):
151	        start_addr = 0 if idx == 0 else self._addr[idx - 1].item()
152	        end_addr = self._addr[idx].item()
153	        bytes = memoryview(self._lst[start_addr:end_addr].numpy())
154	
155	        # @lint-ignore PYTHONPICKLEISBAD
156	        return pickle.loads(bytes)
157	
158	
159	_DEFAULT_DATASET_FROM_LIST_SERIALIZE_METHOD = _TorchSerializedList
160	
161	
162	@contextlib.contextmanager
163	def set_default_dataset_from_list_serialize_method(new):
164	    &quot;&quot;&quot;
165	    Context manager for using custom serialize function when creating DatasetFromList
166	    &quot;&quot;&quot;
167	
168	    global _DEFAULT_DATASET_FROM_LIST_SERIALIZE_METHOD
169	    orig = _DEFAULT_DATASET_FROM_LIST_SERIALIZE_METHOD
170	    _DEFAULT_DATASET_FROM_LIST_SERIALIZE_METHOD = new
171	    yield
172	    _DEFAULT_DATASET_FROM_LIST_SERIALIZE_METHOD = orig
173	
174	
175	class DatasetFromList(data.Dataset):
176	    &quot;&quot;&quot;
177	    Wrap a list to a torch Dataset. It produces elements of the list as data.
178	    &quot;&quot;&quot;
179	
180	    def __init__(
181	        self,
182	        lst: list,
183	        copy: bool = True,
184	        serialize: Union[bool, Callable] = True,
185	    ):
186	        &quot;&quot;&quot;
187	        Args:
188	            lst (list): a list which contains elements to produce.
189	            copy (bool): whether to deepcopy the element when producing it,
190	                so that the result can be modified in place without affecting the
191	                source in the list.
192	            serialize (bool or callable): whether to serialize the stroage to other
193	                backend. If `True`, the default serialize method will be used, if given
194	                a callable, the callable will be used as serialize method.
195	        &quot;&quot;&quot;
196	        self._lst = lst
197	        self._copy = copy
198	        if not isinstance(serialize, (bool, Callable)):
199	            raise TypeError(f&quot;Unsupported type for argument `serailzie`: {serialize}&quot;)
200	        self._serialize = serialize is not False
201	
202	        if self._serialize:
203	            serialize_method = (
204	                serialize
205	                if isinstance(serialize, Callable)
206	                else _DEFAULT_DATASET_FROM_LIST_SERIALIZE_METHOD
207	            )
208	            logger.info(f&quot;Serializing the dataset using: {serialize_method}&quot;)
209	            self._lst = serialize_method(self._lst)
210	
211	    def __len__(self):
212	        return len(self._lst)
213	
214	    def __getitem__(self, idx):
215	        if self._copy and not self._serialize:
</pre>
</div>


</div>
</div>

<div id="issue-44">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Using xml.etree.ElementTree to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree with the equivalent defusedxml package, or make sure defusedxml.defuse_stdlib() is called.<br>
    <b>Test ID:</b> B405<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/datasets/pascal_voc.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/datasets/pascal_voc.py</a><br>
    <b>Line number: </b>6<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b405-import-xml-etree" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b405-import-xml-etree</a><br>

<div class="code">
<pre>
1	# -*- coding: utf-8 -*-
2	# Copyright (c) Facebook, Inc. and its affiliates.
3	
4	import numpy as np
5	import os
6	import xml.etree.ElementTree as ET
7	from typing import List, Tuple, Union
8	
9	from custom_detectron2.data import DatasetCatalog, MetadataCatalog
10	from custom_detectron2.structures import BoxMode
11	from custom_detectron2.utils.file_io import PathManager
12	
13	__all__ = [&quot;load_voc_instances&quot;, &quot;register_pascal_voc&quot;]
14	
15	
16	# fmt: off
17	CLASS_NAMES = (
18	    &quot;aeroplane&quot;, &quot;bicycle&quot;, &quot;bird&quot;, &quot;boat&quot;, &quot;bottle&quot;, &quot;bus&quot;, &quot;car&quot;, &quot;cat&quot;,
19	    &quot;chair&quot;, &quot;cow&quot;, &quot;diningtable&quot;, &quot;dog&quot;, &quot;horse&quot;, &quot;motorbike&quot;, &quot;person&quot;,
20	    &quot;pottedplant&quot;, &quot;sheep&quot;, &quot;sofa&quot;, &quot;train&quot;, &quot;tvmonitor&quot;
21	)
22	# fmt: on
23	
24	
25	def load_voc_instances(dirname: str, split: str, class_names: Union[List[str], Tuple[str, ...]]):
26	    &quot;&quot;&quot;
27	    Load Pascal VOC detection annotations to Detectron2 format.
28	
29	    Args:
30	        dirname: Contain &quot;Annotations&quot;, &quot;ImageSets&quot;, &quot;JPEGImages&quot;
31	        split (str): one of &quot;train&quot;, &quot;test&quot;, &quot;val&quot;, &quot;trainval&quot;
32	        class_names: list or tuple of class names
33	    &quot;&quot;&quot;
34	    with PathManager.open(os.path.join(dirname, &quot;ImageSets&quot;, &quot;Main&quot;, split + &quot;.txt&quot;)) as f:
35	        fileids = np.loadtxt(f, dtype=np.str)
36	
37	    # Needs to read many small annotation files. Makes sense at local
38	    annotation_dirname = PathManager.get_local_path(os.path.join(dirname, &quot;Annotations/&quot;))
39	    dicts = []
40	    for fileid in fileids:
41	        anno_file = os.path.join(annotation_dirname, fileid + &quot;.xml&quot;)
42	        jpeg_file = os.path.join(dirname, &quot;JPEGImages&quot;, fileid + &quot;.jpg&quot;)
43	
44	        with PathManager.open(anno_file) as f:
45	            tree = ET.parse(f)
46	
47	        r = {
48	            &quot;file_name&quot;: jpeg_file,
49	            &quot;image_id&quot;: fileid,
50	            &quot;height&quot;: int(tree.findall(&quot;./size/height&quot;)[0].text),
51	            &quot;width&quot;: int(tree.findall(&quot;./size/width&quot;)[0].text),
52	        }
53	        instances = []
54	
55	        for obj in tree.findall(&quot;object&quot;):
56	            cls = obj.find(&quot;name&quot;).text
57	            # We include &quot;difficult&quot; samples in training.
58	            # Based on limited experiments, they don&#x27;t hurt accuracy.
59	            # difficult = int(obj.find(&quot;difficult&quot;).text)
60	            # if difficult == 1:
61	            # continue
62	            bbox = obj.find(&quot;bndbox&quot;)
63	            bbox = [float(bbox.find(x).text) for x in [&quot;xmin&quot;, &quot;ymin&quot;, &quot;xmax&quot;, &quot;ymax&quot;]]
64	            # Original annotations are integers in the range [1, W or H]
65	            # Assuming they mean 1-based pixel indices (inclusive),
66	            # a box with annotation (xmin=1, xmax=W) covers the whole image.
67	            # In coordinate space this is represented by (xmin=0, xmax=W)
68	            bbox[0] -= 1.0
69	            bbox[1] -= 1.0
70	            instances.append(
71	                {&quot;category_id&quot;: class_names.index(cls), &quot;bbox&quot;: bbox, &quot;bbox_mode&quot;: BoxMode.XYXY_ABS}
72	            )
73	        r[&quot;annotations&quot;] = instances
74	        dicts.append(r)
75	    return dicts
76	
77	
78	def register_pascal_voc(name, dirname, split, year, class_names=CLASS_NAMES):
79	    DatasetCatalog.register(name, lambda: load_voc_instances(dirname, split, class_names))
80	    MetadataCatalog.get(name).set(
81	        thing_classes=list(class_names), dirname=dirname, year=year, split=split
82	    )
</pre>
</div>


</div>
</div>

<div id="issue-45">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Using xml.etree.ElementTree.parse to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree.parse with its defusedxml equivalent function or make sure defusedxml.defuse_stdlib() is called<br>
    <b>Test ID:</b> B314<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/datasets/pascal_voc.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/data/datasets/pascal_voc.py</a><br>
    <b>Line number: </b>45<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b313-b320-xml-bad-elementtree" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b313-b320-xml-bad-elementtree</a><br>

<div class="code">
<pre>
1	# -*- coding: utf-8 -*-
2	# Copyright (c) Facebook, Inc. and its affiliates.
3	
4	import numpy as np
5	import os
6	import xml.etree.ElementTree as ET
7	from typing import List, Tuple, Union
8	
9	from custom_detectron2.data import DatasetCatalog, MetadataCatalog
10	from custom_detectron2.structures import BoxMode
11	from custom_detectron2.utils.file_io import PathManager
12	
13	__all__ = [&quot;load_voc_instances&quot;, &quot;register_pascal_voc&quot;]
14	
15	
16	# fmt: off
17	CLASS_NAMES = (
18	    &quot;aeroplane&quot;, &quot;bicycle&quot;, &quot;bird&quot;, &quot;boat&quot;, &quot;bottle&quot;, &quot;bus&quot;, &quot;car&quot;, &quot;cat&quot;,
19	    &quot;chair&quot;, &quot;cow&quot;, &quot;diningtable&quot;, &quot;dog&quot;, &quot;horse&quot;, &quot;motorbike&quot;, &quot;person&quot;,
20	    &quot;pottedplant&quot;, &quot;sheep&quot;, &quot;sofa&quot;, &quot;train&quot;, &quot;tvmonitor&quot;
21	)
22	# fmt: on
23	
24	
25	def load_voc_instances(dirname: str, split: str, class_names: Union[List[str], Tuple[str, ...]]):
26	    &quot;&quot;&quot;
27	    Load Pascal VOC detection annotations to Detectron2 format.
28	
29	    Args:
30	        dirname: Contain &quot;Annotations&quot;, &quot;ImageSets&quot;, &quot;JPEGImages&quot;
31	        split (str): one of &quot;train&quot;, &quot;test&quot;, &quot;val&quot;, &quot;trainval&quot;
32	        class_names: list or tuple of class names
33	    &quot;&quot;&quot;
34	    with PathManager.open(os.path.join(dirname, &quot;ImageSets&quot;, &quot;Main&quot;, split + &quot;.txt&quot;)) as f:
35	        fileids = np.loadtxt(f, dtype=np.str)
36	
37	    # Needs to read many small annotation files. Makes sense at local
38	    annotation_dirname = PathManager.get_local_path(os.path.join(dirname, &quot;Annotations/&quot;))
39	    dicts = []
40	    for fileid in fileids:
41	        anno_file = os.path.join(annotation_dirname, fileid + &quot;.xml&quot;)
42	        jpeg_file = os.path.join(dirname, &quot;JPEGImages&quot;, fileid + &quot;.jpg&quot;)
43	
44	        with PathManager.open(anno_file) as f:
45	            tree = ET.parse(f)
46	
47	        r = {
48	            &quot;file_name&quot;: jpeg_file,
49	            &quot;image_id&quot;: fileid,
50	            &quot;height&quot;: int(tree.findall(&quot;./size/height&quot;)[0].text),
51	            &quot;width&quot;: int(tree.findall(&quot;./size/width&quot;)[0].text),
52	        }
53	        instances = []
54	
55	        for obj in tree.findall(&quot;object&quot;):
56	            cls = obj.find(&quot;name&quot;).text
57	            # We include &quot;difficult&quot; samples in training.
58	            # Based on limited experiments, they don&#x27;t hurt accuracy.
59	            # difficult = int(obj.find(&quot;difficult&quot;).text)
60	            # if difficult == 1:
61	            # continue
62	            bbox = obj.find(&quot;bndbox&quot;)
63	            bbox = [float(bbox.find(x).text) for x in [&quot;xmin&quot;, &quot;ymin&quot;, &quot;xmax&quot;, &quot;ymax&quot;]]
64	            # Original annotations are integers in the range [1, W or H]
65	            # Assuming they mean 1-based pixel indices (inclusive),
66	            # a box with annotation (xmin=1, xmax=W) covers the whole image.
67	            # In coordinate space this is represented by (xmin=0, xmax=W)
68	            bbox[0] -= 1.0
69	            bbox[1] -= 1.0
70	            instances.append(
71	                {&quot;category_id&quot;: class_names.index(cls), &quot;bbox&quot;: bbox, &quot;bbox_mode&quot;: BoxMode.XYXY_ABS}
72	            )
73	        r[&quot;annotations&quot;] = instances
74	        dicts.append(r)
75	    return dicts
76	
77	
78	def register_pascal_voc(name, dirname, split, year, class_names=CLASS_NAMES):
79	    DatasetCatalog.register(name, lambda: load_voc_instances(dirname, split, class_names))
80	    MetadataCatalog.get(name).set(
81	        thing_classes=list(class_names), dirname=dirname, year=year, split=split
82	    )
</pre>
</div>


</div>
</div>

<div id="issue-46">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/coco_evaluation.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/coco_evaluation.py</a><br>
    <b>Line number: </b>10<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import contextlib
3	import copy
4	import io
5	import itertools
6	import json
7	import logging
8	import numpy as np
9	import os
10	import pickle
11	from collections import OrderedDict
12	import custom_pycocotools.mask as mask_util
13	import torch
14	from custom_pycocotools.coco import COCO
15	from custom_pycocotools.cocoeval import COCOeval
16	from tabulate import tabulate
17	
18	import custom_detectron2.utils.comm as comm
19	from custom_detectron2.config import CfgNode
20	from custom_detectron2.data import MetadataCatalog
21	from custom_detectron2.data.datasets.coco import convert_to_coco_json
22	from custom_detectron2.structures import Boxes, BoxMode, pairwise_iou
23	from custom_detectron2.utils.file_io import PathManager
24	from custom_detectron2.utils.logger import create_small_table
25	
26	from .evaluator import DatasetEvaluator
27	
28	try:
29	    from custom_detectron2.evaluation.fast_eval_api import COCOeval_opt
30	except ImportError:
31	    COCOeval_opt = COCOeval
32	
33	
34	class COCOEvaluator(DatasetEvaluator):
35	    &quot;&quot;&quot;
36	    Evaluate AR for object proposals, AP for instance detection/segmentation, AP
37	    for keypoint detection outputs using COCO&#x27;s metrics.
38	    See http://cocodataset.org/#detection-eval and
39	    http://cocodataset.org/#keypoints-eval to understand its metrics.
40	    The metrics range from 0 to 100 (instead of 0 to 1), where a -1 or NaN means
41	    the metric cannot be computed (e.g. due to no predictions made).
42	
43	    In addition to COCO, this evaluator is able to support any bounding box detection,
44	    instance segmentation, or keypoint detection dataset.
45	    &quot;&quot;&quot;
46	
47	    def __init__(
48	        self,
49	        dataset_name,
50	        tasks=None,
51	        distributed=True,
52	        output_dir=None,
53	        *,
54	        max_dets_per_image=None,
55	        use_fast_impl=True,
56	        kpt_oks_sigmas=(),
57	        allow_cached_coco=True,
58	    ):
59	        &quot;&quot;&quot;
60	        Args:
61	            dataset_name (str): name of the dataset to be evaluated.
62	                It must have either the following corresponding metadata:
63	
64	                    &quot;json_file&quot;: the path to the COCO format annotation
65	
66	                Or it must be in detectron2&#x27;s standard dataset format
67	                so it can be converted to COCO format automatically.
68	            tasks (tuple[str]): tasks that can be evaluated under the given
69	                configuration. A task is one of &quot;bbox&quot;, &quot;segm&quot;, &quot;keypoints&quot;.
70	                By default, will infer this automatically from predictions.
71	            distributed (True): if True, will collect results from all ranks and run evaluation
72	                in the main process.
73	                Otherwise, will only evaluate the results in the current process.
74	            output_dir (str): optional, an output directory to dump all
75	                results predicted on the dataset. The dump contains two files:
76	
77	                1. &quot;instances_predictions.pth&quot; a file that can be loaded with `torch.load` and
78	                   contains all the results in the format they are produced by the model.
79	                2. &quot;coco_instances_results.json&quot; a json file in COCO&#x27;s result format.
80	            max_dets_per_image (int): limit on the maximum number of detections per image.
81	                By default in COCO, this limit is to 100, but this can be customized
82	                to be greater, as is needed in evaluation metrics AP fixed and AP pool
83	                (see https://arxiv.org/pdf/2102.01066.pdf)
84	                This doesn&#x27;t affect keypoint evaluation.
85	            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.
86	                Although the results should be very close to the official implementation in COCO
87	                API, it is still recommended to compute results with the official API for use in
88	                papers. The faster implementation also uses more RAM.
89	            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.
90	                See http://cocodataset.org/#keypoints-eval
91	                When empty, it will use the defaults in COCO.
92	                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.
93	            allow_cached_coco (bool): Whether to use cached coco json from previous validation
94	                runs. You should set this to False if you need to use different validation data.
95	                Defaults to True.
96	        &quot;&quot;&quot;
97	        self._logger = logging.getLogger(__name__)
98	        self._distributed = distributed
99	        self._output_dir = output_dir
100	
101	        if use_fast_impl and (COCOeval_opt is COCOeval):
102	            self._logger.info(&quot;Fast COCO eval is not built. Falling back to official COCO eval.&quot;)
103	            use_fast_impl = False
104	        self._use_fast_impl = use_fast_impl
105	
106	        # COCOeval requires the limit on the number of detections per image (maxDets) to be a list
107	        # with at least 3 elements. The default maxDets in COCOeval is [1, 10, 100], in which the
108	        # 3rd element (100) is used as the limit on the number of detections per image when
109	        # evaluating AP. COCOEvaluator expects an integer for max_dets_per_image, so for COCOeval,
110	        # we reformat max_dets_per_image into [1, 10, max_dets_per_image], based on the defaults.
111	        if max_dets_per_image is None:
112	            max_dets_per_image = [1, 10, 100]
113	        else:
114	            max_dets_per_image = [1, 10, max_dets_per_image]
115	        self._max_dets_per_image = max_dets_per_image
116	
117	        if tasks is not None and isinstance(tasks, CfgNode):
118	            kpt_oks_sigmas = (
119	                tasks.TEST.KEYPOINT_OKS_SIGMAS if not kpt_oks_sigmas else kpt_oks_sigmas
120	            )
</pre>
</div>


</div>
</div>

<div id="issue-47">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/lvis_evaluation.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/lvis_evaluation.py</a><br>
    <b>Line number: </b>7<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import copy
3	import itertools
4	import json
5	import logging
6	import os
7	import pickle
8	from collections import OrderedDict
9	import torch
10	
11	import custom_detectron2.utils.comm as comm
12	from custom_detectron2.config import CfgNode
13	from custom_detectron2.data import MetadataCatalog
14	from custom_detectron2.structures import Boxes, BoxMode, pairwise_iou
15	from custom_detectron2.utils.file_io import PathManager
16	from custom_detectron2.utils.logger import create_small_table
17	
18	from .coco_evaluation import instances_to_coco_json
19	from .evaluator import DatasetEvaluator
20	
21	
22	class LVISEvaluator(DatasetEvaluator):
23	    &quot;&quot;&quot;
24	    Evaluate object proposal and instance detection/segmentation outputs using
25	    LVIS&#x27;s metrics and evaluation API.
26	    &quot;&quot;&quot;
27	
28	    def __init__(
29	        self,
30	        dataset_name,
31	        tasks=None,
32	        distributed=True,
33	        output_dir=None,
34	        *,
35	        max_dets_per_image=None,
36	    ):
37	        &quot;&quot;&quot;
38	        Args:
39	            dataset_name (str): name of the dataset to be evaluated.
40	                It must have the following corresponding metadata:
41	                &quot;json_file&quot;: the path to the LVIS format annotation
42	            tasks (tuple[str]): tasks that can be evaluated under the given
43	                configuration. A task is one of &quot;bbox&quot;, &quot;segm&quot;.
44	                By default, will infer this automatically from predictions.
45	            distributed (True): if True, will collect results from all ranks for evaluation.
46	                Otherwise, will evaluate the results in the current process.
47	            output_dir (str): optional, an output directory to dump results.
48	            max_dets_per_image (None or int): limit on maximum detections per image in evaluating AP
49	                This limit, by default of the LVIS dataset, is 300.
50	        &quot;&quot;&quot;
51	        from lvis import LVIS
52	
53	        self._logger = logging.getLogger(__name__)
54	
55	        if tasks is not None and isinstance(tasks, CfgNode):
56	            self._logger.warn(
57	                &quot;COCO Evaluator instantiated using config, this is deprecated behavior.&quot;
58	                &quot; Please pass in explicit arguments instead.&quot;
59	            )
60	            self._tasks = None  # Infering it from predictions should be better
61	        else:
62	            self._tasks = tasks
63	
64	        self._distributed = distributed
65	        self._output_dir = output_dir
66	        self._max_dets_per_image = max_dets_per_image
67	
68	        self._cpu_device = torch.device(&quot;cpu&quot;)
69	
70	        self._metadata = MetadataCatalog.get(dataset_name)
71	        json_file = PathManager.get_local_path(self._metadata.json_file)
72	        self._lvis_api = LVIS(json_file)
73	        # Test set json files do not contain annotations (evaluation must be
74	        # performed using the LVIS evaluation server).
75	        self._do_evaluation = len(self._lvis_api.get_ann_ids()) &gt; 0
76	
77	    def reset(self):
78	        self._predictions = []
79	
80	    def process(self, inputs, outputs):
81	        &quot;&quot;&quot;
82	        Args:
83	            inputs: the inputs to a LVIS model (e.g., GeneralizedRCNN).
84	                It is a list of dict. Each dict corresponds to an image and
85	                contains keys like &quot;height&quot;, &quot;width&quot;, &quot;file_name&quot;, &quot;image_id&quot;.
86	            outputs: the outputs of a LVIS model. It is a list of dicts with key
87	                &quot;instances&quot; that contains :class:`Instances`.
88	        &quot;&quot;&quot;
89	        for input, output in zip(inputs, outputs):
90	            prediction = {&quot;image_id&quot;: input[&quot;image_id&quot;]}
91	
92	            if &quot;instances&quot; in output:
93	                instances = output[&quot;instances&quot;].to(self._cpu_device)
94	                prediction[&quot;instances&quot;] = instances_to_coco_json(instances, input[&quot;image_id&quot;])
95	            if &quot;proposals&quot; in output:
96	                prediction[&quot;proposals&quot;] = output[&quot;proposals&quot;].to(self._cpu_device)
97	            self._predictions.append(prediction)
98	
99	    def evaluate(self):
100	        if self._distributed:
101	            comm.synchronize()
102	            predictions = comm.gather(self._predictions, dst=0)
103	            predictions = list(itertools.chain(*predictions))
104	
105	            if not comm.is_main_process():
106	                return
107	        else:
108	            predictions = self._predictions
109	
110	        if len(predictions) == 0:
111	            self._logger.warning(&quot;[LVISEvaluator] Did not receive valid predictions.&quot;)
112	            return {}
113	
114	        if self._output_dir:
115	            PathManager.mkdirs(self._output_dir)
116	            file_path = os.path.join(self._output_dir, &quot;instances_predictions.pth&quot;)
117	            with PathManager.open(file_path, &quot;wb&quot;) as f:
118	                torch.save(predictions, f)
119	
120	        self._results = OrderedDict()
</pre>
</div>


</div>
</div>

<div id="issue-48">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Using xml.etree.ElementTree to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree with the equivalent defusedxml package, or make sure defusedxml.defuse_stdlib() is called.<br>
    <b>Test ID:</b> B405<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/pascal_voc_evaluation.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/pascal_voc_evaluation.py</a><br>
    <b>Line number: </b>8<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b405-import-xml-etree" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b405-import-xml-etree</a><br>

<div class="code">
<pre>
1	# -*- coding: utf-8 -*-
2	# Copyright (c) Facebook, Inc. and its affiliates.
3	
4	import logging
5	import numpy as np
6	import os
7	import tempfile
8	import xml.etree.ElementTree as ET
9	from collections import OrderedDict, defaultdict
10	from functools import lru_cache
11	import torch
12	
13	from custom_detectron2.data import MetadataCatalog
14	from custom_detectron2.utils import comm
15	from custom_detectron2.utils.file_io import PathManager
16	
17	from .evaluator import DatasetEvaluator
18	
19	
20	class PascalVOCDetectionEvaluator(DatasetEvaluator):
21	    &quot;&quot;&quot;
22	    Evaluate Pascal VOC style AP for Pascal VOC dataset.
23	    It contains a synchronization, therefore has to be called from all ranks.
24	
25	    Note that the concept of AP can be implemented in different ways and may not
26	    produce identical results. This class mimics the implementation of the official
27	    Pascal VOC Matlab API, and should produce similar but not identical results to the
28	    official API.
29	    &quot;&quot;&quot;
30	
31	    def __init__(self, dataset_name):
32	        &quot;&quot;&quot;
33	        Args:
34	            dataset_name (str): name of the dataset, e.g., &quot;voc_2007_test&quot;
35	        &quot;&quot;&quot;
36	        self._dataset_name = dataset_name
37	        meta = MetadataCatalog.get(dataset_name)
38	
39	        # Too many tiny files, download all to local for speed.
40	        annotation_dir_local = PathManager.get_local_path(
41	            os.path.join(meta.dirname, &quot;Annotations/&quot;)
42	        )
43	        self._anno_file_template = os.path.join(annotation_dir_local, &quot;{}.xml&quot;)
44	        self._image_set_path = os.path.join(meta.dirname, &quot;ImageSets&quot;, &quot;Main&quot;, meta.split + &quot;.txt&quot;)
45	        self._class_names = meta.thing_classes
46	        assert meta.year in [2007, 2012], meta.year
47	        self._is_2007 = meta.year == 2007
48	        self._cpu_device = torch.device(&quot;cpu&quot;)
49	        self._logger = logging.getLogger(__name__)
50	
51	    def reset(self):
52	        self._predictions = defaultdict(list)  # class name -&gt; list of prediction strings
53	
54	    def process(self, inputs, outputs):
55	        for input, output in zip(inputs, outputs):
56	            image_id = input[&quot;image_id&quot;]
57	            instances = output[&quot;instances&quot;].to(self._cpu_device)
58	            boxes = instances.pred_boxes.tensor.numpy()
59	            scores = instances.scores.tolist()
60	            classes = instances.pred_classes.tolist()
61	            for box, score, cls in zip(boxes, scores, classes):
62	                xmin, ymin, xmax, ymax = box
63	                # The inverse of data loading logic in `datasets/pascal_voc.py`
64	                xmin += 1
65	                ymin += 1
66	                self._predictions[cls].append(
67	                    f&quot;{image_id} {score:.3f} {xmin:.1f} {ymin:.1f} {xmax:.1f} {ymax:.1f}&quot;
68	                )
69	
70	    def evaluate(self):
71	        &quot;&quot;&quot;
72	        Returns:
73	            dict: has a key &quot;segm&quot;, whose value is a dict of &quot;AP&quot;, &quot;AP50&quot;, and &quot;AP75&quot;.
74	        &quot;&quot;&quot;
75	        all_predictions = comm.gather(self._predictions, dst=0)
76	        if not comm.is_main_process():
77	            return
78	        predictions = defaultdict(list)
79	        for predictions_per_rank in all_predictions:
80	            for clsid, lines in predictions_per_rank.items():
81	                predictions[clsid].extend(lines)
82	        del all_predictions
83	
84	        self._logger.info(
85	            &quot;Evaluating {} using {} metric. &quot;
86	            &quot;Note that results do not use the official Matlab API.&quot;.format(
87	                self._dataset_name, 2007 if self._is_2007 else 2012
88	            )
89	        )
90	
91	        with tempfile.TemporaryDirectory(prefix=&quot;pascal_voc_eval_&quot;) as dirname:
92	            res_file_template = os.path.join(dirname, &quot;{}.txt&quot;)
93	
94	            aps = defaultdict(list)  # iou -&gt; ap per class
95	            for cls_id, cls_name in enumerate(self._class_names):
96	                lines = predictions.get(cls_id, [&quot;&quot;])
97	
98	                with open(res_file_template.format(cls_name), &quot;w&quot;) as f:
99	                    f.write(&quot;\n&quot;.join(lines))
100	
101	                for thresh in range(50, 100, 5):
102	                    rec, prec, ap = voc_eval(
103	                        res_file_template,
104	                        self._anno_file_template,
105	                        self._image_set_path,
106	                        cls_name,
107	                        ovthresh=thresh / 100.0,
108	                        use_07_metric=self._is_2007,
109	                    )
110	                    aps[thresh].append(ap * 100)
111	
112	        ret = OrderedDict()
113	        mAP = {iou: np.mean(x) for iou, x in aps.items()}
114	        ret[&quot;bbox&quot;] = {&quot;AP&quot;: np.mean(list(mAP.values())), &quot;AP50&quot;: mAP[50], &quot;AP75&quot;: mAP[75]}
115	        return ret
116	
117	
118	##############################################################################
119	#
120	# Below code is modified from
</pre>
</div>


</div>
</div>

<div id="issue-49">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Using xml.etree.ElementTree.parse to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree.parse with its defusedxml equivalent function or make sure defusedxml.defuse_stdlib() is called<br>
    <b>Test ID:</b> B314<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/pascal_voc_evaluation.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/evaluation/pascal_voc_evaluation.py</a><br>
    <b>Line number: </b>135<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b313-b320-xml-bad-elementtree" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b313-b320-xml-bad-elementtree</a><br>

<div class="code">
<pre>
75	        all_predictions = comm.gather(self._predictions, dst=0)
76	        if not comm.is_main_process():
77	            return
78	        predictions = defaultdict(list)
79	        for predictions_per_rank in all_predictions:
80	            for clsid, lines in predictions_per_rank.items():
81	                predictions[clsid].extend(lines)
82	        del all_predictions
83	
84	        self._logger.info(
85	            &quot;Evaluating {} using {} metric. &quot;
86	            &quot;Note that results do not use the official Matlab API.&quot;.format(
87	                self._dataset_name, 2007 if self._is_2007 else 2012
88	            )
89	        )
90	
91	        with tempfile.TemporaryDirectory(prefix=&quot;pascal_voc_eval_&quot;) as dirname:
92	            res_file_template = os.path.join(dirname, &quot;{}.txt&quot;)
93	
94	            aps = defaultdict(list)  # iou -&gt; ap per class
95	            for cls_id, cls_name in enumerate(self._class_names):
96	                lines = predictions.get(cls_id, [&quot;&quot;])
97	
98	                with open(res_file_template.format(cls_name), &quot;w&quot;) as f:
99	                    f.write(&quot;\n&quot;.join(lines))
100	
101	                for thresh in range(50, 100, 5):
102	                    rec, prec, ap = voc_eval(
103	                        res_file_template,
104	                        self._anno_file_template,
105	                        self._image_set_path,
106	                        cls_name,
107	                        ovthresh=thresh / 100.0,
108	                        use_07_metric=self._is_2007,
109	                    )
110	                    aps[thresh].append(ap * 100)
111	
112	        ret = OrderedDict()
113	        mAP = {iou: np.mean(x) for iou, x in aps.items()}
114	        ret[&quot;bbox&quot;] = {&quot;AP&quot;: np.mean(list(mAP.values())), &quot;AP50&quot;: mAP[50], &quot;AP75&quot;: mAP[75]}
115	        return ret
116	
117	
118	##############################################################################
119	#
120	# Below code is modified from
121	# https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py
122	# --------------------------------------------------------
123	# Fast/er R-CNN
124	# Licensed under The MIT License [see LICENSE for details]
125	# Written by Bharath Hariharan
126	# --------------------------------------------------------
127	
128	&quot;&quot;&quot;Python implementation of the PASCAL VOC devkit&#x27;s AP evaluation code.&quot;&quot;&quot;
129	
130	
131	@lru_cache(maxsize=None)
132	def parse_rec(filename):
133	    &quot;&quot;&quot;Parse a PASCAL VOC xml file.&quot;&quot;&quot;
134	    with PathManager.open(filename) as f:
135	        tree = ET.parse(f)
136	    objects = []
137	    for obj in tree.findall(&quot;object&quot;):
138	        obj_struct = {}
139	        obj_struct[&quot;name&quot;] = obj.find(&quot;name&quot;).text
140	        obj_struct[&quot;pose&quot;] = obj.find(&quot;pose&quot;).text
141	        obj_struct[&quot;truncated&quot;] = int(obj.find(&quot;truncated&quot;).text)
142	        obj_struct[&quot;difficult&quot;] = int(obj.find(&quot;difficult&quot;).text)
143	        bbox = obj.find(&quot;bndbox&quot;)
144	        obj_struct[&quot;bbox&quot;] = [
145	            int(bbox.find(&quot;xmin&quot;).text),
146	            int(bbox.find(&quot;ymin&quot;).text),
147	            int(bbox.find(&quot;xmax&quot;).text),
148	            int(bbox.find(&quot;ymax&quot;).text),
149	        ]
150	        objects.append(obj_struct)
151	
152	    return objects
153	
154	
155	def voc_ap(rec, prec, use_07_metric=False):
156	    &quot;&quot;&quot;Compute VOC AP given precision and recall. If use_07_metric is true, uses
157	    the VOC 07 11-point method (default:False).
158	    &quot;&quot;&quot;
159	    if use_07_metric:
160	        # 11 point metric
161	        ap = 0.0
162	        for t in np.arange(0.0, 1.1, 0.1):
163	            if np.sum(rec &gt;= t) == 0:
164	                p = 0
165	            else:
166	                p = np.max(prec[rec &gt;= t])
167	            ap = ap + p / 11.0
168	    else:
169	        # correct AP calculation
170	        # first append sentinel values at the end
171	        mrec = np.concatenate(([0.0], rec, [1.0]))
172	        mpre = np.concatenate(([0.0], prec, [0.0]))
173	
174	        # compute the precision envelope
175	        for i in range(mpre.size - 1, 0, -1):
176	            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])
177	
178	        # to calculate area under PR curve, look for points
179	        # where X axis (recall) changes value
180	        i = np.where(mrec[1:] != mrec[:-1])[0]
181	
182	        # and sum (\Delta recall) * prec
183	        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])
184	    return ap
185	
186	
187	def voc_eval(detpath, annopath, imagesetfile, classname, ovthresh=0.5, use_07_metric=False):
188	    &quot;&quot;&quot;rec, prec, ap = voc_eval(detpath,
189	                                annopath,
190	                                imagesetfile,
191	                                classname,
192	                                [ovthresh],
193	                                [use_07_metric])
194	
</pre>
</div>


</div>
</div>

<div id="issue-50">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>6<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import importlib
3	import numpy as np
4	import os
5	import re
6	import subprocess
7	import sys
8	from collections import defaultdict
9	import PIL
10	import torch
11	import torchvision
12	from tabulate import tabulate
13	
14	__all__ = [&quot;collect_env_info&quot;]
15	
16	
17	def collect_torch_env():
18	    try:
19	        import torch.__config__
20	
21	        return torch.__config__.show()
22	    except ImportError:
23	        # compatible with older versions of pytorch
24	        from torch.utils.collect_env import get_pretty_env_info
25	
26	        return get_pretty_env_info()
27	
28	
29	def get_env_module():
30	    var_name = &quot;DETECTRON2_ENV_MODULE&quot;
31	    return var_name, os.environ.get(var_name, &quot;&lt;not set&gt;&quot;)
32	
33	
34	def detect_compute_compatibility(CUDA_HOME, so_file):
35	    try:
36	        cuobjdump = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;cuobjdump&quot;)
37	        if os.path.isfile(cuobjdump):
38	            output = subprocess.check_output(
39	                &quot;&#x27;{}&#x27; --list-elf &#x27;{}&#x27;&quot;.format(cuobjdump, so_file), shell=True
40	            )
41	            output = output.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)
42	            arch = []
43	            for line in output:
44	                line = re.findall(r&quot;\.sm_([0-9]*)\.&quot;, line)[0]
45	                arch.append(&quot;.&quot;.join(line))
46	            arch = sorted(set(arch))
47	            return &quot;, &quot;.join(arch)
48	        else:
49	            return so_file + &quot;; cannot find cuobjdump&quot;
50	    except Exception:
51	        # unhandled failure
52	        return so_file
53	
54	
55	def collect_env_info():
56	    has_gpu = torch.cuda.is_available()  # true for both CUDA &amp; ROCM
57	    torch_version = torch.__version__
58	
59	    # NOTE that CUDA_HOME/ROCM_HOME could be None even when CUDA runtime libs are functional
60	    from torch.utils.cpp_extension import CUDA_HOME, ROCM_HOME
61	
62	    has_rocm = False
63	    if (getattr(torch.version, &quot;hip&quot;, None) is not None) and (ROCM_HOME is not None):
64	        has_rocm = True
65	    has_cuda = has_gpu and (not has_rocm)
66	
67	    data = []
68	    data.append((&quot;sys.platform&quot;, sys.platform))  # check-template.yml depends on it
69	    data.append((&quot;Python&quot;, sys.version.replace(&quot;\n&quot;, &quot;&quot;)))
70	    data.append((&quot;numpy&quot;, np.__version__))
71	
72	    try:
73	        import custom_detectron2  # noqa
74	
75	        data.append(
76	            (&quot;detectron2&quot;, detectron2.__version__ + &quot; @&quot; + os.path.dirname(detectron2.__file__))
77	        )
78	    except ImportError:
79	        data.append((&quot;detectron2&quot;, &quot;failed to import&quot;))
80	    except AttributeError:
81	        data.append((&quot;detectron2&quot;, &quot;imported a wrong installation&quot;))
82	
83	    try:
84	        import custom_detectron2._C as _C
85	    except ImportError as e:
86	        data.append((&quot;detectron2._C&quot;, f&quot;not built correctly: {e}&quot;))
87	
88	        # print system compilers when extension fails to build
89	        if sys.platform != &quot;win32&quot;:  # don&#x27;t know what to do for windows
90	            try:
91	                # this is how torch/utils/cpp_extensions.py choose compiler
92	                cxx = os.environ.get(&quot;CXX&quot;, &quot;c++&quot;)
93	                cxx = subprocess.check_output(&quot;&#x27;{}&#x27; --version&quot;.format(cxx), shell=True)
94	                cxx = cxx.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[0]
95	            except subprocess.SubprocessError:
96	                cxx = &quot;Not found&quot;
97	            data.append((&quot;Compiler ($CXX)&quot;, cxx))
98	
99	            if has_cuda and CUDA_HOME is not None:
100	                try:
101	                    nvcc = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;nvcc&quot;)
102	                    nvcc = subprocess.check_output(&quot;&#x27;{}&#x27; -V&quot;.format(nvcc), shell=True)
103	                    nvcc = nvcc.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[-1]
104	                except subprocess.SubprocessError:
105	                    nvcc = &quot;Not found&quot;
106	                data.append((&quot;CUDA compiler&quot;, nvcc))
107	        if has_cuda and sys.platform != &quot;win32&quot;:
108	            try:
109	                so_file = importlib.util.find_spec(&quot;detectron2._C&quot;).origin
110	            except (ImportError, AttributeError):
111	                pass
112	            else:
113	                data.append(
114	                    (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, so_file))
115	                )
116	    else:
117	        # print compilers that are used to build extension
118	        data.append((&quot;Compiler&quot;, _C.get_compiler_version()))
119	        data.append((&quot;CUDA compiler&quot;, _C.get_cuda_version()))  # cuda or hip
120	        if has_cuda and getattr(_C, &quot;has_cuda&quot;, lambda: True)():
</pre>
</div>


</div>
</div>

<div id="issue-51">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>39<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) Facebook, Inc. and its affiliates.
2	import importlib
3	import numpy as np
4	import os
5	import re
6	import subprocess
7	import sys
8	from collections import defaultdict
9	import PIL
10	import torch
11	import torchvision
12	from tabulate import tabulate
13	
14	__all__ = [&quot;collect_env_info&quot;]
15	
16	
17	def collect_torch_env():
18	    try:
19	        import torch.__config__
20	
21	        return torch.__config__.show()
22	    except ImportError:
23	        # compatible with older versions of pytorch
24	        from torch.utils.collect_env import get_pretty_env_info
25	
26	        return get_pretty_env_info()
27	
28	
29	def get_env_module():
30	    var_name = &quot;DETECTRON2_ENV_MODULE&quot;
31	    return var_name, os.environ.get(var_name, &quot;&lt;not set&gt;&quot;)
32	
33	
34	def detect_compute_compatibility(CUDA_HOME, so_file):
35	    try:
36	        cuobjdump = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;cuobjdump&quot;)
37	        if os.path.isfile(cuobjdump):
38	            output = subprocess.check_output(
39	                &quot;&#x27;{}&#x27; --list-elf &#x27;{}&#x27;&quot;.format(cuobjdump, so_file), shell=True
40	            )
41	            output = output.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)
42	            arch = []
43	            for line in output:
44	                line = re.findall(r&quot;\.sm_([0-9]*)\.&quot;, line)[0]
45	                arch.append(&quot;.&quot;.join(line))
46	            arch = sorted(set(arch))
47	            return &quot;, &quot;.join(arch)
48	        else:
49	            return so_file + &quot;; cannot find cuobjdump&quot;
50	    except Exception:
51	        # unhandled failure
52	        return so_file
53	
54	
55	def collect_env_info():
56	    has_gpu = torch.cuda.is_available()  # true for both CUDA &amp; ROCM
57	    torch_version = torch.__version__
58	
59	    # NOTE that CUDA_HOME/ROCM_HOME could be None even when CUDA runtime libs are functional
60	    from torch.utils.cpp_extension import CUDA_HOME, ROCM_HOME
61	
62	    has_rocm = False
63	    if (getattr(torch.version, &quot;hip&quot;, None) is not None) and (ROCM_HOME is not None):
64	        has_rocm = True
65	    has_cuda = has_gpu and (not has_rocm)
66	
67	    data = []
68	    data.append((&quot;sys.platform&quot;, sys.platform))  # check-template.yml depends on it
69	    data.append((&quot;Python&quot;, sys.version.replace(&quot;\n&quot;, &quot;&quot;)))
70	    data.append((&quot;numpy&quot;, np.__version__))
71	
72	    try:
73	        import custom_detectron2  # noqa
74	
75	        data.append(
76	            (&quot;detectron2&quot;, detectron2.__version__ + &quot; @&quot; + os.path.dirname(detectron2.__file__))
77	        )
78	    except ImportError:
79	        data.append((&quot;detectron2&quot;, &quot;failed to import&quot;))
80	    except AttributeError:
81	        data.append((&quot;detectron2&quot;, &quot;imported a wrong installation&quot;))
82	
83	    try:
84	        import custom_detectron2._C as _C
85	    except ImportError as e:
86	        data.append((&quot;detectron2._C&quot;, f&quot;not built correctly: {e}&quot;))
87	
88	        # print system compilers when extension fails to build
89	        if sys.platform != &quot;win32&quot;:  # don&#x27;t know what to do for windows
90	            try:
91	                # this is how torch/utils/cpp_extensions.py choose compiler
92	                cxx = os.environ.get(&quot;CXX&quot;, &quot;c++&quot;)
93	                cxx = subprocess.check_output(&quot;&#x27;{}&#x27; --version&quot;.format(cxx), shell=True)
94	                cxx = cxx.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[0]
95	            except subprocess.SubprocessError:
96	                cxx = &quot;Not found&quot;
97	            data.append((&quot;Compiler ($CXX)&quot;, cxx))
98	
99	            if has_cuda and CUDA_HOME is not None:
100	                try:
101	                    nvcc = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;nvcc&quot;)
102	                    nvcc = subprocess.check_output(&quot;&#x27;{}&#x27; -V&quot;.format(nvcc), shell=True)
103	                    nvcc = nvcc.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[-1]
104	                except subprocess.SubprocessError:
105	                    nvcc = &quot;Not found&quot;
106	                data.append((&quot;CUDA compiler&quot;, nvcc))
107	        if has_cuda and sys.platform != &quot;win32&quot;:
108	            try:
109	                so_file = importlib.util.find_spec(&quot;detectron2._C&quot;).origin
110	            except (ImportError, AttributeError):
111	                pass
112	            else:
113	                data.append(
114	                    (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, so_file))
115	                )
116	    else:
117	        # print compilers that are used to build extension
118	        data.append((&quot;Compiler&quot;, _C.get_compiler_version()))
119	        data.append((&quot;CUDA compiler&quot;, _C.get_cuda_version()))  # cuda or hip
120	        if has_cuda and getattr(_C, &quot;has_cuda&quot;, lambda: True)():
121	            data.append(
122	                (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, _C.__file__))
</pre>
</div>


</div>
</div>

<div id="issue-52">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>93<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
33	
34	def detect_compute_compatibility(CUDA_HOME, so_file):
35	    try:
36	        cuobjdump = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;cuobjdump&quot;)
37	        if os.path.isfile(cuobjdump):
38	            output = subprocess.check_output(
39	                &quot;&#x27;{}&#x27; --list-elf &#x27;{}&#x27;&quot;.format(cuobjdump, so_file), shell=True
40	            )
41	            output = output.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)
42	            arch = []
43	            for line in output:
44	                line = re.findall(r&quot;\.sm_([0-9]*)\.&quot;, line)[0]
45	                arch.append(&quot;.&quot;.join(line))
46	            arch = sorted(set(arch))
47	            return &quot;, &quot;.join(arch)
48	        else:
49	            return so_file + &quot;; cannot find cuobjdump&quot;
50	    except Exception:
51	        # unhandled failure
52	        return so_file
53	
54	
55	def collect_env_info():
56	    has_gpu = torch.cuda.is_available()  # true for both CUDA &amp; ROCM
57	    torch_version = torch.__version__
58	
59	    # NOTE that CUDA_HOME/ROCM_HOME could be None even when CUDA runtime libs are functional
60	    from torch.utils.cpp_extension import CUDA_HOME, ROCM_HOME
61	
62	    has_rocm = False
63	    if (getattr(torch.version, &quot;hip&quot;, None) is not None) and (ROCM_HOME is not None):
64	        has_rocm = True
65	    has_cuda = has_gpu and (not has_rocm)
66	
67	    data = []
68	    data.append((&quot;sys.platform&quot;, sys.platform))  # check-template.yml depends on it
69	    data.append((&quot;Python&quot;, sys.version.replace(&quot;\n&quot;, &quot;&quot;)))
70	    data.append((&quot;numpy&quot;, np.__version__))
71	
72	    try:
73	        import custom_detectron2  # noqa
74	
75	        data.append(
76	            (&quot;detectron2&quot;, detectron2.__version__ + &quot; @&quot; + os.path.dirname(detectron2.__file__))
77	        )
78	    except ImportError:
79	        data.append((&quot;detectron2&quot;, &quot;failed to import&quot;))
80	    except AttributeError:
81	        data.append((&quot;detectron2&quot;, &quot;imported a wrong installation&quot;))
82	
83	    try:
84	        import custom_detectron2._C as _C
85	    except ImportError as e:
86	        data.append((&quot;detectron2._C&quot;, f&quot;not built correctly: {e}&quot;))
87	
88	        # print system compilers when extension fails to build
89	        if sys.platform != &quot;win32&quot;:  # don&#x27;t know what to do for windows
90	            try:
91	                # this is how torch/utils/cpp_extensions.py choose compiler
92	                cxx = os.environ.get(&quot;CXX&quot;, &quot;c++&quot;)
93	                cxx = subprocess.check_output(&quot;&#x27;{}&#x27; --version&quot;.format(cxx), shell=True)
94	                cxx = cxx.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[0]
95	            except subprocess.SubprocessError:
96	                cxx = &quot;Not found&quot;
97	            data.append((&quot;Compiler ($CXX)&quot;, cxx))
98	
99	            if has_cuda and CUDA_HOME is not None:
100	                try:
101	                    nvcc = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;nvcc&quot;)
102	                    nvcc = subprocess.check_output(&quot;&#x27;{}&#x27; -V&quot;.format(nvcc), shell=True)
103	                    nvcc = nvcc.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[-1]
104	                except subprocess.SubprocessError:
105	                    nvcc = &quot;Not found&quot;
106	                data.append((&quot;CUDA compiler&quot;, nvcc))
107	        if has_cuda and sys.platform != &quot;win32&quot;:
108	            try:
109	                so_file = importlib.util.find_spec(&quot;detectron2._C&quot;).origin
110	            except (ImportError, AttributeError):
111	                pass
112	            else:
113	                data.append(
114	                    (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, so_file))
115	                )
116	    else:
117	        # print compilers that are used to build extension
118	        data.append((&quot;Compiler&quot;, _C.get_compiler_version()))
119	        data.append((&quot;CUDA compiler&quot;, _C.get_cuda_version()))  # cuda or hip
120	        if has_cuda and getattr(_C, &quot;has_cuda&quot;, lambda: True)():
121	            data.append(
122	                (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, _C.__file__))
123	            )
124	
125	    data.append(get_env_module())
126	    data.append((&quot;PyTorch&quot;, torch_version + &quot; @&quot; + os.path.dirname(torch.__file__)))
127	    data.append((&quot;PyTorch debug build&quot;, torch.version.debug))
128	    try:
129	        data.append((&quot;torch._C._GLIBCXX_USE_CXX11_ABI&quot;, torch._C._GLIBCXX_USE_CXX11_ABI))
130	    except Exception:
131	        pass
132	
133	    if not has_gpu:
134	        has_gpu_text = &quot;No: torch.cuda.is_available() == False&quot;
135	    else:
136	        has_gpu_text = &quot;Yes&quot;
137	    data.append((&quot;GPU available&quot;, has_gpu_text))
138	    if has_gpu:
139	        devices = defaultdict(list)
140	        for k in range(torch.cuda.device_count()):
141	            cap = &quot;.&quot;.join((str(x) for x in torch.cuda.get_device_capability(k)))
142	            name = torch.cuda.get_device_name(k) + f&quot; (arch={cap})&quot;
143	            devices[name].append(str(k))
144	        for name, devids in devices.items():
145	            data.append((&quot;GPU &quot; + &quot;,&quot;.join(devids), name))
146	
147	        if has_rocm:
148	            msg = &quot; - invalid!&quot; if not (ROCM_HOME and os.path.isdir(ROCM_HOME)) else &quot;&quot;
149	            data.append((&quot;ROCM_HOME&quot;, str(ROCM_HOME) + msg))
150	        else:
151	            try:
152	                from torch.utils.collect_env import get_nvidia_driver_version, run as _run
</pre>
</div>


</div>
</div>

<div id="issue-53">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>102<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
42	            arch = []
43	            for line in output:
44	                line = re.findall(r&quot;\.sm_([0-9]*)\.&quot;, line)[0]
45	                arch.append(&quot;.&quot;.join(line))
46	            arch = sorted(set(arch))
47	            return &quot;, &quot;.join(arch)
48	        else:
49	            return so_file + &quot;; cannot find cuobjdump&quot;
50	    except Exception:
51	        # unhandled failure
52	        return so_file
53	
54	
55	def collect_env_info():
56	    has_gpu = torch.cuda.is_available()  # true for both CUDA &amp; ROCM
57	    torch_version = torch.__version__
58	
59	    # NOTE that CUDA_HOME/ROCM_HOME could be None even when CUDA runtime libs are functional
60	    from torch.utils.cpp_extension import CUDA_HOME, ROCM_HOME
61	
62	    has_rocm = False
63	    if (getattr(torch.version, &quot;hip&quot;, None) is not None) and (ROCM_HOME is not None):
64	        has_rocm = True
65	    has_cuda = has_gpu and (not has_rocm)
66	
67	    data = []
68	    data.append((&quot;sys.platform&quot;, sys.platform))  # check-template.yml depends on it
69	    data.append((&quot;Python&quot;, sys.version.replace(&quot;\n&quot;, &quot;&quot;)))
70	    data.append((&quot;numpy&quot;, np.__version__))
71	
72	    try:
73	        import custom_detectron2  # noqa
74	
75	        data.append(
76	            (&quot;detectron2&quot;, detectron2.__version__ + &quot; @&quot; + os.path.dirname(detectron2.__file__))
77	        )
78	    except ImportError:
79	        data.append((&quot;detectron2&quot;, &quot;failed to import&quot;))
80	    except AttributeError:
81	        data.append((&quot;detectron2&quot;, &quot;imported a wrong installation&quot;))
82	
83	    try:
84	        import custom_detectron2._C as _C
85	    except ImportError as e:
86	        data.append((&quot;detectron2._C&quot;, f&quot;not built correctly: {e}&quot;))
87	
88	        # print system compilers when extension fails to build
89	        if sys.platform != &quot;win32&quot;:  # don&#x27;t know what to do for windows
90	            try:
91	                # this is how torch/utils/cpp_extensions.py choose compiler
92	                cxx = os.environ.get(&quot;CXX&quot;, &quot;c++&quot;)
93	                cxx = subprocess.check_output(&quot;&#x27;{}&#x27; --version&quot;.format(cxx), shell=True)
94	                cxx = cxx.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[0]
95	            except subprocess.SubprocessError:
96	                cxx = &quot;Not found&quot;
97	            data.append((&quot;Compiler ($CXX)&quot;, cxx))
98	
99	            if has_cuda and CUDA_HOME is not None:
100	                try:
101	                    nvcc = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;nvcc&quot;)
102	                    nvcc = subprocess.check_output(&quot;&#x27;{}&#x27; -V&quot;.format(nvcc), shell=True)
103	                    nvcc = nvcc.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[-1]
104	                except subprocess.SubprocessError:
105	                    nvcc = &quot;Not found&quot;
106	                data.append((&quot;CUDA compiler&quot;, nvcc))
107	        if has_cuda and sys.platform != &quot;win32&quot;:
108	            try:
109	                so_file = importlib.util.find_spec(&quot;detectron2._C&quot;).origin
110	            except (ImportError, AttributeError):
111	                pass
112	            else:
113	                data.append(
114	                    (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, so_file))
115	                )
116	    else:
117	        # print compilers that are used to build extension
118	        data.append((&quot;Compiler&quot;, _C.get_compiler_version()))
119	        data.append((&quot;CUDA compiler&quot;, _C.get_cuda_version()))  # cuda or hip
120	        if has_cuda and getattr(_C, &quot;has_cuda&quot;, lambda: True)():
121	            data.append(
122	                (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, _C.__file__))
123	            )
124	
125	    data.append(get_env_module())
126	    data.append((&quot;PyTorch&quot;, torch_version + &quot; @&quot; + os.path.dirname(torch.__file__)))
127	    data.append((&quot;PyTorch debug build&quot;, torch.version.debug))
128	    try:
129	        data.append((&quot;torch._C._GLIBCXX_USE_CXX11_ABI&quot;, torch._C._GLIBCXX_USE_CXX11_ABI))
130	    except Exception:
131	        pass
132	
133	    if not has_gpu:
134	        has_gpu_text = &quot;No: torch.cuda.is_available() == False&quot;
135	    else:
136	        has_gpu_text = &quot;Yes&quot;
137	    data.append((&quot;GPU available&quot;, has_gpu_text))
138	    if has_gpu:
139	        devices = defaultdict(list)
140	        for k in range(torch.cuda.device_count()):
141	            cap = &quot;.&quot;.join((str(x) for x in torch.cuda.get_device_capability(k)))
142	            name = torch.cuda.get_device_name(k) + f&quot; (arch={cap})&quot;
143	            devices[name].append(str(k))
144	        for name, devids in devices.items():
145	            data.append((&quot;GPU &quot; + &quot;,&quot;.join(devids), name))
146	
147	        if has_rocm:
148	            msg = &quot; - invalid!&quot; if not (ROCM_HOME and os.path.isdir(ROCM_HOME)) else &quot;&quot;
149	            data.append((&quot;ROCM_HOME&quot;, str(ROCM_HOME) + msg))
150	        else:
151	            try:
152	                from torch.utils.collect_env import get_nvidia_driver_version, run as _run
153	
154	                data.append((&quot;Driver version&quot;, get_nvidia_driver_version(_run)))
155	            except Exception:
156	                pass
157	            msg = &quot; - invalid!&quot; if not (CUDA_HOME and os.path.isdir(CUDA_HOME)) else &quot;&quot;
158	            data.append((&quot;CUDA_HOME&quot;, str(CUDA_HOME) + msg))
159	
160	            cuda_arch_list = os.environ.get(&quot;TORCH_CUDA_ARCH_LIST&quot;, None)
161	            if cuda_arch_list:
</pre>
</div>


</div>
</div>

<div id="issue-54">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>130<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
70	    data.append((&quot;numpy&quot;, np.__version__))
71	
72	    try:
73	        import custom_detectron2  # noqa
74	
75	        data.append(
76	            (&quot;detectron2&quot;, detectron2.__version__ + &quot; @&quot; + os.path.dirname(detectron2.__file__))
77	        )
78	    except ImportError:
79	        data.append((&quot;detectron2&quot;, &quot;failed to import&quot;))
80	    except AttributeError:
81	        data.append((&quot;detectron2&quot;, &quot;imported a wrong installation&quot;))
82	
83	    try:
84	        import custom_detectron2._C as _C
85	    except ImportError as e:
86	        data.append((&quot;detectron2._C&quot;, f&quot;not built correctly: {e}&quot;))
87	
88	        # print system compilers when extension fails to build
89	        if sys.platform != &quot;win32&quot;:  # don&#x27;t know what to do for windows
90	            try:
91	                # this is how torch/utils/cpp_extensions.py choose compiler
92	                cxx = os.environ.get(&quot;CXX&quot;, &quot;c++&quot;)
93	                cxx = subprocess.check_output(&quot;&#x27;{}&#x27; --version&quot;.format(cxx), shell=True)
94	                cxx = cxx.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[0]
95	            except subprocess.SubprocessError:
96	                cxx = &quot;Not found&quot;
97	            data.append((&quot;Compiler ($CXX)&quot;, cxx))
98	
99	            if has_cuda and CUDA_HOME is not None:
100	                try:
101	                    nvcc = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;nvcc&quot;)
102	                    nvcc = subprocess.check_output(&quot;&#x27;{}&#x27; -V&quot;.format(nvcc), shell=True)
103	                    nvcc = nvcc.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[-1]
104	                except subprocess.SubprocessError:
105	                    nvcc = &quot;Not found&quot;
106	                data.append((&quot;CUDA compiler&quot;, nvcc))
107	        if has_cuda and sys.platform != &quot;win32&quot;:
108	            try:
109	                so_file = importlib.util.find_spec(&quot;detectron2._C&quot;).origin
110	            except (ImportError, AttributeError):
111	                pass
112	            else:
113	                data.append(
114	                    (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, so_file))
115	                )
116	    else:
117	        # print compilers that are used to build extension
118	        data.append((&quot;Compiler&quot;, _C.get_compiler_version()))
119	        data.append((&quot;CUDA compiler&quot;, _C.get_cuda_version()))  # cuda or hip
120	        if has_cuda and getattr(_C, &quot;has_cuda&quot;, lambda: True)():
121	            data.append(
122	                (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, _C.__file__))
123	            )
124	
125	    data.append(get_env_module())
126	    data.append((&quot;PyTorch&quot;, torch_version + &quot; @&quot; + os.path.dirname(torch.__file__)))
127	    data.append((&quot;PyTorch debug build&quot;, torch.version.debug))
128	    try:
129	        data.append((&quot;torch._C._GLIBCXX_USE_CXX11_ABI&quot;, torch._C._GLIBCXX_USE_CXX11_ABI))
130	    except Exception:
131	        pass
132	
133	    if not has_gpu:
134	        has_gpu_text = &quot;No: torch.cuda.is_available() == False&quot;
135	    else:
136	        has_gpu_text = &quot;Yes&quot;
137	    data.append((&quot;GPU available&quot;, has_gpu_text))
138	    if has_gpu:
139	        devices = defaultdict(list)
140	        for k in range(torch.cuda.device_count()):
141	            cap = &quot;.&quot;.join((str(x) for x in torch.cuda.get_device_capability(k)))
142	            name = torch.cuda.get_device_name(k) + f&quot; (arch={cap})&quot;
143	            devices[name].append(str(k))
144	        for name, devids in devices.items():
145	            data.append((&quot;GPU &quot; + &quot;,&quot;.join(devids), name))
146	
147	        if has_rocm:
148	            msg = &quot; - invalid!&quot; if not (ROCM_HOME and os.path.isdir(ROCM_HOME)) else &quot;&quot;
149	            data.append((&quot;ROCM_HOME&quot;, str(ROCM_HOME) + msg))
150	        else:
151	            try:
152	                from torch.utils.collect_env import get_nvidia_driver_version, run as _run
153	
154	                data.append((&quot;Driver version&quot;, get_nvidia_driver_version(_run)))
155	            except Exception:
156	                pass
157	            msg = &quot; - invalid!&quot; if not (CUDA_HOME and os.path.isdir(CUDA_HOME)) else &quot;&quot;
158	            data.append((&quot;CUDA_HOME&quot;, str(CUDA_HOME) + msg))
159	
160	            cuda_arch_list = os.environ.get(&quot;TORCH_CUDA_ARCH_LIST&quot;, None)
161	            if cuda_arch_list:
162	                data.append((&quot;TORCH_CUDA_ARCH_LIST&quot;, cuda_arch_list))
163	    data.append((&quot;Pillow&quot;, PIL.__version__))
164	
165	    try:
166	        data.append(
167	            (
168	                &quot;torchvision&quot;,
169	                str(torchvision.__version__) + &quot; @&quot; + os.path.dirname(torchvision.__file__),
170	            )
171	        )
172	        if has_cuda:
173	            try:
174	                torchvision_C = importlib.util.find_spec(&quot;torchvision._C&quot;).origin
175	                msg = detect_compute_compatibility(CUDA_HOME, torchvision_C)
176	                data.append((&quot;torchvision arch flags&quot;, msg))
177	            except (ImportError, AttributeError):
178	                data.append((&quot;torchvision._C&quot;, &quot;Not found&quot;))
179	    except AttributeError:
180	        data.append((&quot;torchvision&quot;, &quot;unknown&quot;))
181	
182	    try:
183	        import fvcore
184	
185	        data.append((&quot;fvcore&quot;, fvcore.__version__))
186	    except (ImportError, AttributeError):
187	        pass
188	
189	    try:
190	        import iopath
</pre>
</div>


</div>
</div>

<div id="issue-55">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>155<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
95	            except subprocess.SubprocessError:
96	                cxx = &quot;Not found&quot;
97	            data.append((&quot;Compiler ($CXX)&quot;, cxx))
98	
99	            if has_cuda and CUDA_HOME is not None:
100	                try:
101	                    nvcc = os.path.join(CUDA_HOME, &quot;bin&quot;, &quot;nvcc&quot;)
102	                    nvcc = subprocess.check_output(&quot;&#x27;{}&#x27; -V&quot;.format(nvcc), shell=True)
103	                    nvcc = nvcc.decode(&quot;utf-8&quot;).strip().split(&quot;\n&quot;)[-1]
104	                except subprocess.SubprocessError:
105	                    nvcc = &quot;Not found&quot;
106	                data.append((&quot;CUDA compiler&quot;, nvcc))
107	        if has_cuda and sys.platform != &quot;win32&quot;:
108	            try:
109	                so_file = importlib.util.find_spec(&quot;detectron2._C&quot;).origin
110	            except (ImportError, AttributeError):
111	                pass
112	            else:
113	                data.append(
114	                    (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, so_file))
115	                )
116	    else:
117	        # print compilers that are used to build extension
118	        data.append((&quot;Compiler&quot;, _C.get_compiler_version()))
119	        data.append((&quot;CUDA compiler&quot;, _C.get_cuda_version()))  # cuda or hip
120	        if has_cuda and getattr(_C, &quot;has_cuda&quot;, lambda: True)():
121	            data.append(
122	                (&quot;detectron2 arch flags&quot;, detect_compute_compatibility(CUDA_HOME, _C.__file__))
123	            )
124	
125	    data.append(get_env_module())
126	    data.append((&quot;PyTorch&quot;, torch_version + &quot; @&quot; + os.path.dirname(torch.__file__)))
127	    data.append((&quot;PyTorch debug build&quot;, torch.version.debug))
128	    try:
129	        data.append((&quot;torch._C._GLIBCXX_USE_CXX11_ABI&quot;, torch._C._GLIBCXX_USE_CXX11_ABI))
130	    except Exception:
131	        pass
132	
133	    if not has_gpu:
134	        has_gpu_text = &quot;No: torch.cuda.is_available() == False&quot;
135	    else:
136	        has_gpu_text = &quot;Yes&quot;
137	    data.append((&quot;GPU available&quot;, has_gpu_text))
138	    if has_gpu:
139	        devices = defaultdict(list)
140	        for k in range(torch.cuda.device_count()):
141	            cap = &quot;.&quot;.join((str(x) for x in torch.cuda.get_device_capability(k)))
142	            name = torch.cuda.get_device_name(k) + f&quot; (arch={cap})&quot;
143	            devices[name].append(str(k))
144	        for name, devids in devices.items():
145	            data.append((&quot;GPU &quot; + &quot;,&quot;.join(devids), name))
146	
147	        if has_rocm:
148	            msg = &quot; - invalid!&quot; if not (ROCM_HOME and os.path.isdir(ROCM_HOME)) else &quot;&quot;
149	            data.append((&quot;ROCM_HOME&quot;, str(ROCM_HOME) + msg))
150	        else:
151	            try:
152	                from torch.utils.collect_env import get_nvidia_driver_version, run as _run
153	
154	                data.append((&quot;Driver version&quot;, get_nvidia_driver_version(_run)))
155	            except Exception:
156	                pass
157	            msg = &quot; - invalid!&quot; if not (CUDA_HOME and os.path.isdir(CUDA_HOME)) else &quot;&quot;
158	            data.append((&quot;CUDA_HOME&quot;, str(CUDA_HOME) + msg))
159	
160	            cuda_arch_list = os.environ.get(&quot;TORCH_CUDA_ARCH_LIST&quot;, None)
161	            if cuda_arch_list:
162	                data.append((&quot;TORCH_CUDA_ARCH_LIST&quot;, cuda_arch_list))
163	    data.append((&quot;Pillow&quot;, PIL.__version__))
164	
165	    try:
166	        data.append(
167	            (
168	                &quot;torchvision&quot;,
169	                str(torchvision.__version__) + &quot; @&quot; + os.path.dirname(torchvision.__file__),
170	            )
171	        )
172	        if has_cuda:
173	            try:
174	                torchvision_C = importlib.util.find_spec(&quot;torchvision._C&quot;).origin
175	                msg = detect_compute_compatibility(CUDA_HOME, torchvision_C)
176	                data.append((&quot;torchvision arch flags&quot;, msg))
177	            except (ImportError, AttributeError):
178	                data.append((&quot;torchvision._C&quot;, &quot;Not found&quot;))
179	    except AttributeError:
180	        data.append((&quot;torchvision&quot;, &quot;unknown&quot;))
181	
182	    try:
183	        import fvcore
184	
185	        data.append((&quot;fvcore&quot;, fvcore.__version__))
186	    except (ImportError, AttributeError):
187	        pass
188	
189	    try:
190	        import iopath
191	
192	        data.append((&quot;iopath&quot;, iopath.__version__))
193	    except (ImportError, AttributeError):
194	        pass
195	
196	    try:
197	        import cv2
198	
199	        data.append((&quot;cv2&quot;, cv2.__version__))
200	    except (ImportError, AttributeError):
201	        data.append((&quot;cv2&quot;, &quot;Not found&quot;))
202	    env_str = tabulate(data) + &quot;\n&quot;
203	    env_str += collect_torch_env()
204	    return env_str
205	
206	
207	def test_nccl_ops():
208	    num_gpu = torch.cuda.device_count()
209	    if os.access(&quot;/tmp&quot;, os.W_OK):
210	        import torch.multiprocessing as mp
211	
212	        dist_url = &quot;file:///tmp/nccl_tmp_file&quot;
213	        print(&quot;Testing NCCL connectivity ... this should not hang.&quot;)
214	        mp.spawn(_test_nccl_worker, nprocs=num_gpu, args=(num_gpu, dist_url), daemon=False)
215	        print(&quot;NCCL succeeded.&quot;)
</pre>
</div>


</div>
</div>

<div id="issue-56">
<div class="issue-block issue-sev-medium">
    <b>hardcoded_tmp_directory: </b> Probable insecure usage of temp file/directory.<br>
    <b>Test ID:</b> B108<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>MEDIUM<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/377.html" target="_blank">CWE-377</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/collect_env.py</a><br>
    <b>Line number: </b>209<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b108_hardcoded_tmp_directory.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b108_hardcoded_tmp_directory.html</a><br>

<div class="code">
<pre>
149	            data.append((&quot;ROCM_HOME&quot;, str(ROCM_HOME) + msg))
150	        else:
151	            try:
152	                from torch.utils.collect_env import get_nvidia_driver_version, run as _run
153	
154	                data.append((&quot;Driver version&quot;, get_nvidia_driver_version(_run)))
155	            except Exception:
156	                pass
157	            msg = &quot; - invalid!&quot; if not (CUDA_HOME and os.path.isdir(CUDA_HOME)) else &quot;&quot;
158	            data.append((&quot;CUDA_HOME&quot;, str(CUDA_HOME) + msg))
159	
160	            cuda_arch_list = os.environ.get(&quot;TORCH_CUDA_ARCH_LIST&quot;, None)
161	            if cuda_arch_list:
162	                data.append((&quot;TORCH_CUDA_ARCH_LIST&quot;, cuda_arch_list))
163	    data.append((&quot;Pillow&quot;, PIL.__version__))
164	
165	    try:
166	        data.append(
167	            (
168	                &quot;torchvision&quot;,
169	                str(torchvision.__version__) + &quot; @&quot; + os.path.dirname(torchvision.__file__),
170	            )
171	        )
172	        if has_cuda:
173	            try:
174	                torchvision_C = importlib.util.find_spec(&quot;torchvision._C&quot;).origin
175	                msg = detect_compute_compatibility(CUDA_HOME, torchvision_C)
176	                data.append((&quot;torchvision arch flags&quot;, msg))
177	            except (ImportError, AttributeError):
178	                data.append((&quot;torchvision._C&quot;, &quot;Not found&quot;))
179	    except AttributeError:
180	        data.append((&quot;torchvision&quot;, &quot;unknown&quot;))
181	
182	    try:
183	        import fvcore
184	
185	        data.append((&quot;fvcore&quot;, fvcore.__version__))
186	    except (ImportError, AttributeError):
187	        pass
188	
189	    try:
190	        import iopath
191	
192	        data.append((&quot;iopath&quot;, iopath.__version__))
193	    except (ImportError, AttributeError):
194	        pass
195	
196	    try:
197	        import cv2
198	
199	        data.append((&quot;cv2&quot;, cv2.__version__))
200	    except (ImportError, AttributeError):
201	        data.append((&quot;cv2&quot;, &quot;Not found&quot;))
202	    env_str = tabulate(data) + &quot;\n&quot;
203	    env_str += collect_torch_env()
204	    return env_str
205	
206	
207	def test_nccl_ops():
208	    num_gpu = torch.cuda.device_count()
209	    if os.access(&quot;/tmp&quot;, os.W_OK):
210	        import torch.multiprocessing as mp
211	
212	        dist_url = &quot;file:///tmp/nccl_tmp_file&quot;
213	        print(&quot;Testing NCCL connectivity ... this should not hang.&quot;)
214	        mp.spawn(_test_nccl_worker, nprocs=num_gpu, args=(num_gpu, dist_url), daemon=False)
215	        print(&quot;NCCL succeeded.&quot;)
216	
217	
218	def _test_nccl_worker(rank, num_gpu, dist_url):
219	    import torch.distributed as dist
220	
221	    dist.init_process_group(backend=&quot;NCCL&quot;, init_method=dist_url, rank=rank, world_size=num_gpu)
222	    dist.barrier(device_ids=[rank])
223	
224	
225	if __name__ == &quot;__main__&quot;:
226	    try:
227	        from custom_detectron2.utils.collect_env import collect_env_info as f
228	
229	        print(f())
230	    except ImportError:
231	        print(collect_env_info())
232	
233	    if torch.cuda.is_available():
234	        num_gpu = torch.cuda.device_count()
235	        for k in range(num_gpu):
236	            device = f&quot;cuda:{k}&quot;
237	            try:
238	                x = torch.tensor([1, 2.0], dtype=torch.float32)
239	                x = x.to(device)
240	            except Exception as e:
241	                print(
242	                    f&quot;Unable to copy tensor to device={device}: {e}. &quot;
243	                    &quot;Your CUDA environment is broken.&quot;
244	                )
245	        if num_gpu &gt; 1:
246	            test_nccl_ops()
</pre>
</div>


</div>
</div>

<div id="issue-57">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Use of possibly insecure function - consider using safer ast.literal_eval.<br>
    <b>Test ID:</b> B307<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/tracing.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_detectron2/utils/tracing.py</a><br>
    <b>Line number: </b>60<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval</a><br>

<div class="code">
<pre>
1	import inspect
2	import torch
3	
4	from custom_detectron2.utils.env import TORCH_VERSION
5	
6	try:
7	    from torch.fx._symbolic_trace import is_fx_tracing as is_fx_tracing_current
8	
9	    tracing_current_exists = True
10	except ImportError:
11	    tracing_current_exists = False
12	
13	try:
14	    from torch.fx._symbolic_trace import _orig_module_call
15	
16	    tracing_legacy_exists = True
17	except ImportError:
18	    tracing_legacy_exists = False
19	
20	
21	@torch.jit.ignore
22	def is_fx_tracing_legacy() -&gt; bool:
23	    &quot;&quot;&quot;
24	    Returns a bool indicating whether torch.fx is currently symbolically tracing a module.
25	    Can be useful for gating module logic that is incompatible with symbolic tracing.
26	    &quot;&quot;&quot;
27	    return torch.nn.Module.__call__ is not _orig_module_call
28	
29	
30	@torch.jit.ignore
31	def is_fx_tracing() -&gt; bool:
32	    &quot;&quot;&quot;Returns whether execution is currently in
33	    Torch FX tracing mode&quot;&quot;&quot;
34	    if TORCH_VERSION &gt;= (1, 10) and tracing_current_exists:
35	        return is_fx_tracing_current()
36	    elif tracing_legacy_exists:
37	        return is_fx_tracing_legacy()
38	    else:
39	        # Can&#x27;t find either current or legacy tracing indication code.
40	        # Enabling this assert_fx_safe() call regardless of tracing status.
41	        return False
42	
43	
44	@torch.jit.ignore
45	def assert_fx_safe(condition: bool, message: str) -&gt; torch.Tensor:
46	    &quot;&quot;&quot;An FX-tracing safe version of assert.
47	    Avoids erroneous type assertion triggering when types are masked inside
48	    an fx.proxy.Proxy object during tracing.
49	    Args: condition - either a boolean expression or a string representing
50	    the condition to test. If this assert triggers an exception when tracing
51	    due to dynamic control flow, try encasing the expression in quotation
52	    marks and supplying it as a string.&quot;&quot;&quot;
53	    # Must return a concrete tensor for compatibility with PyTorch &lt;=1.8.
54	    # If &lt;=1.8 compatibility is not needed, return type can be converted to None
55	    if not is_fx_tracing():
56	        try:
57	            if isinstance(condition, str):
58	                caller_frame = inspect.currentframe().f_back
59	                torch._assert(
60	                    eval(condition, caller_frame.f_globals, caller_frame.f_locals), message
61	                )
62	                return torch.ones(1)
63	            else:
64	                torch._assert(condition, message)
65	                return torch.ones(1)
66	        except torch.fx.proxy.TraceError as e:
67	            print(
68	                &quot;Found a non-FX compatible assertion. Skipping the check. Failure is shown below&quot;
69	                + str(e)
70	            )
71	    return torch.zeros(1)
</pre>
</div>


</div>
</div>

<div id="issue-58">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>3<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-59">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>4<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-60">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>35<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-61">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>35<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-62">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>37<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-63">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>37<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-64">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>43<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-65">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/argutils.py</a><br>
    <b>Line number: </b>43<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	import datetime
2	import os
3	import pickle
4	import subprocess
5	import sys
6	
7	
8	def print_args(args):
9	    opts = vars(args)
10	    print(&#x27;======= Options ========&#x27;)
11	    for k, v in sorted(opts.items()):
12	        print(&#x27;{}: {}&#x27;.format(k, v))
13	    print(&#x27;========================&#x27;)
14	
15	
16	def save_args(args, save_folder, opt_prefix=&#x27;opt&#x27;, verbose=True):
17	    opts = vars(args)
18	    # Create checkpoint folder
19	    if not os.path.exists(save_folder):
20	        os.makedirs(save_folder, exist_ok=True)
21	
22	    # Save options
23	    opt_filename = &#x27;{}.txt&#x27;.format(opt_prefix)
24	    opt_path = os.path.join(save_folder, opt_filename)
25	    with open(opt_path, &#x27;a&#x27;) as opt_file:
26	        opt_file.write(&#x27;====== Options ======\n&#x27;)
27	        for k, v in sorted(opts.items()):
28	            opt_file.write(
29	                &#x27;{option}: {value}\n&#x27;.format(option=str(k), value=str(v)))
30	        opt_file.write(&#x27;=====================\n&#x27;)
31	        opt_file.write(&#x27;launched {} at {}\n&#x27;.format(
32	            str(sys.argv[0]), str(datetime.datetime.now())))
33	
34	        # Add git info
35	        label = subprocess.check_output([&quot;git&quot;, &quot;describe&quot;,
36	                                         &quot;--always&quot;]).strip()
37	        if subprocess.call(
38	            [&quot;git&quot;, &quot;branch&quot;],
39	                stderr=subprocess.STDOUT,
40	                stdout=open(os.devnull, &#x27;w&#x27;)) == 0:
41	            opt_file.write(&#x27;=== Git info ====\n&#x27;)
42	            opt_file.write(&#x27;{}\n&#x27;.format(label))
43	            commit = subprocess.check_output([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
44	            opt_file.write(&#x27;commit : {}\n&#x27;.format(commit.strip()))
45	
46	    opt_picklename = &#x27;{}.pkl&#x27;.format(opt_prefix)
47	    opt_picklepath = os.path.join(save_folder, opt_picklename)
48	    with open(opt_picklepath, &#x27;wb&#x27;) as opt_file:
49	        pickle.dump(opts, opt_file)
50	    if verbose:
51	        print(&#x27;Saved options to {}&#x27;.format(opt_path))
</pre>
</div>


</div>
</div>

<div id="issue-66">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py</a><br>
    <b>Line number: </b>32<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	&#x27;&#x27;&#x27;
2	Copyright 2017 Javier Romero, Dimitrios Tzionas, Michael J Black and the Max Planck Gesellschaft.  All rights reserved.
3	This software is provided for research purposes only.
4	By using this software you agree to the terms of the MANO/SMPL+H Model license here http://mano.is.tue.mpg.de/license
5	
6	More information about MANO/SMPL+H is available at http://mano.is.tue.mpg.de.
7	For comments or questions, please email us at: mano@tue.mpg.de
8	
9	
10	About this file:
11	================
12	This file defines a wrapper for the loading functions of the MANO model.
13	
14	Modules included:
15	- load_model:
16	  loads the MANO model from a given file location (i.e. a .pkl file location),
17	  or a dictionary object.
18	
19	&#x27;&#x27;&#x27;
20	
21	def col(A):
22	    return A.reshape((-1, 1))
23	
24	def MatVecMult(mtx, vec):
25	    result = mtx.dot(col(vec.ravel())).ravel()
26	    if len(vec.shape) &gt; 1 and vec.shape[1] &gt; 1:
27	        result = result.reshape((-1, vec.shape[1]))
28	    return result
29	
30	def ready_arguments(fname_or_dict, posekey4vposed=&#x27;pose&#x27;):
31	    import numpy as np
32	    import pickle
33	    from custom_manopth.posemapper import posemap
34	
35	    if not isinstance(fname_or_dict, dict):
36	        dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
37	        # dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
38	    else:
39	        dd = fname_or_dict
40	
41	    want_shapemodel = &#x27;shapedirs&#x27; in dd
42	    nposeparms = dd[&#x27;kintree_table&#x27;].shape[1] * 3
43	
44	    if &#x27;trans&#x27; not in dd:
45	        dd[&#x27;trans&#x27;] = np.zeros(3)
46	    if &#x27;pose&#x27; not in dd:
47	        dd[&#x27;pose&#x27;] = np.zeros(nposeparms)
48	    if &#x27;shapedirs&#x27; in dd and &#x27;betas&#x27; not in dd:
49	        dd[&#x27;betas&#x27;] = np.zeros(dd[&#x27;shapedirs&#x27;].shape[-1])
50	
51	    for s in [
52	            &#x27;v_template&#x27;, &#x27;weights&#x27;, &#x27;posedirs&#x27;, &#x27;pose&#x27;, &#x27;trans&#x27;, &#x27;shapedirs&#x27;,
53	            &#x27;betas&#x27;, &#x27;J&#x27;
54	    ]:
55	        if (s in dd) and not hasattr(dd[s], &#x27;dterms&#x27;):
56	            dd[s] = np.array(dd[s])
57	
58	    assert (posekey4vposed in dd)
59	    if want_shapemodel:
60	        dd[&#x27;v_shaped&#x27;] = dd[&#x27;shapedirs&#x27;].dot(dd[&#x27;betas&#x27;]) + dd[&#x27;v_template&#x27;]
61	        v_shaped = dd[&#x27;v_shaped&#x27;]
62	        J_tmpx = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 0])
63	        J_tmpy = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 1])
64	        J_tmpz = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 2])
65	        dd[&#x27;J&#x27;] = np.vstack((J_tmpx, J_tmpy, J_tmpz)).T
66	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
67	        dd[&#x27;v_posed&#x27;] = v_shaped + dd[&#x27;posedirs&#x27;].dot(pose_map_res)
68	    else:
69	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
70	        dd_add = dd[&#x27;posedirs&#x27;].dot(pose_map_res)
71	        dd[&#x27;v_posed&#x27;] = dd[&#x27;v_template&#x27;] + dd_add
72	
73	    return dd
74	
75	
76	def load_model(fname_or_dict, ncomps=6, flat_hand_mean=False, v_template=None):
77	    &#x27;&#x27;&#x27; This model loads the fully articulable HAND SMPL model,
78	    and replaces the pose DOFS by ncomps from PCA&#x27;&#x27;&#x27;
79	
80	    from custom_manopth.verts import verts_core
81	    import numpy as np
82	    import pickle
83	    import scipy.sparse as sp
84	    np.random.seed(1)
85	
86	    if not isinstance(fname_or_dict, dict):
87	        smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
88	        # smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
89	    else:
90	        smpl_data = fname_or_dict
91	
92	    rot = 3  # for global orientation!!!
93	
94	    hands_components = smpl_data[&#x27;hands_components&#x27;]
95	    hands_mean = np.zeros(hands_components.shape[
96	        1]) if flat_hand_mean else smpl_data[&#x27;hands_mean&#x27;]
97	    hands_coeffs = smpl_data[&#x27;hands_coeffs&#x27;][:, :ncomps]
98	
99	    selected_components = np.vstack((hands_components[:ncomps]))
100	    hands_mean = hands_mean.copy()
101	
102	    pose_coeffs = np.zeros(rot + selected_components.shape[0])
103	    full_hand_pose = pose_coeffs[rot:(rot + ncomps)].dot(selected_components)
104	
105	    smpl_data[&#x27;fullpose&#x27;] = np.concatenate((pose_coeffs[:rot],
106	                                            hands_mean + full_hand_pose))
107	    smpl_data[&#x27;pose&#x27;] = pose_coeffs
108	
109	    Jreg = smpl_data[&#x27;J_regressor&#x27;]
110	    if not sp.issparse(Jreg):
111	        smpl_data[&#x27;J_regressor&#x27;] = (sp.csc_matrix(
112	            (Jreg.data, (Jreg.row, Jreg.col)), shape=Jreg.shape))
113	
114	    # slightly modify ready_arguments to make sure that it uses the fullpose
115	    # (which will NOT be pose) for the computation of posedirs
116	    dd = ready_arguments(smpl_data, posekey4vposed=&#x27;fullpose&#x27;)
117	
118	    # create the smpl formula with the fullpose,
119	    # but expose the PCA coefficients as smpl.pose for compatibility
120	    args = {
</pre>
</div>


</div>
</div>

<div id="issue-67">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py</a><br>
    <b>Line number: </b>36<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
1	&#x27;&#x27;&#x27;
2	Copyright 2017 Javier Romero, Dimitrios Tzionas, Michael J Black and the Max Planck Gesellschaft.  All rights reserved.
3	This software is provided for research purposes only.
4	By using this software you agree to the terms of the MANO/SMPL+H Model license here http://mano.is.tue.mpg.de/license
5	
6	More information about MANO/SMPL+H is available at http://mano.is.tue.mpg.de.
7	For comments or questions, please email us at: mano@tue.mpg.de
8	
9	
10	About this file:
11	================
12	This file defines a wrapper for the loading functions of the MANO model.
13	
14	Modules included:
15	- load_model:
16	  loads the MANO model from a given file location (i.e. a .pkl file location),
17	  or a dictionary object.
18	
19	&#x27;&#x27;&#x27;
20	
21	def col(A):
22	    return A.reshape((-1, 1))
23	
24	def MatVecMult(mtx, vec):
25	    result = mtx.dot(col(vec.ravel())).ravel()
26	    if len(vec.shape) &gt; 1 and vec.shape[1] &gt; 1:
27	        result = result.reshape((-1, vec.shape[1]))
28	    return result
29	
30	def ready_arguments(fname_or_dict, posekey4vposed=&#x27;pose&#x27;):
31	    import numpy as np
32	    import pickle
33	    from custom_manopth.posemapper import posemap
34	
35	    if not isinstance(fname_or_dict, dict):
36	        dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
37	        # dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
38	    else:
39	        dd = fname_or_dict
40	
41	    want_shapemodel = &#x27;shapedirs&#x27; in dd
42	    nposeparms = dd[&#x27;kintree_table&#x27;].shape[1] * 3
43	
44	    if &#x27;trans&#x27; not in dd:
45	        dd[&#x27;trans&#x27;] = np.zeros(3)
46	    if &#x27;pose&#x27; not in dd:
47	        dd[&#x27;pose&#x27;] = np.zeros(nposeparms)
48	    if &#x27;shapedirs&#x27; in dd and &#x27;betas&#x27; not in dd:
49	        dd[&#x27;betas&#x27;] = np.zeros(dd[&#x27;shapedirs&#x27;].shape[-1])
50	
51	    for s in [
52	            &#x27;v_template&#x27;, &#x27;weights&#x27;, &#x27;posedirs&#x27;, &#x27;pose&#x27;, &#x27;trans&#x27;, &#x27;shapedirs&#x27;,
53	            &#x27;betas&#x27;, &#x27;J&#x27;
54	    ]:
55	        if (s in dd) and not hasattr(dd[s], &#x27;dterms&#x27;):
56	            dd[s] = np.array(dd[s])
57	
58	    assert (posekey4vposed in dd)
59	    if want_shapemodel:
60	        dd[&#x27;v_shaped&#x27;] = dd[&#x27;shapedirs&#x27;].dot(dd[&#x27;betas&#x27;]) + dd[&#x27;v_template&#x27;]
61	        v_shaped = dd[&#x27;v_shaped&#x27;]
62	        J_tmpx = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 0])
63	        J_tmpy = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 1])
64	        J_tmpz = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 2])
65	        dd[&#x27;J&#x27;] = np.vstack((J_tmpx, J_tmpy, J_tmpz)).T
66	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
67	        dd[&#x27;v_posed&#x27;] = v_shaped + dd[&#x27;posedirs&#x27;].dot(pose_map_res)
68	    else:
69	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
70	        dd_add = dd[&#x27;posedirs&#x27;].dot(pose_map_res)
71	        dd[&#x27;v_posed&#x27;] = dd[&#x27;v_template&#x27;] + dd_add
72	
73	    return dd
74	
75	
76	def load_model(fname_or_dict, ncomps=6, flat_hand_mean=False, v_template=None):
77	    &#x27;&#x27;&#x27; This model loads the fully articulable HAND SMPL model,
78	    and replaces the pose DOFS by ncomps from PCA&#x27;&#x27;&#x27;
79	
80	    from custom_manopth.verts import verts_core
81	    import numpy as np
82	    import pickle
83	    import scipy.sparse as sp
84	    np.random.seed(1)
85	
86	    if not isinstance(fname_or_dict, dict):
87	        smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
88	        # smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
89	    else:
90	        smpl_data = fname_or_dict
91	
92	    rot = 3  # for global orientation!!!
93	
94	    hands_components = smpl_data[&#x27;hands_components&#x27;]
95	    hands_mean = np.zeros(hands_components.shape[
96	        1]) if flat_hand_mean else smpl_data[&#x27;hands_mean&#x27;]
97	    hands_coeffs = smpl_data[&#x27;hands_coeffs&#x27;][:, :ncomps]
98	
99	    selected_components = np.vstack((hands_components[:ncomps]))
100	    hands_mean = hands_mean.copy()
101	
102	    pose_coeffs = np.zeros(rot + selected_components.shape[0])
103	    full_hand_pose = pose_coeffs[rot:(rot + ncomps)].dot(selected_components)
104	
105	    smpl_data[&#x27;fullpose&#x27;] = np.concatenate((pose_coeffs[:rot],
106	                                            hands_mean + full_hand_pose))
107	    smpl_data[&#x27;pose&#x27;] = pose_coeffs
108	
109	    Jreg = smpl_data[&#x27;J_regressor&#x27;]
110	    if not sp.issparse(Jreg):
111	        smpl_data[&#x27;J_regressor&#x27;] = (sp.csc_matrix(
112	            (Jreg.data, (Jreg.row, Jreg.col)), shape=Jreg.shape))
113	
114	    # slightly modify ready_arguments to make sure that it uses the fullpose
115	    # (which will NOT be pose) for the computation of posedirs
116	    dd = ready_arguments(smpl_data, posekey4vposed=&#x27;fullpose&#x27;)
117	
118	    # create the smpl formula with the fullpose,
119	    # but expose the PCA coefficients as smpl.pose for compatibility
120	    args = {
</pre>
</div>


</div>
</div>

<div id="issue-68">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py</a><br>
    <b>Line number: </b>82<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
22	    return A.reshape((-1, 1))
23	
24	def MatVecMult(mtx, vec):
25	    result = mtx.dot(col(vec.ravel())).ravel()
26	    if len(vec.shape) &gt; 1 and vec.shape[1] &gt; 1:
27	        result = result.reshape((-1, vec.shape[1]))
28	    return result
29	
30	def ready_arguments(fname_or_dict, posekey4vposed=&#x27;pose&#x27;):
31	    import numpy as np
32	    import pickle
33	    from custom_manopth.posemapper import posemap
34	
35	    if not isinstance(fname_or_dict, dict):
36	        dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
37	        # dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
38	    else:
39	        dd = fname_or_dict
40	
41	    want_shapemodel = &#x27;shapedirs&#x27; in dd
42	    nposeparms = dd[&#x27;kintree_table&#x27;].shape[1] * 3
43	
44	    if &#x27;trans&#x27; not in dd:
45	        dd[&#x27;trans&#x27;] = np.zeros(3)
46	    if &#x27;pose&#x27; not in dd:
47	        dd[&#x27;pose&#x27;] = np.zeros(nposeparms)
48	    if &#x27;shapedirs&#x27; in dd and &#x27;betas&#x27; not in dd:
49	        dd[&#x27;betas&#x27;] = np.zeros(dd[&#x27;shapedirs&#x27;].shape[-1])
50	
51	    for s in [
52	            &#x27;v_template&#x27;, &#x27;weights&#x27;, &#x27;posedirs&#x27;, &#x27;pose&#x27;, &#x27;trans&#x27;, &#x27;shapedirs&#x27;,
53	            &#x27;betas&#x27;, &#x27;J&#x27;
54	    ]:
55	        if (s in dd) and not hasattr(dd[s], &#x27;dterms&#x27;):
56	            dd[s] = np.array(dd[s])
57	
58	    assert (posekey4vposed in dd)
59	    if want_shapemodel:
60	        dd[&#x27;v_shaped&#x27;] = dd[&#x27;shapedirs&#x27;].dot(dd[&#x27;betas&#x27;]) + dd[&#x27;v_template&#x27;]
61	        v_shaped = dd[&#x27;v_shaped&#x27;]
62	        J_tmpx = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 0])
63	        J_tmpy = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 1])
64	        J_tmpz = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 2])
65	        dd[&#x27;J&#x27;] = np.vstack((J_tmpx, J_tmpy, J_tmpz)).T
66	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
67	        dd[&#x27;v_posed&#x27;] = v_shaped + dd[&#x27;posedirs&#x27;].dot(pose_map_res)
68	    else:
69	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
70	        dd_add = dd[&#x27;posedirs&#x27;].dot(pose_map_res)
71	        dd[&#x27;v_posed&#x27;] = dd[&#x27;v_template&#x27;] + dd_add
72	
73	    return dd
74	
75	
76	def load_model(fname_or_dict, ncomps=6, flat_hand_mean=False, v_template=None):
77	    &#x27;&#x27;&#x27; This model loads the fully articulable HAND SMPL model,
78	    and replaces the pose DOFS by ncomps from PCA&#x27;&#x27;&#x27;
79	
80	    from custom_manopth.verts import verts_core
81	    import numpy as np
82	    import pickle
83	    import scipy.sparse as sp
84	    np.random.seed(1)
85	
86	    if not isinstance(fname_or_dict, dict):
87	        smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
88	        # smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
89	    else:
90	        smpl_data = fname_or_dict
91	
92	    rot = 3  # for global orientation!!!
93	
94	    hands_components = smpl_data[&#x27;hands_components&#x27;]
95	    hands_mean = np.zeros(hands_components.shape[
96	        1]) if flat_hand_mean else smpl_data[&#x27;hands_mean&#x27;]
97	    hands_coeffs = smpl_data[&#x27;hands_coeffs&#x27;][:, :ncomps]
98	
99	    selected_components = np.vstack((hands_components[:ncomps]))
100	    hands_mean = hands_mean.copy()
101	
102	    pose_coeffs = np.zeros(rot + selected_components.shape[0])
103	    full_hand_pose = pose_coeffs[rot:(rot + ncomps)].dot(selected_components)
104	
105	    smpl_data[&#x27;fullpose&#x27;] = np.concatenate((pose_coeffs[:rot],
106	                                            hands_mean + full_hand_pose))
107	    smpl_data[&#x27;pose&#x27;] = pose_coeffs
108	
109	    Jreg = smpl_data[&#x27;J_regressor&#x27;]
110	    if not sp.issparse(Jreg):
111	        smpl_data[&#x27;J_regressor&#x27;] = (sp.csc_matrix(
112	            (Jreg.data, (Jreg.row, Jreg.col)), shape=Jreg.shape))
113	
114	    # slightly modify ready_arguments to make sure that it uses the fullpose
115	    # (which will NOT be pose) for the computation of posedirs
116	    dd = ready_arguments(smpl_data, posekey4vposed=&#x27;fullpose&#x27;)
117	
118	    # create the smpl formula with the fullpose,
119	    # but expose the PCA coefficients as smpl.pose for compatibility
120	    args = {
121	        &#x27;pose&#x27;: dd[&#x27;fullpose&#x27;],
122	        &#x27;v&#x27;: dd[&#x27;v_posed&#x27;],
123	        &#x27;J&#x27;: dd[&#x27;J&#x27;],
124	        &#x27;weights&#x27;: dd[&#x27;weights&#x27;],
125	        &#x27;kintree_table&#x27;: dd[&#x27;kintree_table&#x27;],
126	        &#x27;xp&#x27;: np,
127	        &#x27;want_Jtr&#x27;: True,
128	        &#x27;bs_style&#x27;: dd[&#x27;bs_style&#x27;],
129	    }
130	
131	    result_previous, meta = verts_core(**args)
132	
133	    result = result_previous + dd[&#x27;trans&#x27;].reshape((1, 3))
134	    result.no_translation = result_previous
135	
136	    if meta is not None:
137	        for field in [&#x27;Jtr&#x27;, &#x27;A&#x27;, &#x27;A_global&#x27;, &#x27;A_weighted&#x27;]:
138	            if (hasattr(meta, field)):
139	                setattr(result, field, getattr(meta, field))
140	
141	    setattr(result, &#x27;Jtr&#x27;, meta)
</pre>
</div>


</div>
</div>

<div id="issue-69">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_manopth/smpl_handpca_wrapper_HAND_only.py</a><br>
    <b>Line number: </b>87<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
27	        result = result.reshape((-1, vec.shape[1]))
28	    return result
29	
30	def ready_arguments(fname_or_dict, posekey4vposed=&#x27;pose&#x27;):
31	    import numpy as np
32	    import pickle
33	    from custom_manopth.posemapper import posemap
34	
35	    if not isinstance(fname_or_dict, dict):
36	        dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
37	        # dd = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
38	    else:
39	        dd = fname_or_dict
40	
41	    want_shapemodel = &#x27;shapedirs&#x27; in dd
42	    nposeparms = dd[&#x27;kintree_table&#x27;].shape[1] * 3
43	
44	    if &#x27;trans&#x27; not in dd:
45	        dd[&#x27;trans&#x27;] = np.zeros(3)
46	    if &#x27;pose&#x27; not in dd:
47	        dd[&#x27;pose&#x27;] = np.zeros(nposeparms)
48	    if &#x27;shapedirs&#x27; in dd and &#x27;betas&#x27; not in dd:
49	        dd[&#x27;betas&#x27;] = np.zeros(dd[&#x27;shapedirs&#x27;].shape[-1])
50	
51	    for s in [
52	            &#x27;v_template&#x27;, &#x27;weights&#x27;, &#x27;posedirs&#x27;, &#x27;pose&#x27;, &#x27;trans&#x27;, &#x27;shapedirs&#x27;,
53	            &#x27;betas&#x27;, &#x27;J&#x27;
54	    ]:
55	        if (s in dd) and not hasattr(dd[s], &#x27;dterms&#x27;):
56	            dd[s] = np.array(dd[s])
57	
58	    assert (posekey4vposed in dd)
59	    if want_shapemodel:
60	        dd[&#x27;v_shaped&#x27;] = dd[&#x27;shapedirs&#x27;].dot(dd[&#x27;betas&#x27;]) + dd[&#x27;v_template&#x27;]
61	        v_shaped = dd[&#x27;v_shaped&#x27;]
62	        J_tmpx = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 0])
63	        J_tmpy = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 1])
64	        J_tmpz = MatVecMult(dd[&#x27;J_regressor&#x27;], v_shaped[:, 2])
65	        dd[&#x27;J&#x27;] = np.vstack((J_tmpx, J_tmpy, J_tmpz)).T
66	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
67	        dd[&#x27;v_posed&#x27;] = v_shaped + dd[&#x27;posedirs&#x27;].dot(pose_map_res)
68	    else:
69	        pose_map_res = posemap(dd[&#x27;bs_type&#x27;])(dd[posekey4vposed])
70	        dd_add = dd[&#x27;posedirs&#x27;].dot(pose_map_res)
71	        dd[&#x27;v_posed&#x27;] = dd[&#x27;v_template&#x27;] + dd_add
72	
73	    return dd
74	
75	
76	def load_model(fname_or_dict, ncomps=6, flat_hand_mean=False, v_template=None):
77	    &#x27;&#x27;&#x27; This model loads the fully articulable HAND SMPL model,
78	    and replaces the pose DOFS by ncomps from PCA&#x27;&#x27;&#x27;
79	
80	    from custom_manopth.verts import verts_core
81	    import numpy as np
82	    import pickle
83	    import scipy.sparse as sp
84	    np.random.seed(1)
85	
86	    if not isinstance(fname_or_dict, dict):
87	        smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;)
88	        # smpl_data = pickle.load(open(fname_or_dict, &#x27;rb&#x27;))
89	    else:
90	        smpl_data = fname_or_dict
91	
92	    rot = 3  # for global orientation!!!
93	
94	    hands_components = smpl_data[&#x27;hands_components&#x27;]
95	    hands_mean = np.zeros(hands_components.shape[
96	        1]) if flat_hand_mean else smpl_data[&#x27;hands_mean&#x27;]
97	    hands_coeffs = smpl_data[&#x27;hands_coeffs&#x27;][:, :ncomps]
98	
99	    selected_components = np.vstack((hands_components[:ncomps]))
100	    hands_mean = hands_mean.copy()
101	
102	    pose_coeffs = np.zeros(rot + selected_components.shape[0])
103	    full_hand_pose = pose_coeffs[rot:(rot + ncomps)].dot(selected_components)
104	
105	    smpl_data[&#x27;fullpose&#x27;] = np.concatenate((pose_coeffs[:rot],
106	                                            hands_mean + full_hand_pose))
107	    smpl_data[&#x27;pose&#x27;] = pose_coeffs
108	
109	    Jreg = smpl_data[&#x27;J_regressor&#x27;]
110	    if not sp.issparse(Jreg):
111	        smpl_data[&#x27;J_regressor&#x27;] = (sp.csc_matrix(
112	            (Jreg.data, (Jreg.row, Jreg.col)), shape=Jreg.shape))
113	
114	    # slightly modify ready_arguments to make sure that it uses the fullpose
115	    # (which will NOT be pose) for the computation of posedirs
116	    dd = ready_arguments(smpl_data, posekey4vposed=&#x27;fullpose&#x27;)
117	
118	    # create the smpl formula with the fullpose,
119	    # but expose the PCA coefficients as smpl.pose for compatibility
120	    args = {
121	        &#x27;pose&#x27;: dd[&#x27;fullpose&#x27;],
122	        &#x27;v&#x27;: dd[&#x27;v_posed&#x27;],
123	        &#x27;J&#x27;: dd[&#x27;J&#x27;],
124	        &#x27;weights&#x27;: dd[&#x27;weights&#x27;],
125	        &#x27;kintree_table&#x27;: dd[&#x27;kintree_table&#x27;],
126	        &#x27;xp&#x27;: np,
127	        &#x27;want_Jtr&#x27;: True,
128	        &#x27;bs_style&#x27;: dd[&#x27;bs_style&#x27;],
129	    }
130	
131	    result_previous, meta = verts_core(**args)
132	
133	    result = result_previous + dd[&#x27;trans&#x27;].reshape((1, 3))
134	    result.no_translation = result_previous
135	
136	    if meta is not None:
137	        for field in [&#x27;Jtr&#x27;, &#x27;A&#x27;, &#x27;A_global&#x27;, &#x27;A_weighted&#x27;]:
138	            if (hasattr(meta, field)):
139	                setattr(result, field, getattr(meta, field))
140	
141	    setattr(result, &#x27;Jtr&#x27;, meta)
142	    if hasattr(result, &#x27;Jtr&#x27;):
143	        result.J_transformed = result.Jtr + dd[&#x27;trans&#x27;].reshape((1, 3))
144	
145	    for k, v in dd.items():
146	        setattr(result, k, v)
</pre>
</div>


</div>
</div>

<div id="issue-70">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with cPickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/modeling/_smpl.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/modeling/_smpl.py</a><br>
    <b>Line number: </b>13<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot;
2	This file contains the definition of the SMPL model
3	
4	It is adapted from opensource project GraphCMR (https://github.com/nkolot/GraphCMR/)
5	&quot;&quot;&quot;
6	from __future__ import division
7	
8	import torch
9	import torch.nn as nn
10	import numpy as np
11	import scipy.sparse
12	try:
13	    import cPickle as pickle
14	except ImportError:
15	    import pickle
16	
17	from custom_mesh_graphormer.utils.geometric_layers import rodrigues
18	import custom_mesh_graphormer.modeling.data.config as cfg
19	
20	from comfy.model_management import get_torch_device
21	from wrapper_for_mps import sparse_to_dense
22	device = get_torch_device()
23	
24	class SMPL(nn.Module):
25	
26	    def __init__(self, gender=&#x27;neutral&#x27;):
27	        super(SMPL, self).__init__()
28	
29	        if gender==&#x27;m&#x27;:
30	            model_file=cfg.SMPL_Male
31	        elif gender==&#x27;f&#x27;:
32	            model_file=cfg.SMPL_Female
33	        else:
34	            model_file=cfg.SMPL_FILE
35	
36	        smpl_model = pickle.load(open(model_file, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;) 
37	        J_regressor = smpl_model[&#x27;J_regressor&#x27;].tocoo()
38	        row = J_regressor.row
39	        col = J_regressor.col
40	        data = J_regressor.data
41	        i = torch.LongTensor([row, col])
42	        v = torch.FloatTensor(data)
43	        J_regressor_shape = [24, 6890]
44	        self.register_buffer(&#x27;J_regressor&#x27;, torch.sparse_coo_tensor(i, v, J_regressor_shape).to_dense())
45	        self.register_buffer(&#x27;weights&#x27;, torch.FloatTensor(smpl_model[&#x27;weights&#x27;]))
46	        self.register_buffer(&#x27;posedirs&#x27;, torch.FloatTensor(smpl_model[&#x27;posedirs&#x27;]))
47	        self.register_buffer(&#x27;v_template&#x27;, torch.FloatTensor(smpl_model[&#x27;v_template&#x27;]))
48	        self.register_buffer(&#x27;shapedirs&#x27;, torch.FloatTensor(np.array(smpl_model[&#x27;shapedirs&#x27;])))
49	        self.register_buffer(&#x27;faces&#x27;, torch.from_numpy(smpl_model[&#x27;f&#x27;].astype(np.int64)))
50	        self.register_buffer(&#x27;kintree_table&#x27;, torch.from_numpy(smpl_model[&#x27;kintree_table&#x27;].astype(np.int64)))
51	        id_to_col = {self.kintree_table[1, i].item(): i for i in range(self.kintree_table.shape[1])}
52	        self.register_buffer(&#x27;parent&#x27;, torch.LongTensor([id_to_col[self.kintree_table[0, it].item()] for it in range(1, self.kintree_table.shape[1])]))
53	
54	        self.pose_shape = [24, 3]
55	        self.beta_shape = [10]
56	        self.translation_shape = [3]
57	
58	        self.pose = torch.zeros(self.pose_shape)
59	        self.beta = torch.zeros(self.beta_shape)
60	        self.translation = torch.zeros(self.translation_shape)
61	
62	        self.verts = None
63	        self.J = None
64	        self.R = None
65	        
66	        J_regressor_extra = torch.from_numpy(np.load(cfg.JOINT_REGRESSOR_TRAIN_EXTRA)).float()
67	        self.register_buffer(&#x27;J_regressor_extra&#x27;, J_regressor_extra)
68	        self.joints_idx = cfg.JOINTS_IDX
69	
70	        J_regressor_h36m_correct = torch.from_numpy(np.load(cfg.JOINT_REGRESSOR_H36M_correct)).float()
71	        self.register_buffer(&#x27;J_regressor_h36m_correct&#x27;, J_regressor_h36m_correct)
72	
73	
74	    def forward(self, pose, beta):
75	        device = pose.device
76	        batch_size = pose.shape[0]
77	        v_template = self.v_template[None, :]
78	        shapedirs = self.shapedirs.view(-1,10)[None, :].expand(batch_size, -1, -1)
79	        beta = beta[:, :, None]
80	        v_shaped = torch.matmul(shapedirs, beta).view(-1, 6890, 3) + v_template
81	        # batched sparse matmul not supported in pytorch
82	        J = []
83	        for i in range(batch_size):
84	            J.append(torch.matmul(self.J_regressor, v_shaped[i]))
85	        J = torch.stack(J, dim=0)
86	        # input it rotmat: (bs,24,3,3)
87	        if pose.ndimension() == 4:
88	            R = pose
89	        # input it rotmat: (bs,72)
90	        elif pose.ndimension() == 2:
91	            pose_cube = pose.view(-1, 3) # (batch_size * 24, 1, 3)
92	            R = rodrigues(pose_cube).view(batch_size, 24, 3, 3)
93	            R = R.view(batch_size, 24, 3, 3)
94	        I_cube = torch.eye(3)[None, None, :].to(device)
95	        # I_cube = torch.eye(3)[None, None, :].expand(theta.shape[0], R.shape[1]-1, -1, -1)
96	        lrotmin = (R[:,1:,:] - I_cube).view(batch_size, -1)
97	        posedirs = self.posedirs.view(-1,207)[None, :].expand(batch_size, -1, -1)
98	        v_posed = v_shaped + torch.matmul(posedirs, lrotmin[:, :, None]).view(-1, 6890, 3)
99	        J_ = J.clone()
100	        J_[:, 1:, :] = J[:, 1:, :] - J[:, self.parent, :]
101	        G_ = torch.cat([R, J_[:, :, :, None]], dim=-1)
102	        pad_row = torch.FloatTensor([0,0,0,1]).to(device).view(1,1,1,4).expand(batch_size, 24, -1, -1)
103	        G_ = torch.cat([G_, pad_row], dim=2)
104	        G = [G_[:, 0].clone()]
105	        for i in range(1, 24):
106	            G.append(torch.matmul(G[self.parent[i-1]], G_[:, i, :, :]))
107	        G = torch.stack(G, dim=1)
108	
109	        rest = torch.cat([J, torch.zeros(batch_size, 24, 1).to(device)], dim=2).view(batch_size, 24, 4, 1)
110	        zeros = torch.zeros(batch_size, 24, 4, 3).to(device)
111	        rest = torch.cat([zeros, rest], dim=-1)
112	        rest = torch.matmul(G, rest)
113	        G = G - rest
114	        T = torch.matmul(self.weights, G.permute(1,0,2,3).contiguous().view(24,-1)).view(6890, batch_size, 4, 4).transpose(0,1)
115	        rest_shape_h = torch.cat([v_posed, torch.ones_like(v_posed)[:, :, [0]]], dim=-1)
116	        v = torch.matmul(T, rest_shape_h[:, :, :, None])[:, :, :3, 0]
117	        return v
118	
119	    def get_joints(self, vertices):
120	        &quot;&quot;&quot;
</pre>
</div>


</div>
</div>

<div id="issue-71">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/modeling/_smpl.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/modeling/_smpl.py</a><br>
    <b>Line number: </b>15<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot;
2	This file contains the definition of the SMPL model
3	
4	It is adapted from opensource project GraphCMR (https://github.com/nkolot/GraphCMR/)
5	&quot;&quot;&quot;
6	from __future__ import division
7	
8	import torch
9	import torch.nn as nn
10	import numpy as np
11	import scipy.sparse
12	try:
13	    import cPickle as pickle
14	except ImportError:
15	    import pickle
16	
17	from custom_mesh_graphormer.utils.geometric_layers import rodrigues
18	import custom_mesh_graphormer.modeling.data.config as cfg
19	
20	from comfy.model_management import get_torch_device
21	from wrapper_for_mps import sparse_to_dense
22	device = get_torch_device()
23	
24	class SMPL(nn.Module):
25	
26	    def __init__(self, gender=&#x27;neutral&#x27;):
27	        super(SMPL, self).__init__()
28	
29	        if gender==&#x27;m&#x27;:
30	            model_file=cfg.SMPL_Male
31	        elif gender==&#x27;f&#x27;:
32	            model_file=cfg.SMPL_Female
33	        else:
34	            model_file=cfg.SMPL_FILE
35	
36	        smpl_model = pickle.load(open(model_file, &#x27;rb&#x27;), encoding=&#x27;latin1&#x27;) 
37	        J_regressor = smpl_model[&#x27;J_regressor&#x27;].tocoo()
38	        row = J_regressor.row
39	        col = J_regressor.col
40	        data = J_regressor.data
41	        i = torch.LongTensor([row, col])
42	        v = torch.FloatTensor(data)
43	        J_regressor_shape = [24, 6890]
44	        self.register_buffer(&#x27;J_regressor&#x27;, torch.sparse_coo_tensor(i, v, J_regressor_shape).to_dense())
45	        self.register_buffer(&#x27;weights&#x27;, torch.FloatTensor(smpl_model[&#x27;weights&#x27;]))
46	        self.register_buffer(&#x27;posedirs&#x27;, torch.FloatTensor(smpl_model[&#x27;posedirs&#x27;]))
47	        self.register_buffer(&#x27;v_template&#x27;, torch.FloatTensor(smpl_model[&#x27;v_template&#x27;]))
48	        self.register_buffer(&#x27;shapedirs&#x27;, torch.FloatTensor(np.array(smpl_model[&#x27;shapedirs&#x27;])))
49	        self.register_buffer(&#x27;faces&#x27;, torch.from_numpy(smpl_model[&#x27;f&#x27;].astype(np.int64)))
50	        self.register_buffer(&#x27;kintree_table&#x27;, torch.from_numpy(smpl_model[&#x27;kintree_table&#x27;].astype(np.int64)))
51	        id_to_col = {self.kintree_table[1, i].item(): i for i in range(self.kintree_table.shape[1])}
52	        self.register_buffer(&#x27;parent&#x27;, torch.LongTensor([id_to_col[self.kintree_table[0, it].item()] for it in range(1, self.kintree_table.shape[1])]))
53	
54	        self.pose_shape = [24, 3]
55	        self.beta_shape = [10]
56	        self.translation_shape = [3]
57	
58	        self.pose = torch.zeros(self.pose_shape)
59	        self.beta = torch.zeros(self.beta_shape)
60	        self.translation = torch.zeros(self.translation_shape)
61	
62	        self.verts = None
63	        self.J = None
64	        self.R = None
65	        
66	        J_regressor_extra = torch.from_numpy(np.load(cfg.JOINT_REGRESSOR_TRAIN_EXTRA)).float()
67	        self.register_buffer(&#x27;J_regressor_extra&#x27;, J_regressor_extra)
68	        self.joints_idx = cfg.JOINTS_IDX
69	
70	        J_regressor_h36m_correct = torch.from_numpy(np.load(cfg.JOINT_REGRESSOR_H36M_correct)).float()
71	        self.register_buffer(&#x27;J_regressor_h36m_correct&#x27;, J_regressor_h36m_correct)
72	
73	
74	    def forward(self, pose, beta):
75	        device = pose.device
76	        batch_size = pose.shape[0]
77	        v_template = self.v_template[None, :]
78	        shapedirs = self.shapedirs.view(-1,10)[None, :].expand(batch_size, -1, -1)
79	        beta = beta[:, :, None]
80	        v_shaped = torch.matmul(shapedirs, beta).view(-1, 6890, 3) + v_template
81	        # batched sparse matmul not supported in pytorch
82	        J = []
83	        for i in range(batch_size):
84	            J.append(torch.matmul(self.J_regressor, v_shaped[i]))
85	        J = torch.stack(J, dim=0)
86	        # input it rotmat: (bs,24,3,3)
87	        if pose.ndimension() == 4:
88	            R = pose
89	        # input it rotmat: (bs,72)
90	        elif pose.ndimension() == 2:
91	            pose_cube = pose.view(-1, 3) # (batch_size * 24, 1, 3)
92	            R = rodrigues(pose_cube).view(batch_size, 24, 3, 3)
93	            R = R.view(batch_size, 24, 3, 3)
94	        I_cube = torch.eye(3)[None, None, :].to(device)
95	        # I_cube = torch.eye(3)[None, None, :].expand(theta.shape[0], R.shape[1]-1, -1, -1)
96	        lrotmin = (R[:,1:,:] - I_cube).view(batch_size, -1)
97	        posedirs = self.posedirs.view(-1,207)[None, :].expand(batch_size, -1, -1)
98	        v_posed = v_shaped + torch.matmul(posedirs, lrotmin[:, :, None]).view(-1, 6890, 3)
99	        J_ = J.clone()
100	        J_[:, 1:, :] = J[:, 1:, :] - J[:, self.parent, :]
101	        G_ = torch.cat([R, J_[:, :, :, None]], dim=-1)
102	        pad_row = torch.FloatTensor([0,0,0,1]).to(device).view(1,1,1,4).expand(batch_size, 24, -1, -1)
103	        G_ = torch.cat([G_, pad_row], dim=2)
104	        G = [G_[:, 0].clone()]
105	        for i in range(1, 24):
106	            G.append(torch.matmul(G[self.parent[i-1]], G_[:, i, :, :]))
107	        G = torch.stack(G, dim=1)
108	
109	        rest = torch.cat([J, torch.zeros(batch_size, 24, 1).to(device)], dim=2).view(batch_size, 24, 4, 1)
110	        zeros = torch.zeros(batch_size, 24, 4, 3).to(device)
111	        rest = torch.cat([zeros, rest], dim=-1)
112	        rest = torch.matmul(G, rest)
113	        G = G - rest
114	        T = torch.matmul(self.weights, G.permute(1,0,2,3).contiguous().view(24,-1)).view(6890, batch_size, 4, 4).transpose(0,1)
115	        rest_shape_h = torch.cat([v_posed, torch.ones_like(v_posed)[:, :, [0]]], dim=-1)
116	        v = torch.matmul(T, rest_shape_h[:, :, :, None])[:, :, :3, 0]
117	        return v
118	
119	    def get_joints(self, vertices):
120	        &quot;&quot;&quot;
</pre>
</div>


</div>
</div>

<div id="issue-72">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_bodymesh.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_bodymesh.py</a><br>
    <b>Line number: </b>60<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot;
2	Copyright (c) Microsoft Corporation.
3	Licensed under the MIT license.
4	
5	Training and evaluation codes for 
6	3D human body mesh reconstruction from an image
7	&quot;&quot;&quot;
8	
9	from __future__ import absolute_import, division, print_function
10	import argparse
11	import os
12	import os.path as op
13	import code
14	import json
15	import time
16	import datetime
17	import torch
18	import torchvision.models as models
19	from torchvision.utils import make_grid
20	import gc
21	import numpy as np
22	import cv2
23	from custom_mesh_graphormer.modeling.bert import BertConfig, Graphormer
24	from custom_mesh_graphormer.modeling.bert import Graphormer_Body_Network as Graphormer_Network
25	from custom_mesh_graphormer.modeling._smpl import SMPL, Mesh
26	from custom_mesh_graphormer.modeling.hrnet.hrnet_cls_net_gridfeat import get_cls_net_gridfeat
27	from custom_mesh_graphormer.modeling.hrnet.config import config as hrnet_config
28	from custom_mesh_graphormer.modeling.hrnet.config import update_config as hrnet_update_config
29	import custom_mesh_graphormer.modeling.data.config as cfg
30	from custom_mesh_graphormer.datasets.build import make_data_loader
31	
32	from custom_mesh_graphormer.utils.logger import setup_logger
33	from custom_mesh_graphormer.utils.comm import synchronize, is_main_process, get_rank, get_world_size, all_gather
34	from custom_mesh_graphormer.utils.miscellaneous import mkdir, set_seed
35	from custom_mesh_graphormer.utils.metric_logger import AverageMeter, EvalMetricsLogger
36	from custom_mesh_graphormer.utils.renderer import Renderer, visualize_reconstruction, visualize_reconstruction_test
37	from custom_mesh_graphormer.utils.metric_pampjpe import reconstruction_error
38	from custom_mesh_graphormer.utils.geometric_layers import orthographic_projection
39	
40	from comfy.model_management import get_torch_device
41	device = get_torch_device()
42	
43	from azureml.core.run import Run
44	aml_run = Run.get_context()
45	
46	def save_checkpoint(model, args, epoch, iteration, num_trial=10):
47	    checkpoint_dir = op.join(args.output_dir, &#x27;checkpoint-{}-{}&#x27;.format(
48	        epoch, iteration))
49	    if not is_main_process():
50	        return checkpoint_dir
51	    mkdir(checkpoint_dir)
52	    model_to_save = model.module if hasattr(model, &#x27;module&#x27;) else model
53	    for i in range(num_trial):
54	        try:
55	            torch.save(model_to_save, op.join(checkpoint_dir, &#x27;model.bin&#x27;))
56	            torch.save(model_to_save.state_dict(), op.join(checkpoint_dir, &#x27;state_dict.bin&#x27;))
57	            torch.save(args, op.join(checkpoint_dir, &#x27;training_args.bin&#x27;))
58	            logger.info(&quot;Save checkpoint to {}&quot;.format(checkpoint_dir))
59	            break
60	        except:
61	            pass
62	    else:
63	        logger.info(&quot;Failed to save checkpoint after {} trails.&quot;.format(num_trial))
64	    return checkpoint_dir
65	
66	def save_scores(args, split, mpjpe, pampjpe, mpve):
67	    eval_log = []
68	    res = {}
69	    res[&#x27;mPJPE&#x27;] = mpjpe
70	    res[&#x27;PAmPJPE&#x27;] = pampjpe
71	    res[&#x27;mPVE&#x27;] = mpve
72	    eval_log.append(res)
73	    with open(op.join(args.output_dir, split+&#x27;_eval_logs.json&#x27;), &#x27;w&#x27;) as f:
74	        json.dump(eval_log, f)
75	    logger.info(&quot;Save eval scores to {}&quot;.format(args.output_dir))
76	    return
77	
78	def adjust_learning_rate(optimizer, epoch, args):
79	    &quot;&quot;&quot;
80	    Sets the learning rate to the initial LR decayed by x every y epochs
81	    x = 0.1, y = args.num_train_epochs/2.0 = 100
82	    &quot;&quot;&quot;
83	    lr = args.lr * (0.1 ** (epoch // (args.num_train_epochs/2.0)  ))
84	    for param_group in optimizer.param_groups:
85	        param_group[&#x27;lr&#x27;] = lr
86	
87	def mean_per_joint_position_error(pred, gt, has_3d_joints):
88	    &quot;&quot;&quot; 
89	    Compute mPJPE
90	    &quot;&quot;&quot;
91	    gt = gt[has_3d_joints == 1]
92	    gt = gt[:, :, :-1]
93	    pred = pred[has_3d_joints == 1]
94	
95	    with torch.no_grad():
96	        gt_pelvis = (gt[:, 2,:] + gt[:, 3,:]) / 2
97	        gt = gt - gt_pelvis[:, None, :]
98	        pred_pelvis = (pred[:, 2,:] + pred[:, 3,:]) / 2
99	        pred = pred - pred_pelvis[:, None, :]
100	        error = torch.sqrt( ((pred - gt) ** 2).sum(dim=-1)).mean(dim=-1).cpu().numpy()
101	        return error
102	
103	def mean_per_vertex_error(pred, gt, has_smpl):
104	    &quot;&quot;&quot;
105	    Compute mPVE
106	    &quot;&quot;&quot;
107	    pred = pred[has_smpl == 1]
108	    gt = gt[has_smpl == 1]
109	    with torch.no_grad():
110	        error = torch.sqrt( ((pred - gt) ** 2).sum(dim=-1)).mean(dim=-1).cpu().numpy()
111	        return error
112	
113	def keypoint_2d_loss(criterion_keypoints, pred_keypoints_2d, gt_keypoints_2d, has_pose_2d):
114	    &quot;&quot;&quot;
115	    Compute 2D reprojection loss if 2D keypoint annotations are available.
116	    The confidence (conf) is binary and indicates whether the keypoints exist or not.
117	    &quot;&quot;&quot;
118	    conf = gt_keypoints_2d[:, :, -1].unsqueeze(-1).clone()
119	    loss = (conf * criterion_keypoints(pred_keypoints_2d, gt_keypoints_2d[:, :, :-1])).mean()
120	    return loss
121	
</pre>
</div>


</div>
</div>

<div id="issue-73">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py</a><br>
    <b>Line number: </b>60<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot;
2	Copyright (c) Microsoft Corporation.
3	Licensed under the MIT license.
4	
5	Training and evaluation codes for 
6	3D hand mesh reconstruction from an image
7	&quot;&quot;&quot;
8	
9	from __future__ import absolute_import, division, print_function
10	import argparse
11	import os
12	import os.path as op
13	import code
14	import json
15	import time
16	import datetime
17	import torch
18	import torchvision.models as models
19	from torchvision.utils import make_grid
20	import gc
21	import numpy as np
22	import cv2
23	from custom_mesh_graphormer.modeling.bert import BertConfig, Graphormer
24	from custom_mesh_graphormer.modeling.bert import Graphormer_Hand_Network as Graphormer_Network
25	from custom_mesh_graphormer.modeling._mano import MANO, Mesh
26	from custom_mesh_graphormer.modeling.hrnet.hrnet_cls_net_gridfeat import get_cls_net_gridfeat
27	from custom_mesh_graphormer.modeling.hrnet.config import config as hrnet_config
28	from custom_mesh_graphormer.modeling.hrnet.config import update_config as hrnet_update_config
29	import custom_mesh_graphormer.modeling.data.config as cfg
30	from custom_mesh_graphormer.datasets.build import make_hand_data_loader
31	
32	from custom_mesh_graphormer.utils.logger import setup_logger
33	from custom_mesh_graphormer.utils.comm import synchronize, is_main_process, get_rank, get_world_size, all_gather
34	from custom_mesh_graphormer.utils.miscellaneous import mkdir, set_seed
35	from custom_mesh_graphormer.utils.metric_logger import AverageMeter
36	from custom_mesh_graphormer.utils.renderer import Renderer, visualize_reconstruction, visualize_reconstruction_test, visualize_reconstruction_no_text
37	from custom_mesh_graphormer.utils.metric_pampjpe import reconstruction_error
38	from custom_mesh_graphormer.utils.geometric_layers import orthographic_projection
39	
40	from comfy.model_management import get_torch_device
41	device = get_torch_device()
42	
43	from azureml.core.run import Run
44	aml_run = Run.get_context()
45	
46	def save_checkpoint(model, args, epoch, iteration, num_trial=10):
47	    checkpoint_dir = op.join(args.output_dir, &#x27;checkpoint-{}-{}&#x27;.format(
48	        epoch, iteration))
49	    if not is_main_process():
50	        return checkpoint_dir
51	    mkdir(checkpoint_dir)
52	    model_to_save = model.module if hasattr(model, &#x27;module&#x27;) else model
53	    for i in range(num_trial):
54	        try:
55	            torch.save(model_to_save, op.join(checkpoint_dir, &#x27;model.bin&#x27;))
56	            torch.save(model_to_save.state_dict(), op.join(checkpoint_dir, &#x27;state_dict.bin&#x27;))
57	            torch.save(args, op.join(checkpoint_dir, &#x27;training_args.bin&#x27;))
58	            logger.info(&quot;Save checkpoint to {}&quot;.format(checkpoint_dir))
59	            break
60	        except:
61	            pass
62	    else:
63	        logger.info(&quot;Failed to save checkpoint after {} trails.&quot;.format(num_trial))
64	    return checkpoint_dir
65	
66	def adjust_learning_rate(optimizer, epoch, args):
67	    &quot;&quot;&quot;
68	    Sets the learning rate to the initial LR decayed by x every y epochs
69	    x = 0.1, y = args.num_train_epochs/2.0 = 100
70	    &quot;&quot;&quot;
71	    lr = args.lr * (0.1 ** (epoch // (args.num_train_epochs/2.0)  ))
72	    for param_group in optimizer.param_groups:
73	        param_group[&#x27;lr&#x27;] = lr
74	
75	def keypoint_2d_loss(criterion_keypoints, pred_keypoints_2d, gt_keypoints_2d, has_pose_2d):
76	    &quot;&quot;&quot;
77	    Compute 2D reprojection loss if 2D keypoint annotations are available.
78	    The confidence is binary and indicates whether the keypoints exist or not.
79	    &quot;&quot;&quot;
80	    conf = gt_keypoints_2d[:, :, -1].unsqueeze(-1).clone()
81	    loss = (conf * criterion_keypoints(pred_keypoints_2d, gt_keypoints_2d[:, :, :-1])).mean()
82	    return loss
83	
84	def keypoint_3d_loss(criterion_keypoints, pred_keypoints_3d, gt_keypoints_3d, has_pose_3d):
85	    &quot;&quot;&quot;
86	    Compute 3D keypoint loss if 3D keypoint annotations are available.
87	    &quot;&quot;&quot;
88	    conf = gt_keypoints_3d[:, :, -1].unsqueeze(-1).clone()
89	    gt_keypoints_3d = gt_keypoints_3d[:, :, :-1].clone()
90	    gt_keypoints_3d = gt_keypoints_3d[has_pose_3d == 1]
91	    conf = conf[has_pose_3d == 1]
92	    pred_keypoints_3d = pred_keypoints_3d[has_pose_3d == 1]
93	    if len(gt_keypoints_3d) &gt; 0:
94	        gt_root = gt_keypoints_3d[:, 0,:]
95	        gt_keypoints_3d = gt_keypoints_3d - gt_root[:, None, :]
96	        pred_root = pred_keypoints_3d[:, 0,:]
97	        pred_keypoints_3d = pred_keypoints_3d - pred_root[:, None, :]
98	        return (conf * criterion_keypoints(pred_keypoints_3d, gt_keypoints_3d)).mean()
99	    else:
100	        return torch.FloatTensor(1).fill_(0.).to(device)
101	
102	def vertices_loss(criterion_vertices, pred_vertices, gt_vertices, has_smpl):
103	    &quot;&quot;&quot;
104	    Compute per-vertex loss if vertex annotations are available.
105	    &quot;&quot;&quot;
106	    pred_vertices_with_shape = pred_vertices[has_smpl == 1]
107	    gt_vertices_with_shape = gt_vertices[has_smpl == 1]
108	    if len(gt_vertices_with_shape) &gt; 0:
109	        return criterion_vertices(pred_vertices_with_shape, gt_vertices_with_shape)
110	    else:
111	        return torch.FloatTensor(1).fill_(0.).to(device)
112	    
113	
114	def run(args, train_dataloader, Graphormer_model, mano_model, renderer, mesh_sampler):
115	
116	    max_iter = len(train_dataloader)
117	    iters_per_epoch = max_iter // args.num_train_epochs
118	
119	    optimizer = torch.optim.Adam(params=list(Graphormer_model.parameters()),
120	                                           lr=args.lr,
121	                                           betas=(0.9, 0.999),
</pre>
</div>


</div>
</div>

<div id="issue-74">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py</a><br>
    <b>Line number: </b>343<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
283	    Graphormer_model.eval()
284	
285	    if args.aml_eval==True:
286	        run_aml_inference_hand_mesh(args, val_dataloader, 
287	                                Graphormer_model, 
288	                                criterion_keypoints, 
289	                                criterion_vertices, 
290	                                0, 
291	                                mano_model, mesh_sampler,
292	                                renderer, split)
293	    else:
294	        run_inference_hand_mesh(args, val_dataloader, 
295	                                Graphormer_model, 
296	                                criterion_keypoints, 
297	                                criterion_vertices, 
298	                                0, 
299	                                mano_model, mesh_sampler,
300	                                renderer, split)
301	    checkpoint_dir = save_checkpoint(Graphormer_model, args, 0, 0)
302	    return
303	
304	def run_aml_inference_hand_mesh(args, val_loader, Graphormer_model, criterion, criterion_vertices, epoch, mano_model, mesh_sampler, renderer, split):
305	    # switch to evaluate mode
306	    Graphormer_model.eval()
307	    fname_output_save = []
308	    mesh_output_save = []
309	    joint_output_save = []
310	    world_size = get_world_size()
311	    with torch.no_grad():
312	        for i, (img_keys, images, annotations) in enumerate(val_loader):
313	            batch_size = images.size(0)
314	            # compute output
315	            images = images.to(device)
316	            
317	            # forward-pass
318	            pred_camera, pred_3d_joints, pred_vertices_sub, pred_vertices = Graphormer_model(images, mano_model, mesh_sampler)
319	            # obtain 3d joints from full mesh
320	            pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
321	
322	            for j in range(batch_size):
323	                fname_output_save.append(img_keys[j])
324	                pred_vertices_list = pred_vertices[j].tolist()
325	                mesh_output_save.append(pred_vertices_list)
326	                pred_3d_joints_from_mesh_list = pred_3d_joints_from_mesh[j].tolist()
327	                joint_output_save.append(pred_3d_joints_from_mesh_list)
328	
329	    if world_size &gt; 1:
330	        torch.distributed.barrier()
331	    print(&#x27;save results to pred.json&#x27;)
332	    output_json_file = &#x27;pred.json&#x27;
333	    print(&#x27;save results to &#x27;, output_json_file)
334	    with open(output_json_file, &#x27;w&#x27;) as f:
335	        json.dump([joint_output_save, mesh_output_save], f)
336	
337	    azure_ckpt_name = &#x27;200&#x27; # args.resume_checkpoint.split(&#x27;/&#x27;)[-2].split(&#x27;-&#x27;)[1]
338	    inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
339	    output_zip_file = args.output_dir + &#x27;ckpt&#x27; + azure_ckpt_name + &#x27;-&#x27; + inference_setting +&#x27;-pred.zip&#x27;
340	
341	    resolved_submit_cmd = &#x27;zip &#x27; + output_zip_file + &#x27; &#x27; + output_json_file
342	    print(resolved_submit_cmd)
343	    os.system(resolved_submit_cmd)
344	    resolved_submit_cmd = &#x27;rm %s&#x27;%(output_json_file)
345	    print(resolved_submit_cmd)
346	    os.system(resolved_submit_cmd)
347	    if world_size &gt; 1:
348	        torch.distributed.barrier()
349	
350	    return 
351	
352	def run_inference_hand_mesh(args, val_loader, Graphormer_model, criterion, criterion_vertices, epoch, mano_model, mesh_sampler, renderer, split):
353	    # switch to evaluate mode
354	    Graphormer_model.eval()
355	    fname_output_save = []
356	    mesh_output_save = []
357	    joint_output_save = []
358	    with torch.no_grad():
359	        for i, (img_keys, images, annotations) in enumerate(val_loader):
360	            batch_size = images.size(0)
361	            # compute output
362	            images = images.to(device)
363	
364	            # forward-pass
365	            pred_camera, pred_3d_joints, pred_vertices_sub, pred_vertices = Graphormer_model(images, mano_model, mesh_sampler)
366	
367	            # obtain 3d joints from full mesh
368	            pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
369	            pred_3d_pelvis = pred_3d_joints_from_mesh[:,cfg.J_NAME.index(&#x27;Wrist&#x27;),:]
370	            pred_3d_joints_from_mesh = pred_3d_joints_from_mesh - pred_3d_pelvis[:, None, :]
371	            pred_vertices = pred_vertices - pred_3d_pelvis[:, None, :]
372	
373	            for j in range(batch_size):
374	                fname_output_save.append(img_keys[j])
375	                pred_vertices_list = pred_vertices[j].tolist()
376	                mesh_output_save.append(pred_vertices_list)
377	                pred_3d_joints_from_mesh_list = pred_3d_joints_from_mesh[j].tolist()
378	                joint_output_save.append(pred_3d_joints_from_mesh_list)
379	
380	            if i%20==0:
381	                # obtain 3d joints, which are regressed from the full mesh
382	                pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
383	                # obtain 2d joints, which are projected from 3d joints of mesh
384	                pred_2d_joints_from_mesh = orthographic_projection(pred_3d_joints_from_mesh.contiguous(), pred_camera.contiguous())
385	                visual_imgs = visualize_mesh(   renderer,
386	                                                annotations[&#x27;ori_img&#x27;].detach(),
387	                                                annotations[&#x27;joints_2d&#x27;].detach(),
388	                                                pred_vertices.detach(), 
389	                                                pred_camera.detach(),
390	                                                pred_2d_joints_from_mesh.detach())
391	
392	                visual_imgs = visual_imgs.transpose(0,1)
393	                visual_imgs = visual_imgs.transpose(1,2)
394	                visual_imgs = np.asarray(visual_imgs)
395	                
396	                inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
397	                temp_fname = args.output_dir + args.resume_checkpoint[0:-9] + &#x27;freihand_results_&#x27;+inference_setting+&#x27;_batch&#x27;+str(i)+&#x27;.jpg&#x27;
398	                cv2.imwrite(temp_fname, np.asarray(visual_imgs[:,:,::-1]*255))
399	
400	    print(&#x27;save results to pred.json&#x27;)
401	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
402	        json.dump([joint_output_save, mesh_output_save], f)
</pre>
</div>


</div>
</div>

<div id="issue-75">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py</a><br>
    <b>Line number: </b>346<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
286	        run_aml_inference_hand_mesh(args, val_dataloader, 
287	                                Graphormer_model, 
288	                                criterion_keypoints, 
289	                                criterion_vertices, 
290	                                0, 
291	                                mano_model, mesh_sampler,
292	                                renderer, split)
293	    else:
294	        run_inference_hand_mesh(args, val_dataloader, 
295	                                Graphormer_model, 
296	                                criterion_keypoints, 
297	                                criterion_vertices, 
298	                                0, 
299	                                mano_model, mesh_sampler,
300	                                renderer, split)
301	    checkpoint_dir = save_checkpoint(Graphormer_model, args, 0, 0)
302	    return
303	
304	def run_aml_inference_hand_mesh(args, val_loader, Graphormer_model, criterion, criterion_vertices, epoch, mano_model, mesh_sampler, renderer, split):
305	    # switch to evaluate mode
306	    Graphormer_model.eval()
307	    fname_output_save = []
308	    mesh_output_save = []
309	    joint_output_save = []
310	    world_size = get_world_size()
311	    with torch.no_grad():
312	        for i, (img_keys, images, annotations) in enumerate(val_loader):
313	            batch_size = images.size(0)
314	            # compute output
315	            images = images.to(device)
316	            
317	            # forward-pass
318	            pred_camera, pred_3d_joints, pred_vertices_sub, pred_vertices = Graphormer_model(images, mano_model, mesh_sampler)
319	            # obtain 3d joints from full mesh
320	            pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
321	
322	            for j in range(batch_size):
323	                fname_output_save.append(img_keys[j])
324	                pred_vertices_list = pred_vertices[j].tolist()
325	                mesh_output_save.append(pred_vertices_list)
326	                pred_3d_joints_from_mesh_list = pred_3d_joints_from_mesh[j].tolist()
327	                joint_output_save.append(pred_3d_joints_from_mesh_list)
328	
329	    if world_size &gt; 1:
330	        torch.distributed.barrier()
331	    print(&#x27;save results to pred.json&#x27;)
332	    output_json_file = &#x27;pred.json&#x27;
333	    print(&#x27;save results to &#x27;, output_json_file)
334	    with open(output_json_file, &#x27;w&#x27;) as f:
335	        json.dump([joint_output_save, mesh_output_save], f)
336	
337	    azure_ckpt_name = &#x27;200&#x27; # args.resume_checkpoint.split(&#x27;/&#x27;)[-2].split(&#x27;-&#x27;)[1]
338	    inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
339	    output_zip_file = args.output_dir + &#x27;ckpt&#x27; + azure_ckpt_name + &#x27;-&#x27; + inference_setting +&#x27;-pred.zip&#x27;
340	
341	    resolved_submit_cmd = &#x27;zip &#x27; + output_zip_file + &#x27; &#x27; + output_json_file
342	    print(resolved_submit_cmd)
343	    os.system(resolved_submit_cmd)
344	    resolved_submit_cmd = &#x27;rm %s&#x27;%(output_json_file)
345	    print(resolved_submit_cmd)
346	    os.system(resolved_submit_cmd)
347	    if world_size &gt; 1:
348	        torch.distributed.barrier()
349	
350	    return 
351	
352	def run_inference_hand_mesh(args, val_loader, Graphormer_model, criterion, criterion_vertices, epoch, mano_model, mesh_sampler, renderer, split):
353	    # switch to evaluate mode
354	    Graphormer_model.eval()
355	    fname_output_save = []
356	    mesh_output_save = []
357	    joint_output_save = []
358	    with torch.no_grad():
359	        for i, (img_keys, images, annotations) in enumerate(val_loader):
360	            batch_size = images.size(0)
361	            # compute output
362	            images = images.to(device)
363	
364	            # forward-pass
365	            pred_camera, pred_3d_joints, pred_vertices_sub, pred_vertices = Graphormer_model(images, mano_model, mesh_sampler)
366	
367	            # obtain 3d joints from full mesh
368	            pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
369	            pred_3d_pelvis = pred_3d_joints_from_mesh[:,cfg.J_NAME.index(&#x27;Wrist&#x27;),:]
370	            pred_3d_joints_from_mesh = pred_3d_joints_from_mesh - pred_3d_pelvis[:, None, :]
371	            pred_vertices = pred_vertices - pred_3d_pelvis[:, None, :]
372	
373	            for j in range(batch_size):
374	                fname_output_save.append(img_keys[j])
375	                pred_vertices_list = pred_vertices[j].tolist()
376	                mesh_output_save.append(pred_vertices_list)
377	                pred_3d_joints_from_mesh_list = pred_3d_joints_from_mesh[j].tolist()
378	                joint_output_save.append(pred_3d_joints_from_mesh_list)
379	
380	            if i%20==0:
381	                # obtain 3d joints, which are regressed from the full mesh
382	                pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
383	                # obtain 2d joints, which are projected from 3d joints of mesh
384	                pred_2d_joints_from_mesh = orthographic_projection(pred_3d_joints_from_mesh.contiguous(), pred_camera.contiguous())
385	                visual_imgs = visualize_mesh(   renderer,
386	                                                annotations[&#x27;ori_img&#x27;].detach(),
387	                                                annotations[&#x27;joints_2d&#x27;].detach(),
388	                                                pred_vertices.detach(), 
389	                                                pred_camera.detach(),
390	                                                pred_2d_joints_from_mesh.detach())
391	
392	                visual_imgs = visual_imgs.transpose(0,1)
393	                visual_imgs = visual_imgs.transpose(1,2)
394	                visual_imgs = np.asarray(visual_imgs)
395	                
396	                inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
397	                temp_fname = args.output_dir + args.resume_checkpoint[0:-9] + &#x27;freihand_results_&#x27;+inference_setting+&#x27;_batch&#x27;+str(i)+&#x27;.jpg&#x27;
398	                cv2.imwrite(temp_fname, np.asarray(visual_imgs[:,:,::-1]*255))
399	
400	    print(&#x27;save results to pred.json&#x27;)
401	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
402	        json.dump([joint_output_save, mesh_output_save], f)
403	
404	    run_exp_name = args.resume_checkpoint.split(&#x27;/&#x27;)[-3]
405	    run_ckpt_name = args.resume_checkpoint.split(&#x27;/&#x27;)[-2].split(&#x27;-&#x27;)[1]
</pre>
</div>


</div>
</div>

<div id="issue-76">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py</a><br>
    <b>Line number: </b>409<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
349	
350	    return 
351	
352	def run_inference_hand_mesh(args, val_loader, Graphormer_model, criterion, criterion_vertices, epoch, mano_model, mesh_sampler, renderer, split):
353	    # switch to evaluate mode
354	    Graphormer_model.eval()
355	    fname_output_save = []
356	    mesh_output_save = []
357	    joint_output_save = []
358	    with torch.no_grad():
359	        for i, (img_keys, images, annotations) in enumerate(val_loader):
360	            batch_size = images.size(0)
361	            # compute output
362	            images = images.to(device)
363	
364	            # forward-pass
365	            pred_camera, pred_3d_joints, pred_vertices_sub, pred_vertices = Graphormer_model(images, mano_model, mesh_sampler)
366	
367	            # obtain 3d joints from full mesh
368	            pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
369	            pred_3d_pelvis = pred_3d_joints_from_mesh[:,cfg.J_NAME.index(&#x27;Wrist&#x27;),:]
370	            pred_3d_joints_from_mesh = pred_3d_joints_from_mesh - pred_3d_pelvis[:, None, :]
371	            pred_vertices = pred_vertices - pred_3d_pelvis[:, None, :]
372	
373	            for j in range(batch_size):
374	                fname_output_save.append(img_keys[j])
375	                pred_vertices_list = pred_vertices[j].tolist()
376	                mesh_output_save.append(pred_vertices_list)
377	                pred_3d_joints_from_mesh_list = pred_3d_joints_from_mesh[j].tolist()
378	                joint_output_save.append(pred_3d_joints_from_mesh_list)
379	
380	            if i%20==0:
381	                # obtain 3d joints, which are regressed from the full mesh
382	                pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
383	                # obtain 2d joints, which are projected from 3d joints of mesh
384	                pred_2d_joints_from_mesh = orthographic_projection(pred_3d_joints_from_mesh.contiguous(), pred_camera.contiguous())
385	                visual_imgs = visualize_mesh(   renderer,
386	                                                annotations[&#x27;ori_img&#x27;].detach(),
387	                                                annotations[&#x27;joints_2d&#x27;].detach(),
388	                                                pred_vertices.detach(), 
389	                                                pred_camera.detach(),
390	                                                pred_2d_joints_from_mesh.detach())
391	
392	                visual_imgs = visual_imgs.transpose(0,1)
393	                visual_imgs = visual_imgs.transpose(1,2)
394	                visual_imgs = np.asarray(visual_imgs)
395	                
396	                inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
397	                temp_fname = args.output_dir + args.resume_checkpoint[0:-9] + &#x27;freihand_results_&#x27;+inference_setting+&#x27;_batch&#x27;+str(i)+&#x27;.jpg&#x27;
398	                cv2.imwrite(temp_fname, np.asarray(visual_imgs[:,:,::-1]*255))
399	
400	    print(&#x27;save results to pred.json&#x27;)
401	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
402	        json.dump([joint_output_save, mesh_output_save], f)
403	
404	    run_exp_name = args.resume_checkpoint.split(&#x27;/&#x27;)[-3]
405	    run_ckpt_name = args.resume_checkpoint.split(&#x27;/&#x27;)[-2].split(&#x27;-&#x27;)[1]
406	    inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
407	    resolved_submit_cmd = &#x27;zip &#x27; + args.output_dir + run_exp_name + &#x27;-ckpt&#x27;+ run_ckpt_name + &#x27;-&#x27; + inference_setting +&#x27;-pred.zip  &#x27; +  &#x27;pred.json&#x27;
408	    print(resolved_submit_cmd)
409	    os.system(resolved_submit_cmd)
410	    resolved_submit_cmd = &#x27;rm pred.json&#x27;
411	    print(resolved_submit_cmd)
412	    os.system(resolved_submit_cmd)
413	    return 
414	
415	def visualize_mesh( renderer,
416	                    images,
417	                    gt_keypoints_2d,
418	                    pred_vertices, 
419	                    pred_camera,
420	                    pred_keypoints_2d):
421	    &quot;&quot;&quot;Tensorboard logging.&quot;&quot;&quot;
422	    gt_keypoints_2d = gt_keypoints_2d.cpu().numpy()
423	    to_lsp = list(range(21))
424	    rend_imgs = []
425	    batch_size = pred_vertices.shape[0]
426	    # Do visualization for the first 6 images of the batch
427	    for i in range(min(batch_size, 10)):
428	        img = images[i].cpu().numpy().transpose(1,2,0)
429	        # Get LSP keypoints from the full list of keypoints
430	        gt_keypoints_2d_ = gt_keypoints_2d[i, to_lsp]
431	        pred_keypoints_2d_ = pred_keypoints_2d.cpu().numpy()[i, to_lsp]
432	        # Get predict vertices for the particular example
433	        vertices = pred_vertices[i].cpu().numpy()
434	        cam = pred_camera[i].cpu().numpy()
435	        # Visualize reconstruction and detected pose
436	        rend_img = visualize_reconstruction(img, 224, gt_keypoints_2d_, vertices, pred_keypoints_2d_, cam, renderer)
437	        rend_img = rend_img.transpose(2,0,1)
438	        rend_imgs.append(torch.from_numpy(rend_img))   
439	    rend_imgs = make_grid(rend_imgs, nrow=1)
440	    return rend_imgs
441	
442	def visualize_mesh_test( renderer,
443	                    images,
444	                    gt_keypoints_2d,
445	                    pred_vertices, 
446	                    pred_camera,
447	                    pred_keypoints_2d,
448	                    PAmPJPE):
449	    &quot;&quot;&quot;Tensorboard logging.&quot;&quot;&quot;
450	    gt_keypoints_2d = gt_keypoints_2d.cpu().numpy()
451	    to_lsp = list(range(21))
452	    rend_imgs = []
453	    batch_size = pred_vertices.shape[0]
454	    # Do visualization for the first 6 images of the batch
455	    for i in range(min(batch_size, 10)):
456	        img = images[i].cpu().numpy().transpose(1,2,0)
457	        # Get LSP keypoints from the full list of keypoints
458	        gt_keypoints_2d_ = gt_keypoints_2d[i, to_lsp]
459	        pred_keypoints_2d_ = pred_keypoints_2d.cpu().numpy()[i, to_lsp]
460	        # Get predict vertices for the particular example
461	        vertices = pred_vertices[i].cpu().numpy()
462	        cam = pred_camera[i].cpu().numpy()
463	        score = PAmPJPE[i]
464	        # Visualize reconstruction and detected pose
465	        rend_img = visualize_reconstruction_test(img, 224, gt_keypoints_2d_, vertices, pred_keypoints_2d_, cam, renderer, score)
466	        rend_img = rend_img.transpose(2,0,1)
467	        rend_imgs.append(torch.from_numpy(rend_img))   
468	    rend_imgs = make_grid(rend_imgs, nrow=1)
</pre>
</div>


</div>
</div>

<div id="issue-77">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_gphmer_handmesh.py</a><br>
    <b>Line number: </b>412<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
352	def run_inference_hand_mesh(args, val_loader, Graphormer_model, criterion, criterion_vertices, epoch, mano_model, mesh_sampler, renderer, split):
353	    # switch to evaluate mode
354	    Graphormer_model.eval()
355	    fname_output_save = []
356	    mesh_output_save = []
357	    joint_output_save = []
358	    with torch.no_grad():
359	        for i, (img_keys, images, annotations) in enumerate(val_loader):
360	            batch_size = images.size(0)
361	            # compute output
362	            images = images.to(device)
363	
364	            # forward-pass
365	            pred_camera, pred_3d_joints, pred_vertices_sub, pred_vertices = Graphormer_model(images, mano_model, mesh_sampler)
366	
367	            # obtain 3d joints from full mesh
368	            pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
369	            pred_3d_pelvis = pred_3d_joints_from_mesh[:,cfg.J_NAME.index(&#x27;Wrist&#x27;),:]
370	            pred_3d_joints_from_mesh = pred_3d_joints_from_mesh - pred_3d_pelvis[:, None, :]
371	            pred_vertices = pred_vertices - pred_3d_pelvis[:, None, :]
372	
373	            for j in range(batch_size):
374	                fname_output_save.append(img_keys[j])
375	                pred_vertices_list = pred_vertices[j].tolist()
376	                mesh_output_save.append(pred_vertices_list)
377	                pred_3d_joints_from_mesh_list = pred_3d_joints_from_mesh[j].tolist()
378	                joint_output_save.append(pred_3d_joints_from_mesh_list)
379	
380	            if i%20==0:
381	                # obtain 3d joints, which are regressed from the full mesh
382	                pred_3d_joints_from_mesh = mano_model.get_3d_joints(pred_vertices)
383	                # obtain 2d joints, which are projected from 3d joints of mesh
384	                pred_2d_joints_from_mesh = orthographic_projection(pred_3d_joints_from_mesh.contiguous(), pred_camera.contiguous())
385	                visual_imgs = visualize_mesh(   renderer,
386	                                                annotations[&#x27;ori_img&#x27;].detach(),
387	                                                annotations[&#x27;joints_2d&#x27;].detach(),
388	                                                pred_vertices.detach(), 
389	                                                pred_camera.detach(),
390	                                                pred_2d_joints_from_mesh.detach())
391	
392	                visual_imgs = visual_imgs.transpose(0,1)
393	                visual_imgs = visual_imgs.transpose(1,2)
394	                visual_imgs = np.asarray(visual_imgs)
395	                
396	                inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
397	                temp_fname = args.output_dir + args.resume_checkpoint[0:-9] + &#x27;freihand_results_&#x27;+inference_setting+&#x27;_batch&#x27;+str(i)+&#x27;.jpg&#x27;
398	                cv2.imwrite(temp_fname, np.asarray(visual_imgs[:,:,::-1]*255))
399	
400	    print(&#x27;save results to pred.json&#x27;)
401	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
402	        json.dump([joint_output_save, mesh_output_save], f)
403	
404	    run_exp_name = args.resume_checkpoint.split(&#x27;/&#x27;)[-3]
405	    run_ckpt_name = args.resume_checkpoint.split(&#x27;/&#x27;)[-2].split(&#x27;-&#x27;)[1]
406	    inference_setting = &#x27;sc%02d_rot%s&#x27;%(int(args.sc*10),str(int(args.rot)))
407	    resolved_submit_cmd = &#x27;zip &#x27; + args.output_dir + run_exp_name + &#x27;-ckpt&#x27;+ run_ckpt_name + &#x27;-&#x27; + inference_setting +&#x27;-pred.zip  &#x27; +  &#x27;pred.json&#x27;
408	    print(resolved_submit_cmd)
409	    os.system(resolved_submit_cmd)
410	    resolved_submit_cmd = &#x27;rm pred.json&#x27;
411	    print(resolved_submit_cmd)
412	    os.system(resolved_submit_cmd)
413	    return 
414	
415	def visualize_mesh( renderer,
416	                    images,
417	                    gt_keypoints_2d,
418	                    pred_vertices, 
419	                    pred_camera,
420	                    pred_keypoints_2d):
421	    &quot;&quot;&quot;Tensorboard logging.&quot;&quot;&quot;
422	    gt_keypoints_2d = gt_keypoints_2d.cpu().numpy()
423	    to_lsp = list(range(21))
424	    rend_imgs = []
425	    batch_size = pred_vertices.shape[0]
426	    # Do visualization for the first 6 images of the batch
427	    for i in range(min(batch_size, 10)):
428	        img = images[i].cpu().numpy().transpose(1,2,0)
429	        # Get LSP keypoints from the full list of keypoints
430	        gt_keypoints_2d_ = gt_keypoints_2d[i, to_lsp]
431	        pred_keypoints_2d_ = pred_keypoints_2d.cpu().numpy()[i, to_lsp]
432	        # Get predict vertices for the particular example
433	        vertices = pred_vertices[i].cpu().numpy()
434	        cam = pred_camera[i].cpu().numpy()
435	        # Visualize reconstruction and detected pose
436	        rend_img = visualize_reconstruction(img, 224, gt_keypoints_2d_, vertices, pred_keypoints_2d_, cam, renderer)
437	        rend_img = rend_img.transpose(2,0,1)
438	        rend_imgs.append(torch.from_numpy(rend_img))   
439	    rend_imgs = make_grid(rend_imgs, nrow=1)
440	    return rend_imgs
441	
442	def visualize_mesh_test( renderer,
443	                    images,
444	                    gt_keypoints_2d,
445	                    pred_vertices, 
446	                    pred_camera,
447	                    pred_keypoints_2d,
448	                    PAmPJPE):
449	    &quot;&quot;&quot;Tensorboard logging.&quot;&quot;&quot;
450	    gt_keypoints_2d = gt_keypoints_2d.cpu().numpy()
451	    to_lsp = list(range(21))
452	    rend_imgs = []
453	    batch_size = pred_vertices.shape[0]
454	    # Do visualization for the first 6 images of the batch
455	    for i in range(min(batch_size, 10)):
456	        img = images[i].cpu().numpy().transpose(1,2,0)
457	        # Get LSP keypoints from the full list of keypoints
458	        gt_keypoints_2d_ = gt_keypoints_2d[i, to_lsp]
459	        pred_keypoints_2d_ = pred_keypoints_2d.cpu().numpy()[i, to_lsp]
460	        # Get predict vertices for the particular example
461	        vertices = pred_vertices[i].cpu().numpy()
462	        cam = pred_camera[i].cpu().numpy()
463	        score = PAmPJPE[i]
464	        # Visualize reconstruction and detected pose
465	        rend_img = visualize_reconstruction_test(img, 224, gt_keypoints_2d_, vertices, pred_keypoints_2d_, cam, renderer, score)
466	        rend_img = rend_img.transpose(2,0,1)
467	        rend_imgs.append(torch.from_numpy(rend_img))   
468	    rend_imgs = make_grid(rend_imgs, nrow=1)
469	    return rend_imgs
470	
471	def visualize_mesh_no_text( renderer,
</pre>
</div>


</div>
</div>

<div id="issue-78">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_hand_multiscale.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_hand_multiscale.py</a><br>
    <b>Line number: </b>82<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
22	    s = &#x27;10&#x27;
23	    filepath = output_dir+&#x27;ckpt200-sc10_rot0-pred.zip&#x27;
24	    ref_joints, ref_vertices = load_pred_json(filepath)
25	    ref_joints_array = np.asarray(ref_joints)
26	    ref_vertices_array = np.asarray(ref_vertices)
27	
28	    rotations = [0.0]
29	    for i in range(1,10):
30	        rotations.append(i*10)
31	        rotations.append(i*-10)
32	    
33	    scale = [0.7,0.8,0.9,1.0,1.1]
34	    multiscale_joints = []
35	    multiscale_vertices = []
36	
37	    counter = 0
38	    for s in scale:
39	        for r in rotations:
40	            setting = &#x27;sc%02d_rot%s&#x27;%(int(s*10),str(int(r)))
41	            filepath = output_dir+&#x27;ckpt200-&#x27;+setting+&#x27;-pred.zip&#x27;
42	            joints, vertices = load_pred_json(filepath)
43	            joints_array = np.asarray(joints)
44	            vertices_array = np.asarray(vertices)
45	
46	            pa_joint_error, pa_joint_array, _ = get_alignMesh(joints_array, ref_joints_array, reduction=None)
47	            pa_vertices_error, pa_vertices_array, _ = get_alignMesh(vertices_array, ref_vertices_array, reduction=None)
48	            print(&#x27;--------------------------&#x27;)
49	            print(&#x27;scale:&#x27;, s, &#x27;rotate&#x27;, r)
50	            print(&#x27;PAMPJPE:&#x27;, 1000*np.mean(pa_joint_error))
51	            print(&#x27;PAMPVPE:&#x27;, 1000*np.mean(pa_vertices_error))
52	            multiscale_joints.append(pa_joint_array)
53	            multiscale_vertices.append(pa_vertices_array)
54	            counter = counter + 1
55	
56	    overall_joints_array = ref_joints_array.copy()
57	    overall_vertices_array = ref_vertices_array.copy()
58	    for i in range(counter):
59	        overall_joints_array += multiscale_joints[i]
60	        overall_vertices_array += multiscale_vertices[i]
61	
62	    overall_joints_array /= (1+counter)
63	    overall_vertices_array /= (1+counter)
64	    pa_joint_error, pa_joint_array, _ = get_alignMesh(overall_joints_array, ref_joints_array, reduction=None)
65	    pa_vertices_error, pa_vertices_array, _ = get_alignMesh(overall_vertices_array, ref_vertices_array, reduction=None)
66	    print(&#x27;--------------------------&#x27;)
67	    print(&#x27;overall:&#x27;)
68	    print(&#x27;PAMPJPE:&#x27;, 1000*np.mean(pa_joint_error))
69	    print(&#x27;PAMPVPE:&#x27;, 1000*np.mean(pa_vertices_error))
70	
71	    joint_output_save = overall_joints_array.tolist()
72	    mesh_output_save = overall_vertices_array.tolist()
73	
74	    print(&#x27;save results to pred.json&#x27;)
75	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
76	        json.dump([joint_output_save, mesh_output_save], f)
77	
78	
79	    filepath = output_dir+&#x27;ckpt200-multisc-pred.zip&#x27;
80	    resolved_submit_cmd = &#x27;zip &#x27; + filepath + &#x27;  &#x27; +  &#x27;pred.json&#x27;
81	    print(resolved_submit_cmd)
82	    os.system(resolved_submit_cmd)
83	    resolved_submit_cmd = &#x27;rm pred.json&#x27;
84	    print(resolved_submit_cmd)
85	    os.system(resolved_submit_cmd)
86	
87	
88	def run_multiscale_inference(model_path, mode, output_dir):
89	    
90	    if mode==True:
91	        rotations = [0.0]
92	        for i in range(1,10):
93	            rotations.append(i*10)
94	            rotations.append(i*-10)
95	        scale = [0.7,0.8,0.9,1.0,1.1]
96	    else:
97	        rotations = [0.0]
98	        scale = [1.0] 
99	
100	    job_cmd = &quot;python ./src/tools/run_gphmer_handmesh.py &quot; \
101	            &quot;--val_yaml freihand_v3/test.yaml &quot; \
102	            &quot;--resume_checkpoint %s &quot; \
103	            &quot;--per_gpu_eval_batch_size 32 --run_eval_only --num_worker 2 &quot; \
104	            &quot;--multiscale_inference &quot; \
105	            &quot;--rot %f &quot; \
106	            &quot;--sc %s &quot; \
107	            &quot;--arch hrnet-w64 &quot; \
108	            &quot;--num_hidden_layers 4 &quot; \
109	            &quot;--num_attention_heads 4 &quot; \
110	            &quot;--input_feat_dim 2051,512,128 &quot; \
111	            &quot;--hidden_feat_dim 1024,256,64 &quot; \
112	            &quot;--output_dir %s&quot;
113	
114	    for s in scale:
115	        for r in rotations:
116	            resolved_submit_cmd = job_cmd%(model_path, r, s, output_dir)
117	            print(resolved_submit_cmd)
118	            os.system(resolved_submit_cmd)
119	
120	def main(args):
121	    model_path = args.model_path
122	    mode = args.multiscale_inference
123	    output_dir = args.output_dir
124	    run_multiscale_inference(model_path, mode, output_dir)
125	    if mode==True:
126	        multiscale_fusion(output_dir)
127	
128	
129	if __name__ == &quot;__main__&quot;:
130	    parser = argparse.ArgumentParser(description=&quot;Evaluate a checkpoint in the folder&quot;)
131	    parser.add_argument(&quot;--model_path&quot;)
132	    parser.add_argument(&quot;--multiscale_inference&quot;, default=False, action=&#x27;store_true&#x27;,) 
133	    parser.add_argument(&quot;--output_dir&quot;, default=&#x27;output/&#x27;, type=str, required=False,
134	                        help=&quot;The output directory to save checkpoint and test results.&quot;)
135	    args = parser.parse_args()
136	    main(args)
</pre>
</div>


</div>
</div>

<div id="issue-79">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_hand_multiscale.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_hand_multiscale.py</a><br>
    <b>Line number: </b>85<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
25	    ref_joints_array = np.asarray(ref_joints)
26	    ref_vertices_array = np.asarray(ref_vertices)
27	
28	    rotations = [0.0]
29	    for i in range(1,10):
30	        rotations.append(i*10)
31	        rotations.append(i*-10)
32	    
33	    scale = [0.7,0.8,0.9,1.0,1.1]
34	    multiscale_joints = []
35	    multiscale_vertices = []
36	
37	    counter = 0
38	    for s in scale:
39	        for r in rotations:
40	            setting = &#x27;sc%02d_rot%s&#x27;%(int(s*10),str(int(r)))
41	            filepath = output_dir+&#x27;ckpt200-&#x27;+setting+&#x27;-pred.zip&#x27;
42	            joints, vertices = load_pred_json(filepath)
43	            joints_array = np.asarray(joints)
44	            vertices_array = np.asarray(vertices)
45	
46	            pa_joint_error, pa_joint_array, _ = get_alignMesh(joints_array, ref_joints_array, reduction=None)
47	            pa_vertices_error, pa_vertices_array, _ = get_alignMesh(vertices_array, ref_vertices_array, reduction=None)
48	            print(&#x27;--------------------------&#x27;)
49	            print(&#x27;scale:&#x27;, s, &#x27;rotate&#x27;, r)
50	            print(&#x27;PAMPJPE:&#x27;, 1000*np.mean(pa_joint_error))
51	            print(&#x27;PAMPVPE:&#x27;, 1000*np.mean(pa_vertices_error))
52	            multiscale_joints.append(pa_joint_array)
53	            multiscale_vertices.append(pa_vertices_array)
54	            counter = counter + 1
55	
56	    overall_joints_array = ref_joints_array.copy()
57	    overall_vertices_array = ref_vertices_array.copy()
58	    for i in range(counter):
59	        overall_joints_array += multiscale_joints[i]
60	        overall_vertices_array += multiscale_vertices[i]
61	
62	    overall_joints_array /= (1+counter)
63	    overall_vertices_array /= (1+counter)
64	    pa_joint_error, pa_joint_array, _ = get_alignMesh(overall_joints_array, ref_joints_array, reduction=None)
65	    pa_vertices_error, pa_vertices_array, _ = get_alignMesh(overall_vertices_array, ref_vertices_array, reduction=None)
66	    print(&#x27;--------------------------&#x27;)
67	    print(&#x27;overall:&#x27;)
68	    print(&#x27;PAMPJPE:&#x27;, 1000*np.mean(pa_joint_error))
69	    print(&#x27;PAMPVPE:&#x27;, 1000*np.mean(pa_vertices_error))
70	
71	    joint_output_save = overall_joints_array.tolist()
72	    mesh_output_save = overall_vertices_array.tolist()
73	
74	    print(&#x27;save results to pred.json&#x27;)
75	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
76	        json.dump([joint_output_save, mesh_output_save], f)
77	
78	
79	    filepath = output_dir+&#x27;ckpt200-multisc-pred.zip&#x27;
80	    resolved_submit_cmd = &#x27;zip &#x27; + filepath + &#x27;  &#x27; +  &#x27;pred.json&#x27;
81	    print(resolved_submit_cmd)
82	    os.system(resolved_submit_cmd)
83	    resolved_submit_cmd = &#x27;rm pred.json&#x27;
84	    print(resolved_submit_cmd)
85	    os.system(resolved_submit_cmd)
86	
87	
88	def run_multiscale_inference(model_path, mode, output_dir):
89	    
90	    if mode==True:
91	        rotations = [0.0]
92	        for i in range(1,10):
93	            rotations.append(i*10)
94	            rotations.append(i*-10)
95	        scale = [0.7,0.8,0.9,1.0,1.1]
96	    else:
97	        rotations = [0.0]
98	        scale = [1.0] 
99	
100	    job_cmd = &quot;python ./src/tools/run_gphmer_handmesh.py &quot; \
101	            &quot;--val_yaml freihand_v3/test.yaml &quot; \
102	            &quot;--resume_checkpoint %s &quot; \
103	            &quot;--per_gpu_eval_batch_size 32 --run_eval_only --num_worker 2 &quot; \
104	            &quot;--multiscale_inference &quot; \
105	            &quot;--rot %f &quot; \
106	            &quot;--sc %s &quot; \
107	            &quot;--arch hrnet-w64 &quot; \
108	            &quot;--num_hidden_layers 4 &quot; \
109	            &quot;--num_attention_heads 4 &quot; \
110	            &quot;--input_feat_dim 2051,512,128 &quot; \
111	            &quot;--hidden_feat_dim 1024,256,64 &quot; \
112	            &quot;--output_dir %s&quot;
113	
114	    for s in scale:
115	        for r in rotations:
116	            resolved_submit_cmd = job_cmd%(model_path, r, s, output_dir)
117	            print(resolved_submit_cmd)
118	            os.system(resolved_submit_cmd)
119	
120	def main(args):
121	    model_path = args.model_path
122	    mode = args.multiscale_inference
123	    output_dir = args.output_dir
124	    run_multiscale_inference(model_path, mode, output_dir)
125	    if mode==True:
126	        multiscale_fusion(output_dir)
127	
128	
129	if __name__ == &quot;__main__&quot;:
130	    parser = argparse.ArgumentParser(description=&quot;Evaluate a checkpoint in the folder&quot;)
131	    parser.add_argument(&quot;--model_path&quot;)
132	    parser.add_argument(&quot;--multiscale_inference&quot;, default=False, action=&#x27;store_true&#x27;,) 
133	    parser.add_argument(&quot;--output_dir&quot;, default=&#x27;output/&#x27;, type=str, required=False,
134	                        help=&quot;The output directory to save checkpoint and test results.&quot;)
135	    args = parser.parse_args()
136	    main(args)
</pre>
</div>


</div>
</div>

<div id="issue-80">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_hand_multiscale.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/tools/run_hand_multiscale.py</a><br>
    <b>Line number: </b>118<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
58	    for i in range(counter):
59	        overall_joints_array += multiscale_joints[i]
60	        overall_vertices_array += multiscale_vertices[i]
61	
62	    overall_joints_array /= (1+counter)
63	    overall_vertices_array /= (1+counter)
64	    pa_joint_error, pa_joint_array, _ = get_alignMesh(overall_joints_array, ref_joints_array, reduction=None)
65	    pa_vertices_error, pa_vertices_array, _ = get_alignMesh(overall_vertices_array, ref_vertices_array, reduction=None)
66	    print(&#x27;--------------------------&#x27;)
67	    print(&#x27;overall:&#x27;)
68	    print(&#x27;PAMPJPE:&#x27;, 1000*np.mean(pa_joint_error))
69	    print(&#x27;PAMPVPE:&#x27;, 1000*np.mean(pa_vertices_error))
70	
71	    joint_output_save = overall_joints_array.tolist()
72	    mesh_output_save = overall_vertices_array.tolist()
73	
74	    print(&#x27;save results to pred.json&#x27;)
75	    with open(&#x27;pred.json&#x27;, &#x27;w&#x27;) as f:
76	        json.dump([joint_output_save, mesh_output_save], f)
77	
78	
79	    filepath = output_dir+&#x27;ckpt200-multisc-pred.zip&#x27;
80	    resolved_submit_cmd = &#x27;zip &#x27; + filepath + &#x27;  &#x27; +  &#x27;pred.json&#x27;
81	    print(resolved_submit_cmd)
82	    os.system(resolved_submit_cmd)
83	    resolved_submit_cmd = &#x27;rm pred.json&#x27;
84	    print(resolved_submit_cmd)
85	    os.system(resolved_submit_cmd)
86	
87	
88	def run_multiscale_inference(model_path, mode, output_dir):
89	    
90	    if mode==True:
91	        rotations = [0.0]
92	        for i in range(1,10):
93	            rotations.append(i*10)
94	            rotations.append(i*-10)
95	        scale = [0.7,0.8,0.9,1.0,1.1]
96	    else:
97	        rotations = [0.0]
98	        scale = [1.0] 
99	
100	    job_cmd = &quot;python ./src/tools/run_gphmer_handmesh.py &quot; \
101	            &quot;--val_yaml freihand_v3/test.yaml &quot; \
102	            &quot;--resume_checkpoint %s &quot; \
103	            &quot;--per_gpu_eval_batch_size 32 --run_eval_only --num_worker 2 &quot; \
104	            &quot;--multiscale_inference &quot; \
105	            &quot;--rot %f &quot; \
106	            &quot;--sc %s &quot; \
107	            &quot;--arch hrnet-w64 &quot; \
108	            &quot;--num_hidden_layers 4 &quot; \
109	            &quot;--num_attention_heads 4 &quot; \
110	            &quot;--input_feat_dim 2051,512,128 &quot; \
111	            &quot;--hidden_feat_dim 1024,256,64 &quot; \
112	            &quot;--output_dir %s&quot;
113	
114	    for s in scale:
115	        for r in rotations:
116	            resolved_submit_cmd = job_cmd%(model_path, r, s, output_dir)
117	            print(resolved_submit_cmd)
118	            os.system(resolved_submit_cmd)
119	
120	def main(args):
121	    model_path = args.model_path
122	    mode = args.multiscale_inference
123	    output_dir = args.output_dir
124	    run_multiscale_inference(model_path, mode, output_dir)
125	    if mode==True:
126	        multiscale_fusion(output_dir)
127	
128	
129	if __name__ == &quot;__main__&quot;:
130	    parser = argparse.ArgumentParser(description=&quot;Evaluate a checkpoint in the folder&quot;)
131	    parser.add_argument(&quot;--model_path&quot;)
132	    parser.add_argument(&quot;--multiscale_inference&quot;, default=False, action=&#x27;store_true&#x27;,) 
133	    parser.add_argument(&quot;--output_dir&quot;, default=&#x27;output/&#x27;, type=str, required=False,
134	                        help=&quot;The output directory to save checkpoint and test results.&quot;)
135	    args = parser.parse_args()
136	    main(args)
</pre>
</div>


</div>
</div>

<div id="issue-81">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/comm.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/comm.py</a><br>
    <b>Line number: </b>9<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot;
2	Copyright (c) Microsoft Corporation.
3	Licensed under the MIT license.
4	
5	This file contains primitives for multi-gpu communication.
6	This is useful when doing distributed training.
7	&quot;&quot;&quot;
8	
9	import pickle
10	import time
11	
12	import torch
13	import torch.distributed as dist
14	
15	from comfy.model_management import get_torch_device
16	device = get_torch_device()
17	
18	
19	def get_world_size():
20	    if not dist.is_available():
21	        return 1
22	    if not dist.is_initialized():
23	        return 1
24	    return dist.get_world_size()
25	
26	
27	def get_rank():
28	    if not dist.is_available():
29	        return 0
30	    if not dist.is_initialized():
31	        return 0
32	    return dist.get_rank()
33	
34	
35	def is_main_process():
36	    return get_rank() == 0
37	
38	
39	def synchronize():
40	    &quot;&quot;&quot;
41	    Helper function to synchronize (barrier) among all processes when
42	    using distributed training
43	    &quot;&quot;&quot;
44	    if not dist.is_available():
45	        return
46	    if not dist.is_initialized():
47	        return
48	    world_size = dist.get_world_size()
49	    if world_size == 1:
50	        return
51	    dist.barrier()
52	
53	
54	def gather_on_master(data):
55	    &quot;&quot;&quot;Same as all_gather, but gathers data on master process only, using CPU.
56	    Thus, this does not work with NCCL backend unless they add CPU support.
57	
58	    The memory consumption of this function is ~ 3x of data size. While in
59	    principal, it should be ~2x, it&#x27;s not easy to force Python to release
60	    memory immediately and thus, peak memory usage could be up to 3x.
61	    &quot;&quot;&quot;
62	    world_size = get_world_size()
63	    if world_size == 1:
64	        return [data]
65	
66	    # serialized to a Tensor
67	    buffer = pickle.dumps(data)
68	    # trying to optimize memory, but in fact, it&#x27;s not guaranteed to be released
69	    del data
70	    storage = torch.ByteStorage.from_buffer(buffer)
71	    del buffer
72	    tensor = torch.ByteTensor(storage)
73	
74	    # obtain Tensor size of each rank
75	    local_size = torch.LongTensor([tensor.numel()])
76	    size_list = [torch.LongTensor([0]) for _ in range(world_size)]
77	    dist.all_gather(size_list, local_size)
78	    size_list = [int(size.item()) for size in size_list]
79	    max_size = max(size_list)
80	
81	    if local_size != max_size:
82	        padding = torch.ByteTensor(size=(max_size - local_size,))
83	        tensor = torch.cat((tensor, padding), dim=0)
84	        del padding
85	
86	    if is_main_process():
87	        tensor_list = []
88	        for _ in size_list:
89	            tensor_list.append(torch.ByteTensor(size=(max_size,)))
90	        dist.gather(tensor, gather_list=tensor_list, dst=0)
91	        del tensor
92	    else:
93	        dist.gather(tensor, gather_list=[], dst=0)
94	        del tensor
95	        return
96	
97	    data_list = []
98	    for tensor in tensor_list:
99	        buffer = tensor.cpu().numpy().tobytes()
100	        del tensor
101	        data_list.append(pickle.loads(buffer))
102	        del buffer
103	
104	    return data_list
105	
106	
107	def all_gather(data):
108	    &quot;&quot;&quot;
109	    Run all_gather on arbitrary picklable data (not necessarily tensors)
110	    Args:
111	        data: any picklable object
112	    Returns:
113	        list[data]: list of data gathered from each rank
114	    &quot;&quot;&quot;
115	    world_size = get_world_size()
116	    if world_size == 1:
117	        return [data]
118	
119	    # serialized to a Tensor
120	    buffer = pickle.dumps(data)
</pre>
</div>


</div>
</div>

<div id="issue-82">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/comm.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/comm.py</a><br>
    <b>Line number: </b>101<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
41	    Helper function to synchronize (barrier) among all processes when
42	    using distributed training
43	    &quot;&quot;&quot;
44	    if not dist.is_available():
45	        return
46	    if not dist.is_initialized():
47	        return
48	    world_size = dist.get_world_size()
49	    if world_size == 1:
50	        return
51	    dist.barrier()
52	
53	
54	def gather_on_master(data):
55	    &quot;&quot;&quot;Same as all_gather, but gathers data on master process only, using CPU.
56	    Thus, this does not work with NCCL backend unless they add CPU support.
57	
58	    The memory consumption of this function is ~ 3x of data size. While in
59	    principal, it should be ~2x, it&#x27;s not easy to force Python to release
60	    memory immediately and thus, peak memory usage could be up to 3x.
61	    &quot;&quot;&quot;
62	    world_size = get_world_size()
63	    if world_size == 1:
64	        return [data]
65	
66	    # serialized to a Tensor
67	    buffer = pickle.dumps(data)
68	    # trying to optimize memory, but in fact, it&#x27;s not guaranteed to be released
69	    del data
70	    storage = torch.ByteStorage.from_buffer(buffer)
71	    del buffer
72	    tensor = torch.ByteTensor(storage)
73	
74	    # obtain Tensor size of each rank
75	    local_size = torch.LongTensor([tensor.numel()])
76	    size_list = [torch.LongTensor([0]) for _ in range(world_size)]
77	    dist.all_gather(size_list, local_size)
78	    size_list = [int(size.item()) for size in size_list]
79	    max_size = max(size_list)
80	
81	    if local_size != max_size:
82	        padding = torch.ByteTensor(size=(max_size - local_size,))
83	        tensor = torch.cat((tensor, padding), dim=0)
84	        del padding
85	
86	    if is_main_process():
87	        tensor_list = []
88	        for _ in size_list:
89	            tensor_list.append(torch.ByteTensor(size=(max_size,)))
90	        dist.gather(tensor, gather_list=tensor_list, dst=0)
91	        del tensor
92	    else:
93	        dist.gather(tensor, gather_list=[], dst=0)
94	        del tensor
95	        return
96	
97	    data_list = []
98	    for tensor in tensor_list:
99	        buffer = tensor.cpu().numpy().tobytes()
100	        del tensor
101	        data_list.append(pickle.loads(buffer))
102	        del buffer
103	
104	    return data_list
105	
106	
107	def all_gather(data):
108	    &quot;&quot;&quot;
109	    Run all_gather on arbitrary picklable data (not necessarily tensors)
110	    Args:
111	        data: any picklable object
112	    Returns:
113	        list[data]: list of data gathered from each rank
114	    &quot;&quot;&quot;
115	    world_size = get_world_size()
116	    if world_size == 1:
117	        return [data]
118	
119	    # serialized to a Tensor
120	    buffer = pickle.dumps(data)
121	    storage = torch.ByteStorage.from_buffer(buffer)
122	    tensor = torch.ByteTensor(storage).to(device)
123	
124	    # obtain Tensor size of each rank
125	    local_size = torch.LongTensor([tensor.numel()]).to(device)
126	    size_list = [torch.LongTensor([0]).to(device) for _ in range(world_size)]
127	    dist.all_gather(size_list, local_size)
128	    size_list = [int(size.item()) for size in size_list]
129	    max_size = max(size_list)
130	
131	    # receiving Tensor from all ranks
132	    # we pad the tensor because torch all_gather does not support
133	    # gathering tensors of different shapes
134	    tensor_list = []
135	    for _ in size_list:
136	        tensor_list.append(torch.ByteTensor(size=(max_size,)).to(device))
137	    if local_size != max_size:
138	        padding = torch.ByteTensor(size=(max_size - local_size,)).to(device)
139	        tensor = torch.cat((tensor, padding), dim=0)
140	    dist.all_gather(tensor_list, tensor)
141	
142	    data_list = []
143	    for size, tensor in zip(size_list, tensor_list):
144	        buffer = tensor.cpu().numpy().tobytes()[:size]
145	        data_list.append(pickle.loads(buffer))
146	
147	    return data_list
148	
149	
150	def reduce_dict(input_dict, average=True):
151	    &quot;&quot;&quot;
152	    Args:
153	        input_dict (dict): all the values will be reduced
154	        average (bool): whether to do average or sum
155	    Reduce the values in the dictionary from all processes so that process with rank
156	    0 has the averaged results. Returns a dict with the same fields as
157	    input_dict, after reduction.
158	    &quot;&quot;&quot;
159	    world_size = get_world_size()
160	    if world_size &lt; 2:
</pre>
</div>


</div>
</div>

<div id="issue-83">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/comm.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/comm.py</a><br>
    <b>Line number: </b>145<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
85	
86	    if is_main_process():
87	        tensor_list = []
88	        for _ in size_list:
89	            tensor_list.append(torch.ByteTensor(size=(max_size,)))
90	        dist.gather(tensor, gather_list=tensor_list, dst=0)
91	        del tensor
92	    else:
93	        dist.gather(tensor, gather_list=[], dst=0)
94	        del tensor
95	        return
96	
97	    data_list = []
98	    for tensor in tensor_list:
99	        buffer = tensor.cpu().numpy().tobytes()
100	        del tensor
101	        data_list.append(pickle.loads(buffer))
102	        del buffer
103	
104	    return data_list
105	
106	
107	def all_gather(data):
108	    &quot;&quot;&quot;
109	    Run all_gather on arbitrary picklable data (not necessarily tensors)
110	    Args:
111	        data: any picklable object
112	    Returns:
113	        list[data]: list of data gathered from each rank
114	    &quot;&quot;&quot;
115	    world_size = get_world_size()
116	    if world_size == 1:
117	        return [data]
118	
119	    # serialized to a Tensor
120	    buffer = pickle.dumps(data)
121	    storage = torch.ByteStorage.from_buffer(buffer)
122	    tensor = torch.ByteTensor(storage).to(device)
123	
124	    # obtain Tensor size of each rank
125	    local_size = torch.LongTensor([tensor.numel()]).to(device)
126	    size_list = [torch.LongTensor([0]).to(device) for _ in range(world_size)]
127	    dist.all_gather(size_list, local_size)
128	    size_list = [int(size.item()) for size in size_list]
129	    max_size = max(size_list)
130	
131	    # receiving Tensor from all ranks
132	    # we pad the tensor because torch all_gather does not support
133	    # gathering tensors of different shapes
134	    tensor_list = []
135	    for _ in size_list:
136	        tensor_list.append(torch.ByteTensor(size=(max_size,)).to(device))
137	    if local_size != max_size:
138	        padding = torch.ByteTensor(size=(max_size - local_size,)).to(device)
139	        tensor = torch.cat((tensor, padding), dim=0)
140	    dist.all_gather(tensor_list, tensor)
141	
142	    data_list = []
143	    for size, tensor in zip(size_list, tensor_list):
144	        buffer = tensor.cpu().numpy().tobytes()[:size]
145	        data_list.append(pickle.loads(buffer))
146	
147	    return data_list
148	
149	
150	def reduce_dict(input_dict, average=True):
151	    &quot;&quot;&quot;
152	    Args:
153	        input_dict (dict): all the values will be reduced
154	        average (bool): whether to do average or sum
155	    Reduce the values in the dictionary from all processes so that process with rank
156	    0 has the averaged results. Returns a dict with the same fields as
157	    input_dict, after reduction.
158	    &quot;&quot;&quot;
159	    world_size = get_world_size()
160	    if world_size &lt; 2:
161	        return input_dict
162	    with torch.no_grad():
163	        names = []
164	        values = []
165	        # sort the keys so that they are consistent across processes
166	        for k in sorted(input_dict.keys()):
167	            names.append(k)
168	            values.append(input_dict[k])
169	        values = torch.stack(values, dim=0)
170	        dist.reduce(values, dst=0)
171	        if dist.get_rank() == 0 and average:
172	            # only main process gets accumulated, so only divide by
173	            # world_size in this case
174	            values /= world_size
175	        reduced_dict = {k: v for k, v in zip(names, values)}
176	    return reduced_dict
</pre>
</div>


</div>
</div>

<div id="issue-84">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/dataset_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/dataset_utils.py</a><br>
    <b>Line number: </b>66<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
6	
7	
8	import os
9	import os.path as op
10	import numpy as np
11	import base64
12	import cv2
13	import yaml
14	from collections import OrderedDict
15	
16	
17	def img_from_base64(imagestring):
18	    try:
19	        jpgbytestring = base64.b64decode(imagestring)
20	        nparr = np.frombuffer(jpgbytestring, np.uint8)
21	        r = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
22	        return r
23	    except:
24	        return None
25	
26	
27	def load_labelmap(labelmap_file):
28	    label_dict = None
29	    if labelmap_file is not None and op.isfile(labelmap_file):
30	        label_dict = OrderedDict()
31	        with open(labelmap_file, &#x27;r&#x27;) as fp:
32	            for line in fp:
33	                label = line.strip().split(&#x27;\t&#x27;)[0]
34	                if label in label_dict:
35	                    raise ValueError(&quot;Duplicate label &quot; + label + &quot; in labelmap.&quot;)
36	                else:
37	                    label_dict[label] = len(label_dict)
38	    return label_dict
39	
40	
41	def load_shuffle_file(shuf_file):
42	    shuf_list = None
43	    if shuf_file is not None:
44	        with open(shuf_file, &#x27;r&#x27;) as fp:
45	            shuf_list = []
46	            for i in fp:
47	                shuf_list.append(int(i.strip()))
48	    return shuf_list
49	
50	
51	def load_box_shuffle_file(shuf_file):
52	    if shuf_file is not None:
53	        with open(shuf_file, &#x27;r&#x27;) as fp:
54	            img_shuf_list = []
55	            box_shuf_list = []
56	            for i in fp:
57	                idx = [int(_) for _ in i.strip().split(&#x27;\t&#x27;)]
58	                img_shuf_list.append(idx[0])
59	                box_shuf_list.append(idx[1])
60	        return [img_shuf_list, box_shuf_list]
61	    return None
62	
63	
64	def load_from_yaml_file(file_name):
65	    with open(file_name, &#x27;r&#x27;) as fp:
66	        return yaml.load(fp, Loader=yaml.CLoader)
</pre>
</div>


</div>
</div>

<div id="issue-85">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/miscellaneous.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/miscellaneous.py</a><br>
    <b>Line number: </b>159<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
99	
100	def concat_files(ins, out):
101	    mkdir(op.dirname(out))
102	    out_tmp = out + &#x27;.tmp&#x27;
103	    with open(out_tmp, &#x27;wb&#x27;) as fp_out:
104	        for i, f in enumerate(ins):
105	            logging.info(&#x27;concating {}/{} - {}&#x27;.format(i, len(ins), f))
106	            with open(f, &#x27;rb&#x27;) as fp_in:
107	                shutil.copyfileobj(fp_in, fp_out, 1024*1024*10)
108	    os.rename(out_tmp, out)
109	
110	
111	def concat_tsv_files(tsvs, out_tsv):
112	    concat_files(tsvs, out_tsv)
113	    sizes = [os.stat(t).st_size for t in tsvs]
114	    sizes = np.cumsum(sizes)
115	    all_idx = []
116	    for i, t in enumerate(tsvs):
117	        for idx in load_list_file(op.splitext(t)[0] + &#x27;.lineidx&#x27;):
118	            if i == 0:
119	                all_idx.append(idx)
120	            else:
121	                all_idx.append(str(int(idx) + sizes[i - 1]))
122	    with open(op.splitext(out_tsv)[0] + &#x27;.lineidx&#x27;, &#x27;w&#x27;) as f:
123	        f.write(&#x27;\n&#x27;.join(all_idx))
124	
125	
126	def load_list_file(fname):
127	    with open(fname, &#x27;r&#x27;) as fp:
128	        lines = fp.readlines()
129	    result = [line.strip() for line in lines]
130	    if len(result) &gt; 0 and result[-1] == &#x27;&#x27;:
131	        result = result[:-1]
132	    return result
133	
134	
135	def try_once(func):
136	    def func_wrapper(*args, **kwargs):
137	        try:
138	            return func(*args, **kwargs)
139	        except Exception as e:
140	            logging.info(&#x27;ignore error \n{}&#x27;.format(str(e)))
141	    return func_wrapper
142	
143	
144	@try_once
145	def try_delete(f):
146	    os.remove(f)
147	
148	
149	def set_seed(seed, n_gpu):
150	    random.seed(seed)
151	    np.random.seed(seed)
152	    torch.manual_seed(seed)
153	    if n_gpu &gt; 0:
154	        torch.cuda.manual_seed_all(seed)
155	
156	
157	def print_and_run_cmd(cmd):
158	    print(cmd)
159	    os.system(cmd)
160	
161	
162	def write_to_yaml_file(context, file_name):
163	    with open(file_name, &#x27;w&#x27;) as fp:
164	        yaml.dump(context, fp, encoding=&#x27;utf-8&#x27;)
165	
166	
167	def load_from_yaml_file(yaml_file):
168	    with open(yaml_file, &#x27;r&#x27;) as fp:
169	        return yaml.load(fp, Loader=yaml.CLoader)
170	
171	
</pre>
</div>


</div>
</div>

<div id="issue-86">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/miscellaneous.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/miscellaneous.py</a><br>
    <b>Line number: </b>169<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
109	
110	
111	def concat_tsv_files(tsvs, out_tsv):
112	    concat_files(tsvs, out_tsv)
113	    sizes = [os.stat(t).st_size for t in tsvs]
114	    sizes = np.cumsum(sizes)
115	    all_idx = []
116	    for i, t in enumerate(tsvs):
117	        for idx in load_list_file(op.splitext(t)[0] + &#x27;.lineidx&#x27;):
118	            if i == 0:
119	                all_idx.append(idx)
120	            else:
121	                all_idx.append(str(int(idx) + sizes[i - 1]))
122	    with open(op.splitext(out_tsv)[0] + &#x27;.lineidx&#x27;, &#x27;w&#x27;) as f:
123	        f.write(&#x27;\n&#x27;.join(all_idx))
124	
125	
126	def load_list_file(fname):
127	    with open(fname, &#x27;r&#x27;) as fp:
128	        lines = fp.readlines()
129	    result = [line.strip() for line in lines]
130	    if len(result) &gt; 0 and result[-1] == &#x27;&#x27;:
131	        result = result[:-1]
132	    return result
133	
134	
135	def try_once(func):
136	    def func_wrapper(*args, **kwargs):
137	        try:
138	            return func(*args, **kwargs)
139	        except Exception as e:
140	            logging.info(&#x27;ignore error \n{}&#x27;.format(str(e)))
141	    return func_wrapper
142	
143	
144	@try_once
145	def try_delete(f):
146	    os.remove(f)
147	
148	
149	def set_seed(seed, n_gpu):
150	    random.seed(seed)
151	    np.random.seed(seed)
152	    torch.manual_seed(seed)
153	    if n_gpu &gt; 0:
154	        torch.cuda.manual_seed_all(seed)
155	
156	
157	def print_and_run_cmd(cmd):
158	    print(cmd)
159	    os.system(cmd)
160	
161	
162	def write_to_yaml_file(context, file_name):
163	    with open(file_name, &#x27;w&#x27;) as fp:
164	        yaml.dump(context, fp, encoding=&#x27;utf-8&#x27;)
165	
166	
167	def load_from_yaml_file(yaml_file):
168	    with open(yaml_file, &#x27;r&#x27;) as fp:
169	        return yaml.load(fp, Loader=yaml.CLoader)
170	
171	
</pre>
</div>


</div>
</div>

<div id="issue-87">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/tsv_file_ops.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mesh_graphormer/utils/tsv_file_ops.py</a><br>
    <b>Line number: </b>105<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
45	        assert values is not None
46	        for value in values:
47	            assert value is not None
48	            value = [v if type(v)!=bytes else v.decode(&#x27;utf-8&#x27;) for v in value]
49	            v = &#x27;{0}\n&#x27;.format(sep.join(map(str, value)))
50	            fp.write(v)
51	            fpidx.write(str(idx) + &#x27;\n&#x27;)
52	            idx = idx + len(v)
53	    os.rename(tsv_file_tmp, tsv_file)
54	    os.rename(lineidx_file_tmp, lineidx_file)
55	
56	def tsv_reader(tsv_file, sep=&#x27;\t&#x27;):
57	    with open(tsv_file, &#x27;r&#x27;) as fp:
58	        for i, line in enumerate(fp):
59	            yield [x.strip() for x in line.split(sep)]
60	
61	def config_save_file(tsv_file, save_file=None, append_str=&#x27;.new.tsv&#x27;):
62	    if save_file is not None:
63	        return save_file
64	    return op.splitext(tsv_file)[0] + append_str
65	
66	def get_line_list(linelist_file=None, num_rows=None):
67	    if linelist_file is not None:
68	        return load_linelist_file(linelist_file)
69	
70	    if num_rows is not None:
71	        return [i for i in range(num_rows)]
72	
73	def generate_hw_file(img_file, save_file=None):
74	    rows = tsv_reader(img_file)
75	    def gen_rows():
76	        for i, row in tqdm(enumerate(rows)):
77	            row1 = [row[0]]
78	            img = img_from_base64(row[-1])
79	            height = img.shape[0]
80	            width = img.shape[1]
81	            row1.append(json.dumps([{&quot;height&quot;:height, &quot;width&quot;: width}]))
82	            yield row1
83	
84	    save_file = config_save_file(img_file, save_file, &#x27;.hw.tsv&#x27;)
85	    tsv_writer(gen_rows(), save_file)
86	
87	def generate_linelist_file(label_file, save_file=None, ignore_attrs=()):
88	    # generate a list of image that has labels
89	    # images with only ignore labels are not selected. 
90	    line_list = []
91	    rows = tsv_reader(label_file)
92	    for i, row in tqdm(enumerate(rows)):
93	        labels = json.loads(row[1])
94	        if labels:
95	            if ignore_attrs and all([any([lab[attr] for attr in ignore_attrs if attr in lab]) \
96	                                for lab in labels]):
97	                continue
98	            line_list.append([i])
99	
100	    save_file = config_save_file(label_file, save_file, &#x27;.linelist.tsv&#x27;)
101	    tsv_writer(line_list, save_file)
102	
103	def load_from_yaml_file(yaml_file):
104	    with open(yaml_file, &#x27;r&#x27;) as fp:
105	        return yaml.load(fp, Loader=yaml.CLoader)
106	
107	def find_file_path_in_yaml(fname, root):
108	    if fname is not None:
109	        if op.isfile(fname):
110	            return fname
111	        elif op.isfile(op.join(root, fname)):
112	            return op.join(root, fname)
113	        else:
114	            raise FileNotFoundError(
115	                errno.ENOENT, os.strerror(errno.ENOENT), op.join(root, fname)
116	            )
</pre>
</div>


</div>
</div>

<div id="issue-88">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/utils.py</a><br>
    <b>Line number: </b>64<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
4	
5	
6	class Slice(nn.Module):
7	    def __init__(self, start_index=1):
8	        super(Slice, self).__init__()
9	        self.start_index = start_index
10	
11	    def forward(self, x):
12	        return x[:, self.start_index:]
13	
14	
15	class AddReadout(nn.Module):
16	    def __init__(self, start_index=1):
17	        super(AddReadout, self).__init__()
18	        self.start_index = start_index
19	
20	    def forward(self, x):
21	        if self.start_index == 2:
22	            readout = (x[:, 0] + x[:, 1]) / 2
23	        else:
24	            readout = x[:, 0]
25	        return x[:, self.start_index:] + readout.unsqueeze(1)
26	
27	
28	class ProjectReadout(nn.Module):
29	    def __init__(self, in_features, start_index=1):
30	        super(ProjectReadout, self).__init__()
31	        self.start_index = start_index
32	
33	        self.project = nn.Sequential(nn.Linear(2 * in_features, in_features), nn.GELU())
34	
35	    def forward(self, x):
36	        readout = x[:, 0].unsqueeze(1).expand_as(x[:, self.start_index:])
37	        features = torch.cat((x[:, self.start_index:], readout), -1)
38	
39	        return self.project(features)
40	
41	
42	class Transpose(nn.Module):
43	    def __init__(self, dim0, dim1):
44	        super(Transpose, self).__init__()
45	        self.dim0 = dim0
46	        self.dim1 = dim1
47	
48	    def forward(self, x):
49	        x = x.transpose(self.dim0, self.dim1)
50	        return x
51	
52	
53	activations = {}
54	
55	
56	def get_activation(name):
57	    def hook(model, input, output):
58	        activations[name] = output
59	
60	    return hook
61	
62	
63	def forward_default(pretrained, x, function_name=&quot;forward_features&quot;):
64	    exec(f&quot;pretrained.model.{function_name}(x)&quot;)
65	
66	    layer_1 = pretrained.activations[&quot;1&quot;]
67	    layer_2 = pretrained.activations[&quot;2&quot;]
68	    layer_3 = pretrained.activations[&quot;3&quot;]
69	    layer_4 = pretrained.activations[&quot;4&quot;]
70	
71	    if hasattr(pretrained, &quot;act_postprocess1&quot;):
72	        layer_1 = pretrained.act_postprocess1(layer_1)
73	    if hasattr(pretrained, &quot;act_postprocess2&quot;):
74	        layer_2 = pretrained.act_postprocess2(layer_2)
75	    if hasattr(pretrained, &quot;act_postprocess3&quot;):
76	        layer_3 = pretrained.act_postprocess3(layer_3)
77	    if hasattr(pretrained, &quot;act_postprocess4&quot;):
78	        layer_4 = pretrained.act_postprocess4(layer_4)
79	
80	    return layer_1, layer_2, layer_3, layer_4
81	
82	
83	def forward_adapted_unflatten(pretrained, x, function_name=&quot;forward_features&quot;):
84	    b, c, h, w = x.shape
85	
86	    exec(f&quot;glob = pretrained.model.{function_name}(x)&quot;)
87	
88	    layer_1 = pretrained.activations[&quot;1&quot;]
89	    layer_2 = pretrained.activations[&quot;2&quot;]
90	    layer_3 = pretrained.activations[&quot;3&quot;]
91	    layer_4 = pretrained.activations[&quot;4&quot;]
92	
93	    layer_1 = pretrained.act_postprocess1[0:2](layer_1)
94	    layer_2 = pretrained.act_postprocess2[0:2](layer_2)
95	    layer_3 = pretrained.act_postprocess3[0:2](layer_3)
96	    layer_4 = pretrained.act_postprocess4[0:2](layer_4)
97	
98	    unflatten = nn.Sequential(
99	        nn.Unflatten(
100	            2,
101	            torch.Size(
102	                [
103	                    h // pretrained.model.patch_size[1],
104	                    w // pretrained.model.patch_size[0],
105	                ]
106	            ),
107	        )
108	    )
109	
110	    if layer_1.ndim == 3:
111	        layer_1 = unflatten(layer_1)
112	    if layer_2.ndim == 3:
113	        layer_2 = unflatten(layer_2)
114	    if layer_3.ndim == 3:
115	        layer_3 = unflatten(layer_3)
116	    if layer_4.ndim == 3:
117	        layer_4 = unflatten(layer_4)
118	
119	    layer_1 = pretrained.act_postprocess1[3: len(pretrained.act_postprocess1)](layer_1)
120	    layer_2 = pretrained.act_postprocess2[3: len(pretrained.act_postprocess2)](layer_2)
121	    layer_3 = pretrained.act_postprocess3[3: len(pretrained.act_postprocess3)](layer_3)
122	    layer_4 = pretrained.act_postprocess4[3: len(pretrained.act_postprocess4)](layer_4)
123	
</pre>
</div>


</div>
</div>

<div id="issue-89">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/utils.py</a><br>
    <b>Line number: </b>86<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
26	
27	
28	class ProjectReadout(nn.Module):
29	    def __init__(self, in_features, start_index=1):
30	        super(ProjectReadout, self).__init__()
31	        self.start_index = start_index
32	
33	        self.project = nn.Sequential(nn.Linear(2 * in_features, in_features), nn.GELU())
34	
35	    def forward(self, x):
36	        readout = x[:, 0].unsqueeze(1).expand_as(x[:, self.start_index:])
37	        features = torch.cat((x[:, self.start_index:], readout), -1)
38	
39	        return self.project(features)
40	
41	
42	class Transpose(nn.Module):
43	    def __init__(self, dim0, dim1):
44	        super(Transpose, self).__init__()
45	        self.dim0 = dim0
46	        self.dim1 = dim1
47	
48	    def forward(self, x):
49	        x = x.transpose(self.dim0, self.dim1)
50	        return x
51	
52	
53	activations = {}
54	
55	
56	def get_activation(name):
57	    def hook(model, input, output):
58	        activations[name] = output
59	
60	    return hook
61	
62	
63	def forward_default(pretrained, x, function_name=&quot;forward_features&quot;):
64	    exec(f&quot;pretrained.model.{function_name}(x)&quot;)
65	
66	    layer_1 = pretrained.activations[&quot;1&quot;]
67	    layer_2 = pretrained.activations[&quot;2&quot;]
68	    layer_3 = pretrained.activations[&quot;3&quot;]
69	    layer_4 = pretrained.activations[&quot;4&quot;]
70	
71	    if hasattr(pretrained, &quot;act_postprocess1&quot;):
72	        layer_1 = pretrained.act_postprocess1(layer_1)
73	    if hasattr(pretrained, &quot;act_postprocess2&quot;):
74	        layer_2 = pretrained.act_postprocess2(layer_2)
75	    if hasattr(pretrained, &quot;act_postprocess3&quot;):
76	        layer_3 = pretrained.act_postprocess3(layer_3)
77	    if hasattr(pretrained, &quot;act_postprocess4&quot;):
78	        layer_4 = pretrained.act_postprocess4(layer_4)
79	
80	    return layer_1, layer_2, layer_3, layer_4
81	
82	
83	def forward_adapted_unflatten(pretrained, x, function_name=&quot;forward_features&quot;):
84	    b, c, h, w = x.shape
85	
86	    exec(f&quot;glob = pretrained.model.{function_name}(x)&quot;)
87	
88	    layer_1 = pretrained.activations[&quot;1&quot;]
89	    layer_2 = pretrained.activations[&quot;2&quot;]
90	    layer_3 = pretrained.activations[&quot;3&quot;]
91	    layer_4 = pretrained.activations[&quot;4&quot;]
92	
93	    layer_1 = pretrained.act_postprocess1[0:2](layer_1)
94	    layer_2 = pretrained.act_postprocess2[0:2](layer_2)
95	    layer_3 = pretrained.act_postprocess3[0:2](layer_3)
96	    layer_4 = pretrained.act_postprocess4[0:2](layer_4)
97	
98	    unflatten = nn.Sequential(
99	        nn.Unflatten(
100	            2,
101	            torch.Size(
102	                [
103	                    h // pretrained.model.patch_size[1],
104	                    w // pretrained.model.patch_size[0],
105	                ]
106	            ),
107	        )
108	    )
109	
110	    if layer_1.ndim == 3:
111	        layer_1 = unflatten(layer_1)
112	    if layer_2.ndim == 3:
113	        layer_2 = unflatten(layer_2)
114	    if layer_3.ndim == 3:
115	        layer_3 = unflatten(layer_3)
116	    if layer_4.ndim == 3:
117	        layer_4 = unflatten(layer_4)
118	
119	    layer_1 = pretrained.act_postprocess1[3: len(pretrained.act_postprocess1)](layer_1)
120	    layer_2 = pretrained.act_postprocess2[3: len(pretrained.act_postprocess2)](layer_2)
121	    layer_3 = pretrained.act_postprocess3[3: len(pretrained.act_postprocess3)](layer_3)
122	    layer_4 = pretrained.act_postprocess4[3: len(pretrained.act_postprocess4)](layer_4)
123	
124	    return layer_1, layer_2, layer_3, layer_4
125	
126	
127	def get_readout_oper(vit_features, features, use_readout, start_index=1):
128	    if use_readout == &quot;ignore&quot;:
129	        readout_oper = [Slice(start_index)] * len(features)
130	    elif use_readout == &quot;add&quot;:
131	        readout_oper = [AddReadout(start_index)] * len(features)
132	    elif use_readout == &quot;project&quot;:
133	        readout_oper = [
134	            ProjectReadout(vit_features, start_index) for out_feat in features
135	        ]
136	    else:
137	        assert (
138	            False
139	        ), &quot;wrong operation for readout token, use_readout can be &#x27;ignore&#x27;, &#x27;add&#x27;, or &#x27;project&#x27;&quot;
140	
141	    return readout_oper
142	
143	
144	def make_backbone_default(
145	        model,
</pre>
</div>


</div>
</div>

<div id="issue-90">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/vit.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/vit.py</a><br>
    <b>Line number: </b>150<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
90	    pretrained.model.forward_flex = types.MethodType(forward_flex, pretrained.model)
91	    pretrained.model._resize_pos_embed = types.MethodType(
92	        _resize_pos_embed, pretrained.model
93	    )
94	
95	    return pretrained
96	
97	
98	def _make_pretrained_vitl16_384(pretrained, use_readout=&quot;ignore&quot;, hooks=None):
99	    model = timm.create_model(&quot;vit_large_patch16_384&quot;, pretrained=pretrained)
100	
101	    hooks = [5, 11, 17, 23] if hooks == None else hooks
102	    return _make_vit_b16_backbone(
103	        model,
104	        features=[256, 512, 1024, 1024],
105	        hooks=hooks,
106	        vit_features=1024,
107	        use_readout=use_readout,
108	    )
109	
110	
111	def _make_pretrained_vitb16_384(pretrained, use_readout=&quot;ignore&quot;, hooks=None):
112	    model = timm.create_model(&quot;vit_base_patch16_384&quot;, pretrained=pretrained)
113	
114	    hooks = [2, 5, 8, 11] if hooks == None else hooks
115	    return _make_vit_b16_backbone(
116	        model, features=[96, 192, 384, 768], hooks=hooks, use_readout=use_readout
117	    )
118	
119	
120	def _make_vit_b_rn50_backbone(
121	    model,
122	    features=[256, 512, 768, 768],
123	    size=[384, 384],
124	    hooks=[0, 1, 8, 11],
125	    vit_features=768,
126	    patch_size=[16, 16],
127	    number_stages=2,
128	    use_vit_only=False,
129	    use_readout=&quot;ignore&quot;,
130	    start_index=1,
131	):
132	    pretrained = nn.Module()
133	
134	    pretrained.model = model
135	
136	    used_number_stages = 0 if use_vit_only else number_stages
137	    for s in range(used_number_stages):
138	        pretrained.model.patch_embed.backbone.stages[s].register_forward_hook(
139	            get_activation(str(s + 1))
140	        )
141	    for s in range(used_number_stages, 4):
142	        pretrained.model.blocks[hooks[s]].register_forward_hook(get_activation(str(s + 1)))
143	
144	    pretrained.activations = activations
145	
146	    readout_oper = get_readout_oper(vit_features, features, use_readout, start_index)
147	
148	    for s in range(used_number_stages):
149	        value = nn.Sequential(nn.Identity(), nn.Identity(), nn.Identity())
150	        exec(f&quot;pretrained.act_postprocess{s + 1}=value&quot;)
151	    for s in range(used_number_stages, 4):
152	        if s &lt; number_stages:
153	            final_layer = nn.ConvTranspose2d(
154	                in_channels=features[s],
155	                out_channels=features[s],
156	                kernel_size=4 // (2 ** s),
157	                stride=4 // (2 ** s),
158	                padding=0,
159	                bias=True,
160	                dilation=1,
161	                groups=1,
162	            )
163	        elif s &gt; number_stages:
164	            final_layer = nn.Conv2d(
165	                in_channels=features[3],
166	                out_channels=features[3],
167	                kernel_size=3,
168	                stride=2,
169	                padding=1,
170	            )
171	        else:
172	            final_layer = None
173	
174	        layers = [
175	            readout_oper[s],
176	            Transpose(1, 2),
177	            nn.Unflatten(2, torch.Size([size[0] // 16, size[1] // 16])),
178	            nn.Conv2d(
179	                in_channels=vit_features,
180	                out_channels=features[s],
181	                kernel_size=1,
182	                stride=1,
183	                padding=0,
184	            ),
185	        ]
186	        if final_layer is not None:
187	            layers.append(final_layer)
188	
189	        value = nn.Sequential(*layers)
190	        exec(f&quot;pretrained.act_postprocess{s + 1}=value&quot;)
191	
192	    pretrained.model.start_index = start_index
193	    pretrained.model.patch_size = patch_size
194	
195	    # We inject this function into the VisionTransformer instances so that
196	    # we can use it with interpolated position embeddings without modifying the library source.
197	    pretrained.model.forward_flex = types.MethodType(forward_flex, pretrained.model)
198	
199	    # We inject this function into the VisionTransformer instances so that
200	    # we can use it with interpolated position embeddings without modifying the library source.
201	    pretrained.model._resize_pos_embed = types.MethodType(
202	        _resize_pos_embed, pretrained.model
203	    )
204	
205	    return pretrained
206	
207	
208	def _make_pretrained_vitb_rn50_384(
209	    pretrained, use_readout=&quot;ignore&quot;, hooks=None, use_vit_only=False
</pre>
</div>


</div>
</div>

<div id="issue-91">
<div class="issue-block issue-sev-medium">
    <b>exec_used: </b> Use of exec detected.<br>
    <b>Test ID:</b> B102<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/vit.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_midas_repo/midas/backbones/vit.py</a><br>
    <b>Line number: </b>190<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b102_exec_used.html</a><br>

<div class="code">
<pre>
130	    start_index=1,
131	):
132	    pretrained = nn.Module()
133	
134	    pretrained.model = model
135	
136	    used_number_stages = 0 if use_vit_only else number_stages
137	    for s in range(used_number_stages):
138	        pretrained.model.patch_embed.backbone.stages[s].register_forward_hook(
139	            get_activation(str(s + 1))
140	        )
141	    for s in range(used_number_stages, 4):
142	        pretrained.model.blocks[hooks[s]].register_forward_hook(get_activation(str(s + 1)))
143	
144	    pretrained.activations = activations
145	
146	    readout_oper = get_readout_oper(vit_features, features, use_readout, start_index)
147	
148	    for s in range(used_number_stages):
149	        value = nn.Sequential(nn.Identity(), nn.Identity(), nn.Identity())
150	        exec(f&quot;pretrained.act_postprocess{s + 1}=value&quot;)
151	    for s in range(used_number_stages, 4):
152	        if s &lt; number_stages:
153	            final_layer = nn.ConvTranspose2d(
154	                in_channels=features[s],
155	                out_channels=features[s],
156	                kernel_size=4 // (2 ** s),
157	                stride=4 // (2 ** s),
158	                padding=0,
159	                bias=True,
160	                dilation=1,
161	                groups=1,
162	            )
163	        elif s &gt; number_stages:
164	            final_layer = nn.Conv2d(
165	                in_channels=features[3],
166	                out_channels=features[3],
167	                kernel_size=3,
168	                stride=2,
169	                padding=1,
170	            )
171	        else:
172	            final_layer = None
173	
174	        layers = [
175	            readout_oper[s],
176	            Transpose(1, 2),
177	            nn.Unflatten(2, torch.Size([size[0] // 16, size[1] // 16])),
178	            nn.Conv2d(
179	                in_channels=vit_features,
180	                out_channels=features[s],
181	                kernel_size=1,
182	                stride=1,
183	                padding=0,
184	            ),
185	        ]
186	        if final_layer is not None:
187	            layers.append(final_layer)
188	
189	        value = nn.Sequential(*layers)
190	        exec(f&quot;pretrained.act_postprocess{s + 1}=value&quot;)
191	
192	    pretrained.model.start_index = start_index
193	    pretrained.model.patch_size = patch_size
194	
195	    # We inject this function into the VisionTransformer instances so that
196	    # we can use it with interpolated position embeddings without modifying the library source.
197	    pretrained.model.forward_flex = types.MethodType(forward_flex, pretrained.model)
198	
199	    # We inject this function into the VisionTransformer instances so that
200	    # we can use it with interpolated position embeddings without modifying the library source.
201	    pretrained.model._resize_pos_embed = types.MethodType(
202	        _resize_pos_embed, pretrained.model
203	    )
204	
205	    return pretrained
206	
207	
208	def _make_pretrained_vitb_rn50_384(
209	    pretrained, use_readout=&quot;ignore&quot;, hooks=None, use_vit_only=False
210	):
211	    model = timm.create_model(&quot;vit_base_resnet50_384&quot;, pretrained=pretrained)
212	
213	    hooks = [0, 1, 8, 11] if hooks == None else hooks
214	    return _make_vit_b_rn50_backbone(
215	        model,
216	        features=[256, 512, 768, 768],
217	        size=[384, 384],
218	        hooks=hooks,
219	        use_vit_only=use_vit_only,
220	        use_readout=use_readout,
221	    )
</pre>
</div>


</div>
</div>

<div id="issue-92">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/engine/test.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/engine/test.py</a><br>
    <b>Line number: </b>3<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import os.path as osp
3	import pickle
4	import shutil
5	import tempfile
6	import time
7	
8	import torch
9	import torch.distributed as dist
10	
11	import custom_mmpkg.custom_mmcv as mmcv
12	from custom_mmpkg.custom_mmcv.runner import get_dist_info
13	
14	
15	def single_gpu_test(model, data_loader):
16	    &quot;&quot;&quot;Test model with a single gpu.
17	
18	    This method tests model with a single gpu and displays test progress bar.
19	
20	    Args:
21	        model (nn.Module): Model to be tested.
22	        data_loader (nn.Dataloader): Pytorch data loader.
23	
24	    Returns:
25	        list: The prediction results.
26	    &quot;&quot;&quot;
27	    model.eval()
28	    results = []
29	    dataset = data_loader.dataset
30	    prog_bar = mmcv.ProgressBar(len(dataset))
31	    for data in data_loader:
32	        with torch.no_grad():
33	            result = model(return_loss=False, **data)
34	        results.extend(result)
35	
36	        # Assume result has the same length of batch_size
37	        # refer to https://github.com/open-mmlab/mmcv/issues/985
38	        batch_size = len(result)
39	        for _ in range(batch_size):
40	            prog_bar.update()
41	    return results
42	
43	
44	def multi_gpu_test(model, data_loader, tmpdir=None, gpu_collect=False):
45	    &quot;&quot;&quot;Test model with multiple gpus.
46	
47	    This method tests model with multiple gpus and collects the results
48	    under two different modes: gpu and cpu modes. By setting
49	    ``gpu_collect=True``, it encodes results to gpu tensors and use gpu
50	    communication for results collection. On cpu mode it saves the results on
51	    different gpus to ``tmpdir`` and collects them by the rank 0 worker.
52	
53	    Args:
54	        model (nn.Module): Model to be tested.
55	        data_loader (nn.Dataloader): Pytorch data loader.
56	        tmpdir (str): Path of directory to save the temporary results from
57	            different gpus under cpu mode.
58	        gpu_collect (bool): Option to use either gpu or cpu to collect results.
59	
60	    Returns:
61	        list: The prediction results.
62	    &quot;&quot;&quot;
63	    model.eval()
64	    results = []
65	    dataset = data_loader.dataset
66	    rank, world_size = get_dist_info()
67	    if rank == 0:
68	        prog_bar = mmcv.ProgressBar(len(dataset))
69	    time.sleep(2)  # This line can prevent deadlock problem in some cases.
70	    for i, data in enumerate(data_loader):
71	        with torch.no_grad():
72	            result = model(return_loss=False, **data)
73	        results.extend(result)
74	
75	        if rank == 0:
76	            batch_size = len(result)
77	            batch_size_all = batch_size * world_size
78	            if batch_size_all + prog_bar.completed &gt; len(dataset):
79	                batch_size_all = len(dataset) - prog_bar.completed
80	            for _ in range(batch_size_all):
81	                prog_bar.update()
82	
83	    # collect results from all ranks
84	    if gpu_collect:
85	        results = collect_results_gpu(results, len(dataset))
86	    else:
87	        results = collect_results_cpu(results, len(dataset), tmpdir)
88	    return results
89	
90	
91	def collect_results_cpu(result_part, size, tmpdir=None):
92	    &quot;&quot;&quot;Collect results under cpu mode.
93	
94	    On cpu mode, this function will save the results on different gpus to
95	    ``tmpdir`` and collect them by the rank 0 worker.
96	
97	    Args:
98	        result_part (list): Result list containing result parts
99	            to be collected.
100	        size (int): Size of the results, commonly equal to length of
101	            the results.
102	        tmpdir (str | None): temporal directory for collected results to
103	            store. If set to None, it will create a random temporal directory
104	            for it.
105	
106	    Returns:
107	        list: The collected results.
108	    &quot;&quot;&quot;
109	    rank, world_size = get_dist_info()
110	    # create a tmp dir if it is not specified
111	    if tmpdir is None:
112	        MAX_LEN = 512
113	        # 32 is whitespace
114	        dir_tensor = torch.full((MAX_LEN, ),
115	                                32,
116	                                dtype=torch.uint8,
117	                                device=&#x27;cuda&#x27;)
118	        if rank == 0:
119	            mmcv.mkdir_or_exist(&#x27;.dist_test&#x27;)
120	            tmpdir = tempfile.mkdtemp(dir=&#x27;.dist_test&#x27;)
</pre>
</div>


</div>
</div>

<div id="issue-93">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/engine/test.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/engine/test.py</a><br>
    <b>Line number: </b>191<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
131	    # collect all parts
132	    if rank != 0:
133	        return None
134	    else:
135	        # load results of all parts from tmp dir
136	        part_list = []
137	        for i in range(world_size):
138	            part_file = osp.join(tmpdir, f&#x27;part_{i}.pkl&#x27;)
139	            part_result = mmcv.load(part_file)
140	            # When data is severely insufficient, an empty part_result
141	            # on a certain gpu could makes the overall outputs empty.
142	            if part_result:
143	                part_list.append(part_result)
144	        # sort the results
145	        ordered_results = []
146	        for res in zip(*part_list):
147	            ordered_results.extend(list(res))
148	        # the dataloader may pad some samples
149	        ordered_results = ordered_results[:size]
150	        # remove tmp dir
151	        shutil.rmtree(tmpdir)
152	        return ordered_results
153	
154	
155	def collect_results_gpu(result_part, size):
156	    &quot;&quot;&quot;Collect results under gpu mode.
157	
158	    On gpu mode, this function will encode results to gpu tensors and use gpu
159	    communication for results collection.
160	
161	    Args:
162	        result_part (list): Result list containing result parts
163	            to be collected.
164	        size (int): Size of the results, commonly equal to length of
165	            the results.
166	
167	    Returns:
168	        list: The collected results.
169	    &quot;&quot;&quot;
170	    rank, world_size = get_dist_info()
171	    # dump result part to tensor with pickle
172	    part_tensor = torch.tensor(
173	        bytearray(pickle.dumps(result_part)), dtype=torch.uint8, device=&#x27;cuda&#x27;)
174	    # gather all result part tensor shape
175	    shape_tensor = torch.tensor(part_tensor.shape, device=&#x27;cuda&#x27;)
176	    shape_list = [shape_tensor.clone() for _ in range(world_size)]
177	    dist.all_gather(shape_list, shape_tensor)
178	    # padding result part tensor to max length
179	    shape_max = torch.tensor(shape_list).max()
180	    part_send = torch.zeros(shape_max, dtype=torch.uint8, device=&#x27;cuda&#x27;)
181	    part_send[:shape_tensor[0]] = part_tensor
182	    part_recv_list = [
183	        part_tensor.new_zeros(shape_max) for _ in range(world_size)
184	    ]
185	    # gather all result part
186	    dist.all_gather(part_recv_list, part_send)
187	
188	    if rank == 0:
189	        part_list = []
190	        for recv, shape in zip(part_recv_list, shape_list):
191	            part_result = pickle.loads(recv[:shape[0]].cpu().numpy().tobytes())
192	            # When data is severely insufficient, an empty part_result
193	            # on a certain gpu could makes the overall outputs empty.
194	            if part_result:
195	                part_list.append(part_result)
196	        # sort the results
197	        ordered_results = []
198	        for res in zip(*part_list):
199	            ordered_results.extend(list(res))
200	        # the dataloader may pad some samples
201	        ordered_results = ordered_results[:size]
202	        return ordered_results
</pre>
</div>


</div>
</div>

<div id="issue-94">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Audit url open for permitted schemes. Allowing use of file:/ or custom schemes is often unexpected.<br>
    <b>Test ID:</b> B310<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/file_client.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/file_client.py</a><br>
    <b>Line number: </b>695<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen</a><br>

<div class="code">
<pre>
635	        &quot;&quot;&quot;Only for unified API and do nothing.&quot;&quot;&quot;
636	        yield filepath
637	
638	    def list_dir_or_file(self,
639	                         dir_path: Union[str, Path],
640	                         list_dir: bool = True,
641	                         list_file: bool = True,
642	                         suffix: Optional[Union[str, Tuple[str]]] = None,
643	                         recursive: bool = False) -&gt; Iterator[str]:
644	        &quot;&quot;&quot;Scan a directory to find the interested directories or files in
645	        arbitrary order.
646	
647	        Note:
648	            :meth:`list_dir_or_file` returns the path relative to ``dir_path``.
649	
650	        Args:
651	            dir_path (str | Path): Path of the directory.
652	            list_dir (bool): List the directories. Default: True.
653	            list_file (bool): List the path of files. Default: True.
654	            suffix (str or tuple[str], optional):  File suffix
655	                that we are interested in. Default: None.
656	            recursive (bool): If set to True, recursively scan the
657	                directory. Default: False.
658	
659	        Yields:
660	            Iterable[str]: A relative path to ``dir_path``.
661	        &quot;&quot;&quot;
662	        if list_dir and suffix is not None:
663	            raise TypeError(&#x27;`suffix` should be None when `list_dir` is True&#x27;)
664	
665	        if (suffix is not None) and not isinstance(suffix, (str, tuple)):
666	            raise TypeError(&#x27;`suffix` must be a string or tuple of strings&#x27;)
667	
668	        root = dir_path
669	
670	        def _list_dir_or_file(dir_path, list_dir, list_file, suffix,
671	                              recursive):
672	            for entry in os.scandir(dir_path):
673	                if not entry.name.startswith(&#x27;.&#x27;) and entry.is_file():
674	                    rel_path = osp.relpath(entry.path, root)
675	                    if (suffix is None
676	                            or rel_path.endswith(suffix)) and list_file:
677	                        yield rel_path
678	                elif osp.isdir(entry.path):
679	                    if list_dir:
680	                        rel_dir = osp.relpath(entry.path, root)
681	                        yield rel_dir
682	                    if recursive:
683	                        yield from _list_dir_or_file(entry.path, list_dir,
684	                                                     list_file, suffix,
685	                                                     recursive)
686	
687	        return _list_dir_or_file(dir_path, list_dir, list_file, suffix,
688	                                 recursive)
689	
690	
691	class HTTPBackend(BaseStorageBackend):
692	    &quot;&quot;&quot;HTTP and HTTPS storage bachend.&quot;&quot;&quot;
693	
694	    def get(self, filepath):
695	        value_buf = urlopen(filepath).read()
696	        return value_buf
697	
698	    def get_text(self, filepath, encoding=&#x27;utf-8&#x27;):
699	        value_buf = urlopen(filepath).read()
700	        return value_buf.decode(encoding)
701	
702	    @contextmanager
703	    def get_local_path(self, filepath: str) -&gt; Iterable[str]:
704	        &quot;&quot;&quot;Download a file from ``filepath``.
705	
706	        ``get_local_path`` is decorated by :meth:`contxtlib.contextmanager`. It
707	        can be called with ``with`` statement, and when exists from the
708	        ``with`` statement, the temporary path will be released.
709	
710	        Args:
711	            filepath (str): Download a file from ``filepath``.
712	
713	        Examples:
714	            &gt;&gt;&gt; client = HTTPBackend()
715	            &gt;&gt;&gt; # After existing from the ``with`` clause,
716	            &gt;&gt;&gt; # the path will be removed
717	            &gt;&gt;&gt; with client.get_local_path(&#x27;http://path/of/your/file&#x27;) as path:
718	            ...     # do something here
719	        &quot;&quot;&quot;
720	        try:
721	            f = tempfile.NamedTemporaryFile(delete=False)
722	            f.write(self.get(filepath))
723	            f.close()
724	            yield f.name
725	        finally:
726	            os.remove(f.name)
727	
728	
729	class FileClient:
730	    &quot;&quot;&quot;A general file client to access files in different backends.
731	
732	    The client loads a file or text in a specified backend from its path
733	    and returns it as a binary or text file. There are two ways to choose a
734	    backend, the name of backend and the prefix of path. Although both of them
735	    can be used to choose a storage backend, ``backend`` has a higher priority
736	    that is if they are all set, the storage backend will be chosen by the
737	    backend argument. If they are all `None`, the disk backend will be chosen.
738	    Note that It can also register other backend accessor with a given name,
739	    prefixes, and backend class. In addition, We use the singleton pattern to
740	    avoid repeated object creation. If the arguments are the same, the same
741	    object will be returned.
742	
743	    Args:
744	        backend (str, optional): The storage backend type. Options are &quot;disk&quot;,
745	            &quot;ceph&quot;, &quot;memcached&quot;, &quot;lmdb&quot;, &quot;http&quot; and &quot;petrel&quot;. Default: None.
746	        prefix (str, optional): The prefix of the registered storage backend.
747	            Options are &quot;s3&quot;, &quot;http&quot;, &quot;https&quot;. Default: None.
748	
749	    Examples:
750	        &gt;&gt;&gt; # only set backend
751	        &gt;&gt;&gt; file_client = FileClient(backend=&#x27;petrel&#x27;)
752	        &gt;&gt;&gt; # only set prefix
753	        &gt;&gt;&gt; file_client = FileClient(prefix=&#x27;s3&#x27;)
754	        &gt;&gt;&gt; # set both backend and prefix but use backend to choose client
</pre>
</div>


</div>
</div>

<div id="issue-95">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Audit url open for permitted schemes. Allowing use of file:/ or custom schemes is often unexpected.<br>
    <b>Test ID:</b> B310<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/file_client.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/file_client.py</a><br>
    <b>Line number: </b>699<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen</a><br>

<div class="code">
<pre>
639	                         dir_path: Union[str, Path],
640	                         list_dir: bool = True,
641	                         list_file: bool = True,
642	                         suffix: Optional[Union[str, Tuple[str]]] = None,
643	                         recursive: bool = False) -&gt; Iterator[str]:
644	        &quot;&quot;&quot;Scan a directory to find the interested directories or files in
645	        arbitrary order.
646	
647	        Note:
648	            :meth:`list_dir_or_file` returns the path relative to ``dir_path``.
649	
650	        Args:
651	            dir_path (str | Path): Path of the directory.
652	            list_dir (bool): List the directories. Default: True.
653	            list_file (bool): List the path of files. Default: True.
654	            suffix (str or tuple[str], optional):  File suffix
655	                that we are interested in. Default: None.
656	            recursive (bool): If set to True, recursively scan the
657	                directory. Default: False.
658	
659	        Yields:
660	            Iterable[str]: A relative path to ``dir_path``.
661	        &quot;&quot;&quot;
662	        if list_dir and suffix is not None:
663	            raise TypeError(&#x27;`suffix` should be None when `list_dir` is True&#x27;)
664	
665	        if (suffix is not None) and not isinstance(suffix, (str, tuple)):
666	            raise TypeError(&#x27;`suffix` must be a string or tuple of strings&#x27;)
667	
668	        root = dir_path
669	
670	        def _list_dir_or_file(dir_path, list_dir, list_file, suffix,
671	                              recursive):
672	            for entry in os.scandir(dir_path):
673	                if not entry.name.startswith(&#x27;.&#x27;) and entry.is_file():
674	                    rel_path = osp.relpath(entry.path, root)
675	                    if (suffix is None
676	                            or rel_path.endswith(suffix)) and list_file:
677	                        yield rel_path
678	                elif osp.isdir(entry.path):
679	                    if list_dir:
680	                        rel_dir = osp.relpath(entry.path, root)
681	                        yield rel_dir
682	                    if recursive:
683	                        yield from _list_dir_or_file(entry.path, list_dir,
684	                                                     list_file, suffix,
685	                                                     recursive)
686	
687	        return _list_dir_or_file(dir_path, list_dir, list_file, suffix,
688	                                 recursive)
689	
690	
691	class HTTPBackend(BaseStorageBackend):
692	    &quot;&quot;&quot;HTTP and HTTPS storage bachend.&quot;&quot;&quot;
693	
694	    def get(self, filepath):
695	        value_buf = urlopen(filepath).read()
696	        return value_buf
697	
698	    def get_text(self, filepath, encoding=&#x27;utf-8&#x27;):
699	        value_buf = urlopen(filepath).read()
700	        return value_buf.decode(encoding)
701	
702	    @contextmanager
703	    def get_local_path(self, filepath: str) -&gt; Iterable[str]:
704	        &quot;&quot;&quot;Download a file from ``filepath``.
705	
706	        ``get_local_path`` is decorated by :meth:`contxtlib.contextmanager`. It
707	        can be called with ``with`` statement, and when exists from the
708	        ``with`` statement, the temporary path will be released.
709	
710	        Args:
711	            filepath (str): Download a file from ``filepath``.
712	
713	        Examples:
714	            &gt;&gt;&gt; client = HTTPBackend()
715	            &gt;&gt;&gt; # After existing from the ``with`` clause,
716	            &gt;&gt;&gt; # the path will be removed
717	            &gt;&gt;&gt; with client.get_local_path(&#x27;http://path/of/your/file&#x27;) as path:
718	            ...     # do something here
719	        &quot;&quot;&quot;
720	        try:
721	            f = tempfile.NamedTemporaryFile(delete=False)
722	            f.write(self.get(filepath))
723	            f.close()
724	            yield f.name
725	        finally:
726	            os.remove(f.name)
727	
728	
729	class FileClient:
730	    &quot;&quot;&quot;A general file client to access files in different backends.
731	
732	    The client loads a file or text in a specified backend from its path
733	    and returns it as a binary or text file. There are two ways to choose a
734	    backend, the name of backend and the prefix of path. Although both of them
735	    can be used to choose a storage backend, ``backend`` has a higher priority
736	    that is if they are all set, the storage backend will be chosen by the
737	    backend argument. If they are all `None`, the disk backend will be chosen.
738	    Note that It can also register other backend accessor with a given name,
739	    prefixes, and backend class. In addition, We use the singleton pattern to
740	    avoid repeated object creation. If the arguments are the same, the same
741	    object will be returned.
742	
743	    Args:
744	        backend (str, optional): The storage backend type. Options are &quot;disk&quot;,
745	            &quot;ceph&quot;, &quot;memcached&quot;, &quot;lmdb&quot;, &quot;http&quot; and &quot;petrel&quot;. Default: None.
746	        prefix (str, optional): The prefix of the registered storage backend.
747	            Options are &quot;s3&quot;, &quot;http&quot;, &quot;https&quot;. Default: None.
748	
749	    Examples:
750	        &gt;&gt;&gt; # only set backend
751	        &gt;&gt;&gt; file_client = FileClient(backend=&#x27;petrel&#x27;)
752	        &gt;&gt;&gt; # only set prefix
753	        &gt;&gt;&gt; file_client = FileClient(prefix=&#x27;s3&#x27;)
754	        &gt;&gt;&gt; # set both backend and prefix but use backend to choose client
755	        &gt;&gt;&gt; file_client = FileClient(backend=&#x27;petrel&#x27;, prefix=&#x27;s3&#x27;)
756	        &gt;&gt;&gt; # if the arguments are the same, the same object is returned
757	        &gt;&gt;&gt; file_client1 = FileClient(backend=&#x27;petrel&#x27;)
758	        &gt;&gt;&gt; file_client1 is file_client
</pre>
</div>


</div>
</div>

<div id="issue-96">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with PickleHandler module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/__init__.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/__init__.py</a><br>
    <b>Line number: </b>4<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	from .base import BaseFileHandler
3	from .json_handler import JsonHandler
4	from .pickle_handler import PickleHandler
5	from .yaml_handler import YamlHandler
6	
7	__all__ = [&#x27;BaseFileHandler&#x27;, &#x27;JsonHandler&#x27;, &#x27;PickleHandler&#x27;, &#x27;YamlHandler&#x27;]
</pre>
</div>


</div>
</div>

<div id="issue-97">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/pickle_handler.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/pickle_handler.py</a><br>
    <b>Line number: </b>2<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import pickle
3	
4	from .base import BaseFileHandler
5	
6	
7	class PickleHandler(BaseFileHandler):
8	
9	    str_like = False
10	
11	    def load_from_fileobj(self, file, **kwargs):
12	        return pickle.load(file, **kwargs)
13	
14	    def load_from_path(self, filepath, **kwargs):
15	        return super(PickleHandler, self).load_from_path(
16	            filepath, mode=&#x27;rb&#x27;, **kwargs)
17	
18	    def dump_to_str(self, obj, **kwargs):
19	        kwargs.setdefault(&#x27;protocol&#x27;, 2)
20	        return pickle.dumps(obj, **kwargs)
21	
22	    def dump_to_fileobj(self, obj, file, **kwargs):
23	        kwargs.setdefault(&#x27;protocol&#x27;, 2)
24	        pickle.dump(obj, file, **kwargs)
25	
26	    def dump_to_path(self, obj, filepath, **kwargs):
27	        super(PickleHandler, self).dump_to_path(
28	            obj, filepath, mode=&#x27;wb&#x27;, **kwargs)
</pre>
</div>


</div>
</div>

<div id="issue-98">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/pickle_handler.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/pickle_handler.py</a><br>
    <b>Line number: </b>12<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import pickle
3	
4	from .base import BaseFileHandler
5	
6	
7	class PickleHandler(BaseFileHandler):
8	
9	    str_like = False
10	
11	    def load_from_fileobj(self, file, **kwargs):
12	        return pickle.load(file, **kwargs)
13	
14	    def load_from_path(self, filepath, **kwargs):
15	        return super(PickleHandler, self).load_from_path(
16	            filepath, mode=&#x27;rb&#x27;, **kwargs)
17	
18	    def dump_to_str(self, obj, **kwargs):
19	        kwargs.setdefault(&#x27;protocol&#x27;, 2)
20	        return pickle.dumps(obj, **kwargs)
21	
22	    def dump_to_fileobj(self, obj, file, **kwargs):
23	        kwargs.setdefault(&#x27;protocol&#x27;, 2)
24	        pickle.dump(obj, file, **kwargs)
25	
26	    def dump_to_path(self, obj, filepath, **kwargs):
27	        super(PickleHandler, self).dump_to_path(
28	            obj, filepath, mode=&#x27;wb&#x27;, **kwargs)
</pre>
</div>


</div>
</div>

<div id="issue-99">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/yaml_handler.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/fileio/handlers/yaml_handler.py</a><br>
    <b>Line number: </b>16<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import yaml
3	
4	try:
5	    from yaml import CLoader as Loader, CDumper as Dumper
6	except ImportError:
7	    from yaml import Loader, Dumper
8	
9	from .base import BaseFileHandler  # isort:skip
10	
11	
12	class YamlHandler(BaseFileHandler):
13	
14	    def load_from_fileobj(self, file, **kwargs):
15	        kwargs.setdefault(&#x27;Loader&#x27;, Loader)
16	        return yaml.load(file, **kwargs)
17	
18	    def dump_to_fileobj(self, obj, file, **kwargs):
19	        kwargs.setdefault(&#x27;Dumper&#x27;, Dumper)
20	        yaml.dump(obj, file, **kwargs)
21	
22	    def dump_to_str(self, obj, **kwargs):
23	        kwargs.setdefault(&#x27;Dumper&#x27;, Dumper)
24	        return yaml.dump(obj, **kwargs)
</pre>
</div>


</div>
</div>

<div id="issue-100">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Use of possibly insecure function - consider using safer ast.literal_eval.<br>
    <b>Test ID:</b> B307<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/ops/nms.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/ops/nms.py</a><br>
    <b>Line number: </b>302<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval</a><br>

<div class="code">
<pre>
242	        }
243	        inds = ext_module.softnms(*indata_list, **indata_dict)
244	    else:
245	        dets, inds = SoftNMSop.apply(boxes.cpu(), scores.cpu(),
246	                                     float(iou_threshold), float(sigma),
247	                                     float(min_score), method_dict[method],
248	                                     int(offset))
249	
250	    dets = dets[:inds.size(0)]
251	
252	    if is_numpy:
253	        dets = dets.cpu().numpy()
254	        inds = inds.cpu().numpy()
255	        return dets, inds
256	    else:
257	        return dets.to(device=boxes.device), inds.to(device=boxes.device)
258	
259	
260	def batched_nms(boxes, scores, idxs, nms_cfg, class_agnostic=False):
261	    &quot;&quot;&quot;Performs non-maximum suppression in a batched fashion.
262	
263	    Modified from https://github.com/pytorch/vision/blob
264	    /505cd6957711af790211896d32b40291bea1bc21/torchvision/ops/boxes.py#L39.
265	    In order to perform NMS independently per class, we add an offset to all
266	    the boxes. The offset is dependent only on the class idx, and is large
267	    enough so that boxes from different classes do not overlap.
268	
269	    Arguments:
270	        boxes (torch.Tensor): boxes in shape (N, 4).
271	        scores (torch.Tensor): scores in shape (N, ).
272	        idxs (torch.Tensor): each index value correspond to a bbox cluster,
273	            and NMS will not be applied between elements of different idxs,
274	            shape (N, ).
275	        nms_cfg (dict): specify nms type and other parameters like iou_thr.
276	            Possible keys includes the following.
277	
278	            - iou_thr (float): IoU threshold used for NMS.
279	            - split_thr (float): threshold number of boxes. In some cases the
280	                number of boxes is large (e.g., 200k). To avoid OOM during
281	                training, the users could set `split_thr` to a small value.
282	                If the number of boxes is greater than the threshold, it will
283	                perform NMS on each group of boxes separately and sequentially.
284	                Defaults to 10000.
285	        class_agnostic (bool): if true, nms is class agnostic,
286	            i.e. IoU thresholding happens over all boxes,
287	            regardless of the predicted class.
288	
289	    Returns:
290	        tuple: kept dets and indice.
291	    &quot;&quot;&quot;
292	    nms_cfg_ = nms_cfg.copy()
293	    class_agnostic = nms_cfg_.pop(&#x27;class_agnostic&#x27;, class_agnostic)
294	    if class_agnostic:
295	        boxes_for_nms = boxes
296	    else:
297	        max_coordinate = boxes.max()
298	        offsets = idxs.to(boxes) * (max_coordinate + torch.tensor(1).to(boxes))
299	        boxes_for_nms = boxes + offsets[:, None]
300	
301	    nms_type = nms_cfg_.pop(&#x27;type&#x27;, &#x27;nms&#x27;)
302	    nms_op = eval(nms_type)
303	
304	    split_thr = nms_cfg_.pop(&#x27;split_thr&#x27;, 10000)
305	    # Won&#x27;t split to multiple nms nodes when exporting to onnx
306	    if boxes_for_nms.shape[0] &lt; split_thr or torch.onnx.is_in_onnx_export():
307	        dets, keep = nms_op(boxes_for_nms, scores, **nms_cfg_)
308	        boxes = boxes[keep]
309	        # -1 indexing works abnormal in TensorRT
310	        # This assumes `dets` has 5 dimensions where
311	        # the last dimension is score.
312	        # TODO: more elegant way to handle the dimension issue.
313	        # Some type of nms would reweight the score, such as SoftNMS
314	        scores = dets[:, 4]
315	    else:
316	        max_num = nms_cfg_.pop(&#x27;max_num&#x27;, -1)
317	        total_mask = scores.new_zeros(scores.size(), dtype=torch.bool)
318	        # Some type of nms would reweight the score, such as SoftNMS
319	        scores_after_nms = scores.new_zeros(scores.size())
320	        for id in torch.unique(idxs):
321	            mask = (idxs == id).nonzero(as_tuple=False).view(-1)
322	            dets, keep = nms_op(boxes_for_nms[mask], scores[mask], **nms_cfg_)
323	            total_mask[mask[keep]] = True
324	            scores_after_nms[mask[keep]] = dets[:, -1]
325	        keep = total_mask.nonzero(as_tuple=False).view(-1)
326	
327	        scores, inds = scores_after_nms[keep].sort(descending=True)
328	        keep = keep[inds]
329	        boxes = boxes[keep]
330	
331	        if max_num &gt; 0:
332	            keep = keep[:max_num]
333	            boxes = boxes[:max_num]
334	            scores = scores[:max_num]
335	
336	    return torch.cat([boxes, scores[:, None]], -1), keep
337	
338	
339	def nms_match(dets, iou_threshold):
340	    &quot;&quot;&quot;Matched dets into different groups by NMS.
341	
342	    NMS match is Similar to NMS but when a bbox is suppressed, nms match will
343	    record the indice of suppressed bbox and form a group with the indice of
344	    kept bbox. In each group, indice is sorted as score order.
345	
346	    Arguments:
347	        dets (torch.Tensor | np.ndarray): Det boxes with scores, shape (N, 5).
348	        iou_thr (float): IoU thresh for NMS.
349	
350	    Returns:
351	        List[torch.Tensor | np.ndarray]: The outer list corresponds different
352	            matched group, the inner Tensor corresponds the indices for a group
353	            in score order.
354	    &quot;&quot;&quot;
355	    if dets.shape[0] == 0:
356	        matched = []
357	    else:
358	        assert dets.shape[-1] == 5, &#x27;inputs dets.shape should be (N, 5), &#x27; \
359	                                    f&#x27;but get {dets.shape}&#x27;
360	        if isinstance(dets, torch.Tensor):
361	            dets_t = dets.detach().cpu()
</pre>
</div>


</div>
</div>

<div id="issue-101">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/runner/dist_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/runner/dist_utils.py</a><br>
    <b>Line number: </b>4<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import functools
3	import os
4	import subprocess
5	from collections import OrderedDict
6	
7	import torch
8	import torch.multiprocessing as mp
9	from torch import distributed as dist
10	from torch._utils import (_flatten_dense_tensors, _take_tensors,
11	                          _unflatten_dense_tensors)
12	
13	
14	def init_dist(launcher, backend=&#x27;nccl&#x27;, **kwargs):
15	    if mp.get_start_method(allow_none=True) is None:
16	        mp.set_start_method(&#x27;spawn&#x27;)
17	    if launcher == &#x27;pytorch&#x27;:
18	        _init_dist_pytorch(backend, **kwargs)
19	    elif launcher == &#x27;mpi&#x27;:
20	        _init_dist_mpi(backend, **kwargs)
21	    elif launcher == &#x27;slurm&#x27;:
22	        _init_dist_slurm(backend, **kwargs)
23	    else:
24	        raise ValueError(f&#x27;Invalid launcher type: {launcher}&#x27;)
25	
26	
27	def _init_dist_pytorch(backend, **kwargs):
28	    # TODO: use local_rank instead of rank % num_gpus
29	    rank = int(os.environ[&#x27;RANK&#x27;])
30	    num_gpus = torch.cuda.device_count()
31	    torch.cuda.set_device(rank % num_gpus)
32	    dist.init_process_group(backend=backend, **kwargs)
33	
34	
35	def _init_dist_mpi(backend, **kwargs):
36	    # TODO: use local_rank instead of rank % num_gpus
37	    rank = int(os.environ[&#x27;OMPI_COMM_WORLD_RANK&#x27;])
38	    num_gpus = torch.cuda.device_count()
39	    torch.cuda.set_device(rank % num_gpus)
40	    dist.init_process_group(backend=backend, **kwargs)
41	
42	
43	def _init_dist_slurm(backend, port=None):
44	    &quot;&quot;&quot;Initialize slurm distributed training environment.
45	
46	    If argument ``port`` is not specified, then the master port will be system
47	    environment variable ``MASTER_PORT``. If ``MASTER_PORT`` is not in system
48	    environment variable, then a default port ``29500`` will be used.
49	
50	    Args:
51	        backend (str): Backend of torch.distributed.
52	        port (int, optional): Master port. Defaults to None.
53	    &quot;&quot;&quot;
54	    proc_id = int(os.environ[&#x27;SLURM_PROCID&#x27;])
55	    ntasks = int(os.environ[&#x27;SLURM_NTASKS&#x27;])
56	    node_list = os.environ[&#x27;SLURM_NODELIST&#x27;]
57	    num_gpus = torch.cuda.device_count()
58	    torch.cuda.set_device(proc_id % num_gpus)
59	    addr = subprocess.getoutput(
60	        f&#x27;scontrol show hostname {node_list} | head -n1&#x27;)
61	    # specify master port
62	    if port is not None:
63	        os.environ[&#x27;MASTER_PORT&#x27;] = str(port)
64	    elif &#x27;MASTER_PORT&#x27; in os.environ:
65	        pass  # use MASTER_PORT in the environment variable
66	    else:
67	        # 29500 is torch.distributed default port
68	        os.environ[&#x27;MASTER_PORT&#x27;] = &#x27;29500&#x27;
69	    # use MASTER_ADDR in the environment variable if it already exists
70	    if &#x27;MASTER_ADDR&#x27; not in os.environ:
71	        os.environ[&#x27;MASTER_ADDR&#x27;] = addr
72	    os.environ[&#x27;WORLD_SIZE&#x27;] = str(ntasks)
73	    os.environ[&#x27;LOCAL_RANK&#x27;] = str(proc_id % num_gpus)
74	    os.environ[&#x27;RANK&#x27;] = str(proc_id)
75	    dist.init_process_group(backend=backend)
76	
77	
78	def get_dist_info():
79	    if dist.is_available() and dist.is_initialized():
80	        rank = dist.get_rank()
81	        world_size = dist.get_world_size()
82	    else:
83	        rank = 0
84	        world_size = 1
85	    return rank, world_size
86	
87	
88	def master_only(func):
89	
90	    @functools.wraps(func)
91	    def wrapper(*args, **kwargs):
92	        rank, _ = get_dist_info()
93	        if rank == 0:
94	            return func(*args, **kwargs)
95	
96	    return wrapper
97	
98	
99	def allreduce_params(params, coalesce=True, bucket_size_mb=-1):
100	    &quot;&quot;&quot;Allreduce parameters.
101	
102	    Args:
103	        params (list[torch.Parameters]): List of parameters or buffers of a
104	            model.
105	        coalesce (bool, optional): Whether allreduce parameters as a whole.
106	            Defaults to True.
107	        bucket_size_mb (int, optional): Size of bucket, the unit is MB.
108	            Defaults to -1.
109	    &quot;&quot;&quot;
110	    _, world_size = get_dist_info()
111	    if world_size == 1:
112	        return
113	    params = [param.data for param in params]
114	    if coalesce:
115	        _allreduce_coalesced(params, world_size, bucket_size_mb)
116	    else:
117	        for tensor in params:
118	            dist.all_reduce(tensor.div_(world_size))
119	
120	
</pre>
</div>


</div>
</div>

<div id="issue-102">
<div class="issue-block issue-sev-high">
    <b>start_process_with_a_shell: </b> Starting a process with a shell, possible injection detected, security issue.<br>
    <b>Test ID:</b> B605<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/runner/dist_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/runner/dist_utils.py</a><br>
    <b>Line number: </b>59<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b605_start_process_with_a_shell.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import functools
3	import os
4	import subprocess
5	from collections import OrderedDict
6	
7	import torch
8	import torch.multiprocessing as mp
9	from torch import distributed as dist
10	from torch._utils import (_flatten_dense_tensors, _take_tensors,
11	                          _unflatten_dense_tensors)
12	
13	
14	def init_dist(launcher, backend=&#x27;nccl&#x27;, **kwargs):
15	    if mp.get_start_method(allow_none=True) is None:
16	        mp.set_start_method(&#x27;spawn&#x27;)
17	    if launcher == &#x27;pytorch&#x27;:
18	        _init_dist_pytorch(backend, **kwargs)
19	    elif launcher == &#x27;mpi&#x27;:
20	        _init_dist_mpi(backend, **kwargs)
21	    elif launcher == &#x27;slurm&#x27;:
22	        _init_dist_slurm(backend, **kwargs)
23	    else:
24	        raise ValueError(f&#x27;Invalid launcher type: {launcher}&#x27;)
25	
26	
27	def _init_dist_pytorch(backend, **kwargs):
28	    # TODO: use local_rank instead of rank % num_gpus
29	    rank = int(os.environ[&#x27;RANK&#x27;])
30	    num_gpus = torch.cuda.device_count()
31	    torch.cuda.set_device(rank % num_gpus)
32	    dist.init_process_group(backend=backend, **kwargs)
33	
34	
35	def _init_dist_mpi(backend, **kwargs):
36	    # TODO: use local_rank instead of rank % num_gpus
37	    rank = int(os.environ[&#x27;OMPI_COMM_WORLD_RANK&#x27;])
38	    num_gpus = torch.cuda.device_count()
39	    torch.cuda.set_device(rank % num_gpus)
40	    dist.init_process_group(backend=backend, **kwargs)
41	
42	
43	def _init_dist_slurm(backend, port=None):
44	    &quot;&quot;&quot;Initialize slurm distributed training environment.
45	
46	    If argument ``port`` is not specified, then the master port will be system
47	    environment variable ``MASTER_PORT``. If ``MASTER_PORT`` is not in system
48	    environment variable, then a default port ``29500`` will be used.
49	
50	    Args:
51	        backend (str): Backend of torch.distributed.
52	        port (int, optional): Master port. Defaults to None.
53	    &quot;&quot;&quot;
54	    proc_id = int(os.environ[&#x27;SLURM_PROCID&#x27;])
55	    ntasks = int(os.environ[&#x27;SLURM_NTASKS&#x27;])
56	    node_list = os.environ[&#x27;SLURM_NODELIST&#x27;]
57	    num_gpus = torch.cuda.device_count()
58	    torch.cuda.set_device(proc_id % num_gpus)
59	    addr = subprocess.getoutput(
60	        f&#x27;scontrol show hostname {node_list} | head -n1&#x27;)
61	    # specify master port
62	    if port is not None:
63	        os.environ[&#x27;MASTER_PORT&#x27;] = str(port)
64	    elif &#x27;MASTER_PORT&#x27; in os.environ:
65	        pass  # use MASTER_PORT in the environment variable
66	    else:
67	        # 29500 is torch.distributed default port
68	        os.environ[&#x27;MASTER_PORT&#x27;] = &#x27;29500&#x27;
69	    # use MASTER_ADDR in the environment variable if it already exists
70	    if &#x27;MASTER_ADDR&#x27; not in os.environ:
71	        os.environ[&#x27;MASTER_ADDR&#x27;] = addr
72	    os.environ[&#x27;WORLD_SIZE&#x27;] = str(ntasks)
73	    os.environ[&#x27;LOCAL_RANK&#x27;] = str(proc_id % num_gpus)
74	    os.environ[&#x27;RANK&#x27;] = str(proc_id)
75	    dist.init_process_group(backend=backend)
76	
77	
78	def get_dist_info():
79	    if dist.is_available() and dist.is_initialized():
80	        rank = dist.get_rank()
81	        world_size = dist.get_world_size()
82	    else:
83	        rank = 0
84	        world_size = 1
85	    return rank, world_size
86	
87	
88	def master_only(func):
89	
90	    @functools.wraps(func)
91	    def wrapper(*args, **kwargs):
92	        rank, _ = get_dist_info()
93	        if rank == 0:
94	            return func(*args, **kwargs)
95	
96	    return wrapper
97	
98	
99	def allreduce_params(params, coalesce=True, bucket_size_mb=-1):
100	    &quot;&quot;&quot;Allreduce parameters.
101	
102	    Args:
103	        params (list[torch.Parameters]): List of parameters or buffers of a
104	            model.
105	        coalesce (bool, optional): Whether allreduce parameters as a whole.
106	            Defaults to True.
107	        bucket_size_mb (int, optional): Size of bucket, the unit is MB.
108	            Defaults to -1.
109	    &quot;&quot;&quot;
110	    _, world_size = get_dist_info()
111	    if world_size == 1:
112	        return
113	    params = [param.data for param in params]
114	    if coalesce:
115	        _allreduce_coalesced(params, world_size, bucket_size_mb)
116	    else:
117	        for tensor in params:
118	            dist.all_reduce(tensor.div_(world_size))
119	
120	
121	def allreduce_grads(params, coalesce=True, bucket_size_mb=-1):
</pre>
</div>


</div>
</div>

<div id="issue-103">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py</a><br>
    <b>Line number: </b>5<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	&quot;&quot;&quot;This file holding some environment constant for sharing by other files.&quot;&quot;&quot;
3	
4	import os.path as osp
5	import subprocess
6	import sys
7	from collections import defaultdict
8	
9	import cv2
10	import torch
11	
12	import custom_mmpkg.custom_mmcv as mmcv
13	from .parrots_wrapper import get_build_config
14	
15	
16	def collect_env():
17	    &quot;&quot;&quot;Collect the information of the running environments.
18	
19	    Returns:
20	        dict: The environment information. The following fields are contained.
21	
22	            - sys.platform: The variable of ``sys.platform``.
23	            - Python: Python version.
24	            - CUDA available: Bool, indicating if CUDA is available.
25	            - GPU devices: Device type of each GPU.
26	            - CUDA_HOME (optional): The env var ``CUDA_HOME``.
27	            - NVCC (optional): NVCC version.
28	            - GCC: GCC version, &quot;n/a&quot; if GCC is not installed.
29	            - PyTorch: PyTorch version.
30	            - PyTorch compiling details: The output of \
31	                ``torch.__config__.show()``.
32	            - TorchVision (optional): TorchVision version.
33	            - OpenCV: OpenCV version.
34	            - MMCV: MMCV version.
35	            - MMCV Compiler: The GCC version for compiling MMCV ops.
36	            - MMCV CUDA Compiler: The CUDA version for compiling MMCV ops.
37	    &quot;&quot;&quot;
38	    env_info = {}
39	    env_info[&#x27;sys.platform&#x27;] = sys.platform
40	    env_info[&#x27;Python&#x27;] = sys.version.replace(&#x27;\n&#x27;, &#x27;&#x27;)
41	
42	    cuda_available = torch.cuda.is_available()
43	    env_info[&#x27;CUDA available&#x27;] = cuda_available
44	
45	    if cuda_available:
46	        devices = defaultdict(list)
47	        for k in range(torch.cuda.device_count()):
48	            devices[torch.cuda.get_device_name(k)].append(str(k))
49	        for name, device_ids in devices.items():
50	            env_info[&#x27;GPU &#x27; + &#x27;,&#x27;.join(device_ids)] = name
51	
52	        from custom_mmpkg.custom_mmcv.utils.parrots_wrapper import _get_cuda_home
53	        CUDA_HOME = _get_cuda_home()
54	        env_info[&#x27;CUDA_HOME&#x27;] = CUDA_HOME
55	
56	        if CUDA_HOME is not None and osp.isdir(CUDA_HOME):
57	            try:
58	                nvcc = osp.join(CUDA_HOME, &#x27;bin/nvcc&#x27;)
59	                nvcc = subprocess.check_output(
60	                    f&#x27;&quot;{nvcc}&quot; -V | tail -n1&#x27;, shell=True)
61	                nvcc = nvcc.decode(&#x27;utf-8&#x27;).strip()
62	            except subprocess.SubprocessError:
63	                nvcc = &#x27;Not Available&#x27;
64	            env_info[&#x27;NVCC&#x27;] = nvcc
65	
66	    try:
67	        gcc = subprocess.check_output(&#x27;gcc --version | head -n1&#x27;, shell=True)
68	        gcc = gcc.decode(&#x27;utf-8&#x27;).strip()
69	        env_info[&#x27;GCC&#x27;] = gcc
70	    except subprocess.CalledProcessError:  # gcc is unavailable
71	        env_info[&#x27;GCC&#x27;] = &#x27;n/a&#x27;
72	
73	    env_info[&#x27;PyTorch&#x27;] = torch.__version__
74	    env_info[&#x27;PyTorch compiling details&#x27;] = get_build_config()
75	
76	    try:
77	        import torchvision
78	        env_info[&#x27;TorchVision&#x27;] = torchvision.__version__
79	    except ModuleNotFoundError:
80	        pass
81	
82	    env_info[&#x27;OpenCV&#x27;] = cv2.__version__
83	
84	    env_info[&#x27;MMCV&#x27;] = mmcv.__version__
85	
86	    try:
87	        from custom_mmpkg.custom_mmcv.ops import get_compiler_version, get_compiling_cuda_version
88	    except ModuleNotFoundError:
89	        env_info[&#x27;MMCV Compiler&#x27;] = &#x27;n/a&#x27;
90	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = &#x27;n/a&#x27;
91	    else:
92	        env_info[&#x27;MMCV Compiler&#x27;] = get_compiler_version()
93	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = get_compiling_cuda_version()
94	
95	    return env_info
</pre>
</div>


</div>
</div>

<div id="issue-104">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py</a><br>
    <b>Line number: </b>60<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	&quot;&quot;&quot;This file holding some environment constant for sharing by other files.&quot;&quot;&quot;
3	
4	import os.path as osp
5	import subprocess
6	import sys
7	from collections import defaultdict
8	
9	import cv2
10	import torch
11	
12	import custom_mmpkg.custom_mmcv as mmcv
13	from .parrots_wrapper import get_build_config
14	
15	
16	def collect_env():
17	    &quot;&quot;&quot;Collect the information of the running environments.
18	
19	    Returns:
20	        dict: The environment information. The following fields are contained.
21	
22	            - sys.platform: The variable of ``sys.platform``.
23	            - Python: Python version.
24	            - CUDA available: Bool, indicating if CUDA is available.
25	            - GPU devices: Device type of each GPU.
26	            - CUDA_HOME (optional): The env var ``CUDA_HOME``.
27	            - NVCC (optional): NVCC version.
28	            - GCC: GCC version, &quot;n/a&quot; if GCC is not installed.
29	            - PyTorch: PyTorch version.
30	            - PyTorch compiling details: The output of \
31	                ``torch.__config__.show()``.
32	            - TorchVision (optional): TorchVision version.
33	            - OpenCV: OpenCV version.
34	            - MMCV: MMCV version.
35	            - MMCV Compiler: The GCC version for compiling MMCV ops.
36	            - MMCV CUDA Compiler: The CUDA version for compiling MMCV ops.
37	    &quot;&quot;&quot;
38	    env_info = {}
39	    env_info[&#x27;sys.platform&#x27;] = sys.platform
40	    env_info[&#x27;Python&#x27;] = sys.version.replace(&#x27;\n&#x27;, &#x27;&#x27;)
41	
42	    cuda_available = torch.cuda.is_available()
43	    env_info[&#x27;CUDA available&#x27;] = cuda_available
44	
45	    if cuda_available:
46	        devices = defaultdict(list)
47	        for k in range(torch.cuda.device_count()):
48	            devices[torch.cuda.get_device_name(k)].append(str(k))
49	        for name, device_ids in devices.items():
50	            env_info[&#x27;GPU &#x27; + &#x27;,&#x27;.join(device_ids)] = name
51	
52	        from custom_mmpkg.custom_mmcv.utils.parrots_wrapper import _get_cuda_home
53	        CUDA_HOME = _get_cuda_home()
54	        env_info[&#x27;CUDA_HOME&#x27;] = CUDA_HOME
55	
56	        if CUDA_HOME is not None and osp.isdir(CUDA_HOME):
57	            try:
58	                nvcc = osp.join(CUDA_HOME, &#x27;bin/nvcc&#x27;)
59	                nvcc = subprocess.check_output(
60	                    f&#x27;&quot;{nvcc}&quot; -V | tail -n1&#x27;, shell=True)
61	                nvcc = nvcc.decode(&#x27;utf-8&#x27;).strip()
62	            except subprocess.SubprocessError:
63	                nvcc = &#x27;Not Available&#x27;
64	            env_info[&#x27;NVCC&#x27;] = nvcc
65	
66	    try:
67	        gcc = subprocess.check_output(&#x27;gcc --version | head -n1&#x27;, shell=True)
68	        gcc = gcc.decode(&#x27;utf-8&#x27;).strip()
69	        env_info[&#x27;GCC&#x27;] = gcc
70	    except subprocess.CalledProcessError:  # gcc is unavailable
71	        env_info[&#x27;GCC&#x27;] = &#x27;n/a&#x27;
72	
73	    env_info[&#x27;PyTorch&#x27;] = torch.__version__
74	    env_info[&#x27;PyTorch compiling details&#x27;] = get_build_config()
75	
76	    try:
77	        import torchvision
78	        env_info[&#x27;TorchVision&#x27;] = torchvision.__version__
79	    except ModuleNotFoundError:
80	        pass
81	
82	    env_info[&#x27;OpenCV&#x27;] = cv2.__version__
83	
84	    env_info[&#x27;MMCV&#x27;] = mmcv.__version__
85	
86	    try:
87	        from custom_mmpkg.custom_mmcv.ops import get_compiler_version, get_compiling_cuda_version
88	    except ModuleNotFoundError:
89	        env_info[&#x27;MMCV Compiler&#x27;] = &#x27;n/a&#x27;
90	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = &#x27;n/a&#x27;
91	    else:
92	        env_info[&#x27;MMCV Compiler&#x27;] = get_compiler_version()
93	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = get_compiling_cuda_version()
94	
95	    return env_info
</pre>
</div>


</div>
</div>

<div id="issue-105">
<div class="issue-block issue-sev-low">
    <b>start_process_with_partial_path: </b> Starting a process with a partial executable path<br>
    <b>Test ID:</b> B607<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py</a><br>
    <b>Line number: </b>67<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b607_start_process_with_partial_path.html</a><br>

<div class="code">
<pre>
7	from collections import defaultdict
8	
9	import cv2
10	import torch
11	
12	import custom_mmpkg.custom_mmcv as mmcv
13	from .parrots_wrapper import get_build_config
14	
15	
16	def collect_env():
17	    &quot;&quot;&quot;Collect the information of the running environments.
18	
19	    Returns:
20	        dict: The environment information. The following fields are contained.
21	
22	            - sys.platform: The variable of ``sys.platform``.
23	            - Python: Python version.
24	            - CUDA available: Bool, indicating if CUDA is available.
25	            - GPU devices: Device type of each GPU.
26	            - CUDA_HOME (optional): The env var ``CUDA_HOME``.
27	            - NVCC (optional): NVCC version.
28	            - GCC: GCC version, &quot;n/a&quot; if GCC is not installed.
29	            - PyTorch: PyTorch version.
30	            - PyTorch compiling details: The output of \
31	                ``torch.__config__.show()``.
32	            - TorchVision (optional): TorchVision version.
33	            - OpenCV: OpenCV version.
34	            - MMCV: MMCV version.
35	            - MMCV Compiler: The GCC version for compiling MMCV ops.
36	            - MMCV CUDA Compiler: The CUDA version for compiling MMCV ops.
37	    &quot;&quot;&quot;
38	    env_info = {}
39	    env_info[&#x27;sys.platform&#x27;] = sys.platform
40	    env_info[&#x27;Python&#x27;] = sys.version.replace(&#x27;\n&#x27;, &#x27;&#x27;)
41	
42	    cuda_available = torch.cuda.is_available()
43	    env_info[&#x27;CUDA available&#x27;] = cuda_available
44	
45	    if cuda_available:
46	        devices = defaultdict(list)
47	        for k in range(torch.cuda.device_count()):
48	            devices[torch.cuda.get_device_name(k)].append(str(k))
49	        for name, device_ids in devices.items():
50	            env_info[&#x27;GPU &#x27; + &#x27;,&#x27;.join(device_ids)] = name
51	
52	        from custom_mmpkg.custom_mmcv.utils.parrots_wrapper import _get_cuda_home
53	        CUDA_HOME = _get_cuda_home()
54	        env_info[&#x27;CUDA_HOME&#x27;] = CUDA_HOME
55	
56	        if CUDA_HOME is not None and osp.isdir(CUDA_HOME):
57	            try:
58	                nvcc = osp.join(CUDA_HOME, &#x27;bin/nvcc&#x27;)
59	                nvcc = subprocess.check_output(
60	                    f&#x27;&quot;{nvcc}&quot; -V | tail -n1&#x27;, shell=True)
61	                nvcc = nvcc.decode(&#x27;utf-8&#x27;).strip()
62	            except subprocess.SubprocessError:
63	                nvcc = &#x27;Not Available&#x27;
64	            env_info[&#x27;NVCC&#x27;] = nvcc
65	
66	    try:
67	        gcc = subprocess.check_output(&#x27;gcc --version | head -n1&#x27;, shell=True)
68	        gcc = gcc.decode(&#x27;utf-8&#x27;).strip()
69	        env_info[&#x27;GCC&#x27;] = gcc
70	    except subprocess.CalledProcessError:  # gcc is unavailable
71	        env_info[&#x27;GCC&#x27;] = &#x27;n/a&#x27;
72	
73	    env_info[&#x27;PyTorch&#x27;] = torch.__version__
74	    env_info[&#x27;PyTorch compiling details&#x27;] = get_build_config()
75	
76	    try:
77	        import torchvision
78	        env_info[&#x27;TorchVision&#x27;] = torchvision.__version__
79	    except ModuleNotFoundError:
80	        pass
81	
82	    env_info[&#x27;OpenCV&#x27;] = cv2.__version__
83	
84	    env_info[&#x27;MMCV&#x27;] = mmcv.__version__
85	
86	    try:
87	        from custom_mmpkg.custom_mmcv.ops import get_compiler_version, get_compiling_cuda_version
88	    except ModuleNotFoundError:
89	        env_info[&#x27;MMCV Compiler&#x27;] = &#x27;n/a&#x27;
90	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = &#x27;n/a&#x27;
91	    else:
92	        env_info[&#x27;MMCV Compiler&#x27;] = get_compiler_version()
93	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = get_compiling_cuda_version()
94	
95	    return env_info
</pre>
</div>


</div>
</div>

<div id="issue-106">
<div class="issue-block issue-sev-low">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/env.py</a><br>
    <b>Line number: </b>67<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
7	from collections import defaultdict
8	
9	import cv2
10	import torch
11	
12	import custom_mmpkg.custom_mmcv as mmcv
13	from .parrots_wrapper import get_build_config
14	
15	
16	def collect_env():
17	    &quot;&quot;&quot;Collect the information of the running environments.
18	
19	    Returns:
20	        dict: The environment information. The following fields are contained.
21	
22	            - sys.platform: The variable of ``sys.platform``.
23	            - Python: Python version.
24	            - CUDA available: Bool, indicating if CUDA is available.
25	            - GPU devices: Device type of each GPU.
26	            - CUDA_HOME (optional): The env var ``CUDA_HOME``.
27	            - NVCC (optional): NVCC version.
28	            - GCC: GCC version, &quot;n/a&quot; if GCC is not installed.
29	            - PyTorch: PyTorch version.
30	            - PyTorch compiling details: The output of \
31	                ``torch.__config__.show()``.
32	            - TorchVision (optional): TorchVision version.
33	            - OpenCV: OpenCV version.
34	            - MMCV: MMCV version.
35	            - MMCV Compiler: The GCC version for compiling MMCV ops.
36	            - MMCV CUDA Compiler: The CUDA version for compiling MMCV ops.
37	    &quot;&quot;&quot;
38	    env_info = {}
39	    env_info[&#x27;sys.platform&#x27;] = sys.platform
40	    env_info[&#x27;Python&#x27;] = sys.version.replace(&#x27;\n&#x27;, &#x27;&#x27;)
41	
42	    cuda_available = torch.cuda.is_available()
43	    env_info[&#x27;CUDA available&#x27;] = cuda_available
44	
45	    if cuda_available:
46	        devices = defaultdict(list)
47	        for k in range(torch.cuda.device_count()):
48	            devices[torch.cuda.get_device_name(k)].append(str(k))
49	        for name, device_ids in devices.items():
50	            env_info[&#x27;GPU &#x27; + &#x27;,&#x27;.join(device_ids)] = name
51	
52	        from custom_mmpkg.custom_mmcv.utils.parrots_wrapper import _get_cuda_home
53	        CUDA_HOME = _get_cuda_home()
54	        env_info[&#x27;CUDA_HOME&#x27;] = CUDA_HOME
55	
56	        if CUDA_HOME is not None and osp.isdir(CUDA_HOME):
57	            try:
58	                nvcc = osp.join(CUDA_HOME, &#x27;bin/nvcc&#x27;)
59	                nvcc = subprocess.check_output(
60	                    f&#x27;&quot;{nvcc}&quot; -V | tail -n1&#x27;, shell=True)
61	                nvcc = nvcc.decode(&#x27;utf-8&#x27;).strip()
62	            except subprocess.SubprocessError:
63	                nvcc = &#x27;Not Available&#x27;
64	            env_info[&#x27;NVCC&#x27;] = nvcc
65	
66	    try:
67	        gcc = subprocess.check_output(&#x27;gcc --version | head -n1&#x27;, shell=True)
68	        gcc = gcc.decode(&#x27;utf-8&#x27;).strip()
69	        env_info[&#x27;GCC&#x27;] = gcc
70	    except subprocess.CalledProcessError:  # gcc is unavailable
71	        env_info[&#x27;GCC&#x27;] = &#x27;n/a&#x27;
72	
73	    env_info[&#x27;PyTorch&#x27;] = torch.__version__
74	    env_info[&#x27;PyTorch compiling details&#x27;] = get_build_config()
75	
76	    try:
77	        import torchvision
78	        env_info[&#x27;TorchVision&#x27;] = torchvision.__version__
79	    except ModuleNotFoundError:
80	        pass
81	
82	    env_info[&#x27;OpenCV&#x27;] = cv2.__version__
83	
84	    env_info[&#x27;MMCV&#x27;] = mmcv.__version__
85	
86	    try:
87	        from custom_mmpkg.custom_mmcv.ops import get_compiler_version, get_compiling_cuda_version
88	    except ModuleNotFoundError:
89	        env_info[&#x27;MMCV Compiler&#x27;] = &#x27;n/a&#x27;
90	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = &#x27;n/a&#x27;
91	    else:
92	        env_info[&#x27;MMCV Compiler&#x27;] = get_compiler_version()
93	        env_info[&#x27;MMCV CUDA Compiler&#x27;] = get_compiling_cuda_version()
94	
95	    return env_info
</pre>
</div>


</div>
</div>

<div id="issue-107">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/misc.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/misc.py</a><br>
    <b>Line number: </b>5<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import collections.abc
3	import functools
4	import itertools
5	import subprocess
6	import warnings
7	from collections import abc
8	from importlib import import_module
9	from inspect import getfullargspec
10	from itertools import repeat
11	
12	
13	# From PyTorch internals
14	def _ntuple(n):
15	
16	    def parse(x):
17	        if isinstance(x, collections.abc.Iterable):
18	            return x
19	        return tuple(repeat(x, n))
20	
21	    return parse
22	
23	
24	to_1tuple = _ntuple(1)
25	to_2tuple = _ntuple(2)
26	to_3tuple = _ntuple(3)
27	to_4tuple = _ntuple(4)
28	to_ntuple = _ntuple
29	
30	
31	def is_str(x):
32	    &quot;&quot;&quot;Whether the input is an string instance.
33	
34	    Note: This method is deprecated since python 2 is no longer supported.
35	    &quot;&quot;&quot;
36	    return isinstance(x, str)
37	
38	
39	def import_modules_from_strings(imports, allow_failed_imports=False):
40	    &quot;&quot;&quot;Import modules from the given list of strings.
41	
42	    Args:
43	        imports (list | str | None): The given module names to be imported.
44	        allow_failed_imports (bool): If True, the failed imports will return
45	            None. Otherwise, an ImportError is raise. Default: False.
46	
47	    Returns:
48	        list[module] | module | None: The imported modules.
49	
50	    Examples:
51	        &gt;&gt;&gt; osp, sys = import_modules_from_strings(
52	        ...     [&#x27;os.path&#x27;, &#x27;sys&#x27;])
53	        &gt;&gt;&gt; import os.path as osp_
54	        &gt;&gt;&gt; import sys as sys_
55	        &gt;&gt;&gt; assert osp == osp_
56	        &gt;&gt;&gt; assert sys == sys_
57	    &quot;&quot;&quot;
58	    if not imports:
59	        return
60	    single_import = False
61	    if isinstance(imports, str):
62	        single_import = True
63	        imports = [imports]
64	    if not isinstance(imports, list):
65	        raise TypeError(
66	            f&#x27;custom_imports must be a list but got type {type(imports)}&#x27;)
67	    imported = []
68	    for imp in imports:
69	        if not isinstance(imp, str):
70	            raise TypeError(
71	                f&#x27;{imp} is of type {type(imp)} and cannot be imported.&#x27;)
72	        try:
73	            imported_tmp = import_module(imp)
74	        except ImportError:
75	            if allow_failed_imports:
76	                warnings.warn(f&#x27;{imp} failed to import and is ignored.&#x27;,
77	                              UserWarning)
78	                imported_tmp = None
79	            else:
80	                raise ImportError
81	        imported.append(imported_tmp)
82	    if single_import:
83	        imported = imported[0]
84	    return imported
85	
86	
87	def iter_cast(inputs, dst_type, return_type=None):
88	    &quot;&quot;&quot;Cast elements of an iterable object into some type.
89	
90	    Args:
91	        inputs (Iterable): The input object.
92	        dst_type (type): Destination type.
93	        return_type (type, optional): If specified, the output object will be
94	            converted to this type, otherwise an iterator.
95	
96	    Returns:
97	        iterator or specified type: The converted object.
98	    &quot;&quot;&quot;
99	    if not isinstance(inputs, abc.Iterable):
100	        raise TypeError(&#x27;inputs must be an iterable object&#x27;)
101	    if not isinstance(dst_type, type):
102	        raise TypeError(&#x27;&quot;dst_type&quot; must be a valid type&#x27;)
103	
104	    out_iterable = map(dst_type, inputs)
105	
106	    if return_type is None:
107	        return out_iterable
108	    else:
109	        return return_type(out_iterable)
110	
111	
112	def list_cast(inputs, dst_type):
113	    &quot;&quot;&quot;Cast elements of an iterable object into a list of some type.
114	
115	    A partial method of :func:`iter_cast`.
116	    &quot;&quot;&quot;
117	    return iter_cast(inputs, dst_type, return_type=list)
118	
119	
120	def tuple_cast(inputs, dst_type):
</pre>
</div>


</div>
</div>

<div id="issue-108">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/misc.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/misc.py</a><br>
    <b>Line number: </b>254<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
194	def concat_list(in_list):
195	    &quot;&quot;&quot;Concatenate a list of list into a single list.
196	
197	    Args:
198	        in_list (list): The list of list to be merged.
199	
200	    Returns:
201	        list: The concatenated flat list.
202	    &quot;&quot;&quot;
203	    return list(itertools.chain(*in_list))
204	
205	
206	def check_prerequisites(
207	        prerequisites,
208	        checker,
209	        msg_tmpl=&#x27;Prerequisites &quot;{}&quot; are required in method &quot;{}&quot; but not &#x27;
210	        &#x27;found, please install them first.&#x27;):  # yapf: disable
211	    &quot;&quot;&quot;A decorator factory to check if prerequisites are satisfied.
212	
213	    Args:
214	        prerequisites (str of list[str]): Prerequisites to be checked.
215	        checker (callable): The checker method that returns True if a
216	            prerequisite is meet, False otherwise.
217	        msg_tmpl (str): The message template with two variables.
218	
219	    Returns:
220	        decorator: A specific decorator.
221	    &quot;&quot;&quot;
222	
223	    def wrap(func):
224	
225	        @functools.wraps(func)
226	        def wrapped_func(*args, **kwargs):
227	            requirements = [prerequisites] if isinstance(
228	                prerequisites, str) else prerequisites
229	            missing = []
230	            for item in requirements:
231	                if not checker(item):
232	                    missing.append(item)
233	            if missing:
234	                print(msg_tmpl.format(&#x27;, &#x27;.join(missing), func.__name__))
235	                raise RuntimeError(&#x27;Prerequisites not meet.&#x27;)
236	            else:
237	                return func(*args, **kwargs)
238	
239	        return wrapped_func
240	
241	    return wrap
242	
243	
244	def _check_py_package(package):
245	    try:
246	        import_module(package)
247	    except ImportError:
248	        return False
249	    else:
250	        return True
251	
252	
253	def _check_executable(cmd):
254	    if subprocess.call(f&#x27;which {cmd}&#x27;, shell=True) != 0:
255	        return False
256	    else:
257	        return True
258	
259	
260	def requires_package(prerequisites):
261	    &quot;&quot;&quot;A decorator to check if some python packages are installed.
262	
263	    Example:
264	        &gt;&gt;&gt; @requires_package(&#x27;numpy&#x27;)
265	        &gt;&gt;&gt; func(arg1, args):
266	        &gt;&gt;&gt;     return numpy.zeros(1)
267	        array([0.])
268	        &gt;&gt;&gt; @requires_package([&#x27;numpy&#x27;, &#x27;non_package&#x27;])
269	        &gt;&gt;&gt; func(arg1, args):
270	        &gt;&gt;&gt;     return numpy.zeros(1)
271	        ImportError
272	    &quot;&quot;&quot;
273	    return check_prerequisites(prerequisites, checker=_check_py_package)
274	
275	
276	def requires_executable(prerequisites):
277	    &quot;&quot;&quot;A decorator to check if some executable files are installed.
278	
279	    Example:
280	        &gt;&gt;&gt; @requires_executable(&#x27;ffmpeg&#x27;)
281	        &gt;&gt;&gt; func(arg1, args):
282	        &gt;&gt;&gt;     print(1)
283	        1
284	    &quot;&quot;&quot;
285	    return check_prerequisites(prerequisites, checker=_check_executable)
286	
287	
288	def deprecated_api_warning(name_dict, cls_name=None):
289	    &quot;&quot;&quot;A decorator to check if some arguments are deprecate and try to replace
290	    deprecate src_arg_name to dst_arg_name.
291	
292	    Args:
293	        name_dict(dict):
294	            key (str): Deprecate argument names.
295	            val (str): Expected argument names.
296	
297	    Returns:
298	        func: New function.
299	    &quot;&quot;&quot;
300	
301	    def api_warning_wrapper(old_func):
302	
303	        @functools.wraps(old_func)
304	        def new_func(*args, **kwargs):
305	            # get the arg spec of the decorated method
306	            args_info = getfullargspec(old_func)
307	            # get name of the function
308	            func_name = old_func.__name__
309	            if cls_name is not None:
310	                func_name = f&#x27;{cls_name}.{func_name}&#x27;
311	            if args:
312	                arg_names = args_info.args[:len(args)]
313	                for src_arg_name, dst_arg_name in name_dict.items():
</pre>
</div>


</div>
</div>

<div id="issue-109">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/version_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/version_utils.py</a><br>
    <b>Line number: </b>3<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import os
3	import subprocess
4	import warnings
5	
6	from packaging.version import parse
7	
8	
9	def digit_version(version_str: str, length: int = 4):
10	    &quot;&quot;&quot;Convert a version string into a tuple of integers.
11	
12	    This method is usually used for comparing two versions. For pre-release
13	    versions: alpha &lt; beta &lt; rc.
14	
15	    Args:
16	        version_str (str): The version string.
17	        length (int): The maximum number of version levels. Default: 4.
18	
19	    Returns:
20	        tuple[int]: The version info in digits (integers).
21	    &quot;&quot;&quot;
22	    assert &#x27;parrots&#x27; not in version_str
23	    version = parse(version_str)
24	    assert version.release, f&#x27;failed to parse version {version_str}&#x27;
25	    release = list(version.release)
26	    release = release[:length]
27	    if len(release) &lt; length:
28	        release = release + [0] * (length - len(release))
29	    if version.is_prerelease:
30	        mapping = {&#x27;a&#x27;: -3, &#x27;b&#x27;: -2, &#x27;rc&#x27;: -1}
31	        val = -4
32	        # version.pre can be None
33	        if version.pre:
34	            if version.pre[0] not in mapping:
35	                warnings.warn(f&#x27;unknown prerelease version {version.pre[0]}, &#x27;
36	                              &#x27;version checking may go wrong&#x27;)
37	            else:
38	                val = mapping[version.pre[0]]
39	            release.extend([val, version.pre[-1]])
40	        else:
41	            release.extend([val, 0])
42	
43	    elif version.is_postrelease:
44	        release.extend([1, version.post])
45	    else:
46	        release.extend([0, 0])
47	    return tuple(release)
48	
49	
50	def _minimal_ext_cmd(cmd):
51	    # construct minimal environment
52	    env = {}
53	    for k in [&#x27;SYSTEMROOT&#x27;, &#x27;PATH&#x27;, &#x27;HOME&#x27;]:
54	        v = os.environ.get(k)
55	        if v is not None:
56	            env[k] = v
57	    # LANGUAGE is used on win32
58	    env[&#x27;LANGUAGE&#x27;] = &#x27;C&#x27;
59	    env[&#x27;LANG&#x27;] = &#x27;C&#x27;
60	    env[&#x27;LC_ALL&#x27;] = &#x27;C&#x27;
61	    out = subprocess.Popen(
62	        cmd, stdout=subprocess.PIPE, env=env).communicate()[0]
63	    return out
64	
65	
66	def get_git_hash(fallback=&#x27;unknown&#x27;, digits=None):
67	    &quot;&quot;&quot;Get the git hash of the current repo.
68	
69	    Args:
70	        fallback (str, optional): The fallback string when git hash is
71	            unavailable. Defaults to &#x27;unknown&#x27;.
72	        digits (int, optional): kept digits of the hash. Defaults to None,
73	            meaning all digits are kept.
74	
75	    Returns:
76	        str: Git commit hash.
77	    &quot;&quot;&quot;
78	
79	    if digits is not None and not isinstance(digits, int):
80	        raise TypeError(&#x27;digits must be None or an integer&#x27;)
81	
82	    try:
83	        out = _minimal_ext_cmd([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
84	        sha = out.strip().decode(&#x27;ascii&#x27;)
85	        if digits is not None:
86	            sha = sha[:digits]
87	    except OSError:
88	        sha = fallback
89	
90	    return sha
</pre>
</div>


</div>
</div>

<div id="issue-110">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/version_utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/utils/version_utils.py</a><br>
    <b>Line number: </b>61<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import os
3	import subprocess
4	import warnings
5	
6	from packaging.version import parse
7	
8	
9	def digit_version(version_str: str, length: int = 4):
10	    &quot;&quot;&quot;Convert a version string into a tuple of integers.
11	
12	    This method is usually used for comparing two versions. For pre-release
13	    versions: alpha &lt; beta &lt; rc.
14	
15	    Args:
16	        version_str (str): The version string.
17	        length (int): The maximum number of version levels. Default: 4.
18	
19	    Returns:
20	        tuple[int]: The version info in digits (integers).
21	    &quot;&quot;&quot;
22	    assert &#x27;parrots&#x27; not in version_str
23	    version = parse(version_str)
24	    assert version.release, f&#x27;failed to parse version {version_str}&#x27;
25	    release = list(version.release)
26	    release = release[:length]
27	    if len(release) &lt; length:
28	        release = release + [0] * (length - len(release))
29	    if version.is_prerelease:
30	        mapping = {&#x27;a&#x27;: -3, &#x27;b&#x27;: -2, &#x27;rc&#x27;: -1}
31	        val = -4
32	        # version.pre can be None
33	        if version.pre:
34	            if version.pre[0] not in mapping:
35	                warnings.warn(f&#x27;unknown prerelease version {version.pre[0]}, &#x27;
36	                              &#x27;version checking may go wrong&#x27;)
37	            else:
38	                val = mapping[version.pre[0]]
39	            release.extend([val, version.pre[-1]])
40	        else:
41	            release.extend([val, 0])
42	
43	    elif version.is_postrelease:
44	        release.extend([1, version.post])
45	    else:
46	        release.extend([0, 0])
47	    return tuple(release)
48	
49	
50	def _minimal_ext_cmd(cmd):
51	    # construct minimal environment
52	    env = {}
53	    for k in [&#x27;SYSTEMROOT&#x27;, &#x27;PATH&#x27;, &#x27;HOME&#x27;]:
54	        v = os.environ.get(k)
55	        if v is not None:
56	            env[k] = v
57	    # LANGUAGE is used on win32
58	    env[&#x27;LANGUAGE&#x27;] = &#x27;C&#x27;
59	    env[&#x27;LANG&#x27;] = &#x27;C&#x27;
60	    env[&#x27;LC_ALL&#x27;] = &#x27;C&#x27;
61	    out = subprocess.Popen(
62	        cmd, stdout=subprocess.PIPE, env=env).communicate()[0]
63	    return out
64	
65	
66	def get_git_hash(fallback=&#x27;unknown&#x27;, digits=None):
67	    &quot;&quot;&quot;Get the git hash of the current repo.
68	
69	    Args:
70	        fallback (str, optional): The fallback string when git hash is
71	            unavailable. Defaults to &#x27;unknown&#x27;.
72	        digits (int, optional): kept digits of the hash. Defaults to None,
73	            meaning all digits are kept.
74	
75	    Returns:
76	        str: Git commit hash.
77	    &quot;&quot;&quot;
78	
79	    if digits is not None and not isinstance(digits, int):
80	        raise TypeError(&#x27;digits must be None or an integer&#x27;)
81	
82	    try:
83	        out = _minimal_ext_cmd([&#x27;git&#x27;, &#x27;rev-parse&#x27;, &#x27;HEAD&#x27;])
84	        sha = out.strip().decode(&#x27;ascii&#x27;)
85	        if digits is not None:
86	            sha = sha[:digits]
87	    except OSError:
88	        sha = fallback
89	
90	    return sha
</pre>
</div>


</div>
</div>

<div id="issue-111">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/video/processing.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/video/processing.py</a><br>
    <b>Line number: </b>4<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import os
3	import os.path as osp
4	import subprocess
5	import tempfile
6	
7	from custom_mmpkg.custom_mmcv.utils import requires_executable
8	
9	
10	@requires_executable(&#x27;ffmpeg&#x27;)
11	def convert_video(in_file,
12	                  out_file,
13	                  print_cmd=False,
14	                  pre_options=&#x27;&#x27;,
15	                  **kwargs):
16	    &quot;&quot;&quot;Convert a video with ffmpeg.
17	
18	    This provides a general api to ffmpeg, the executed command is::
19	
20	        `ffmpeg -y &lt;pre_options&gt; -i &lt;in_file&gt; &lt;options&gt; &lt;out_file&gt;`
21	
22	    Options(kwargs) are mapped to ffmpeg commands with the following rules:
23	
24	    - key=val: &quot;-key val&quot;
25	    - key=True: &quot;-key&quot;
26	    - key=False: &quot;&quot;
27	
28	    Args:
29	        in_file (str): Input video filename.
30	        out_file (str): Output video filename.
31	        pre_options (str): Options appears before &quot;-i &lt;in_file&gt;&quot;.
32	        print_cmd (bool): Whether to print the final ffmpeg command.
33	    &quot;&quot;&quot;
34	    options = []
35	    for k, v in kwargs.items():
36	        if isinstance(v, bool):
37	            if v:
38	                options.append(f&#x27;-{k}&#x27;)
39	        elif k == &#x27;log_level&#x27;:
40	            assert v in [
41	                &#x27;quiet&#x27;, &#x27;panic&#x27;, &#x27;fatal&#x27;, &#x27;error&#x27;, &#x27;warning&#x27;, &#x27;info&#x27;,
42	                &#x27;verbose&#x27;, &#x27;debug&#x27;, &#x27;trace&#x27;
43	            ]
44	            options.append(f&#x27;-loglevel {v}&#x27;)
45	        else:
46	            options.append(f&#x27;-{k} {v}&#x27;)
47	    cmd = f&#x27;ffmpeg -y {pre_options} -i {in_file} {&quot; &quot;.join(options)} &#x27; \
48	          f&#x27;{out_file}&#x27;
49	    if print_cmd:
50	        print(cmd)
51	    subprocess.call(cmd, shell=True)
52	
53	
54	@requires_executable(&#x27;ffmpeg&#x27;)
55	def resize_video(in_file,
56	                 out_file,
57	                 size=None,
58	                 ratio=None,
59	                 keep_ar=False,
60	                 log_level=&#x27;info&#x27;,
61	                 print_cmd=False):
62	    &quot;&quot;&quot;Resize a video.
63	
64	    Args:
65	        in_file (str): Input video filename.
66	        out_file (str): Output video filename.
67	        size (tuple): Expected size (w, h), eg, (320, 240) or (320, -1).
68	        ratio (tuple or float): Expected resize ratio, (2, 0.5) means
69	            (w*2, h*0.5).
70	        keep_ar (bool): Whether to keep original aspect ratio.
71	        log_level (str): Logging level of ffmpeg.
72	        print_cmd (bool): Whether to print the final ffmpeg command.
73	    &quot;&quot;&quot;
74	    if size is None and ratio is None:
75	        raise ValueError(&#x27;expected size or ratio must be specified&#x27;)
76	    if size is not None and ratio is not None:
77	        raise ValueError(&#x27;size and ratio cannot be specified at the same time&#x27;)
78	    options = {&#x27;log_level&#x27;: log_level}
79	    if size:
80	        if not keep_ar:
81	            options[&#x27;vf&#x27;] = f&#x27;scale={size[0]}:{size[1]}&#x27;
82	        else:
83	            options[&#x27;vf&#x27;] = f&#x27;scale=w={size[0]}:h={size[1]}:&#x27; \
84	                            &#x27;force_original_aspect_ratio=decrease&#x27;
85	    else:
86	        if not isinstance(ratio, tuple):
87	            ratio = (ratio, ratio)
88	        options[&#x27;vf&#x27;] = f&#x27;scale=&quot;trunc(iw*{ratio[0]}):trunc(ih*{ratio[1]})&quot;&#x27;
89	    convert_video(in_file, out_file, print_cmd, **options)
90	
91	
92	@requires_executable(&#x27;ffmpeg&#x27;)
93	def cut_video(in_file,
94	              out_file,
95	              start=None,
96	              end=None,
97	              vcodec=None,
98	              acodec=None,
99	              log_level=&#x27;info&#x27;,
100	              print_cmd=False):
101	    &quot;&quot;&quot;Cut a clip from a video.
102	
103	    Args:
104	        in_file (str): Input video filename.
105	        out_file (str): Output video filename.
106	        start (None or float): Start time (in seconds).
107	        end (None or float): End time (in seconds).
108	        vcodec (None or str): Output video codec, None for unchanged.
109	        acodec (None or str): Output audio codec, None for unchanged.
110	        log_level (str): Logging level of ffmpeg.
111	        print_cmd (bool): Whether to print the final ffmpeg command.
112	    &quot;&quot;&quot;
113	    options = {&#x27;log_level&#x27;: log_level}
114	    if vcodec is None:
115	        options[&#x27;vcodec&#x27;] = &#x27;copy&#x27;
116	    if acodec is None:
117	        options[&#x27;acodec&#x27;] = &#x27;copy&#x27;
118	    if start:
119	        options[&#x27;ss&#x27;] = start
120	    else:
</pre>
</div>


</div>
</div>

<div id="issue-112">
<div class="issue-block issue-sev-high">
    <b>subprocess_popen_with_shell_equals_true: </b> subprocess call with shell=True identified, security issue.<br>
    <b>Test ID:</b> B602<br>
    <b>Severity: </b>HIGH<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/video/processing.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmcv/video/processing.py</a><br>
    <b>Line number: </b>51<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b602_subprocess_popen_with_shell_equals_true.html</a><br>

<div class="code">
<pre>
1	# Copyright (c) OpenMMLab. All rights reserved.
2	import os
3	import os.path as osp
4	import subprocess
5	import tempfile
6	
7	from custom_mmpkg.custom_mmcv.utils import requires_executable
8	
9	
10	@requires_executable(&#x27;ffmpeg&#x27;)
11	def convert_video(in_file,
12	                  out_file,
13	                  print_cmd=False,
14	                  pre_options=&#x27;&#x27;,
15	                  **kwargs):
16	    &quot;&quot;&quot;Convert a video with ffmpeg.
17	
18	    This provides a general api to ffmpeg, the executed command is::
19	
20	        `ffmpeg -y &lt;pre_options&gt; -i &lt;in_file&gt; &lt;options&gt; &lt;out_file&gt;`
21	
22	    Options(kwargs) are mapped to ffmpeg commands with the following rules:
23	
24	    - key=val: &quot;-key val&quot;
25	    - key=True: &quot;-key&quot;
26	    - key=False: &quot;&quot;
27	
28	    Args:
29	        in_file (str): Input video filename.
30	        out_file (str): Output video filename.
31	        pre_options (str): Options appears before &quot;-i &lt;in_file&gt;&quot;.
32	        print_cmd (bool): Whether to print the final ffmpeg command.
33	    &quot;&quot;&quot;
34	    options = []
35	    for k, v in kwargs.items():
36	        if isinstance(v, bool):
37	            if v:
38	                options.append(f&#x27;-{k}&#x27;)
39	        elif k == &#x27;log_level&#x27;:
40	            assert v in [
41	                &#x27;quiet&#x27;, &#x27;panic&#x27;, &#x27;fatal&#x27;, &#x27;error&#x27;, &#x27;warning&#x27;, &#x27;info&#x27;,
42	                &#x27;verbose&#x27;, &#x27;debug&#x27;, &#x27;trace&#x27;
43	            ]
44	            options.append(f&#x27;-loglevel {v}&#x27;)
45	        else:
46	            options.append(f&#x27;-{k} {v}&#x27;)
47	    cmd = f&#x27;ffmpeg -y {pre_options} -i {in_file} {&quot; &quot;.join(options)} &#x27; \
48	          f&#x27;{out_file}&#x27;
49	    if print_cmd:
50	        print(cmd)
51	    subprocess.call(cmd, shell=True)
52	
53	
54	@requires_executable(&#x27;ffmpeg&#x27;)
55	def resize_video(in_file,
56	                 out_file,
57	                 size=None,
58	                 ratio=None,
59	                 keep_ar=False,
60	                 log_level=&#x27;info&#x27;,
61	                 print_cmd=False):
62	    &quot;&quot;&quot;Resize a video.
63	
64	    Args:
65	        in_file (str): Input video filename.
66	        out_file (str): Output video filename.
67	        size (tuple): Expected size (w, h), eg, (320, 240) or (320, -1).
68	        ratio (tuple or float): Expected resize ratio, (2, 0.5) means
69	            (w*2, h*0.5).
70	        keep_ar (bool): Whether to keep original aspect ratio.
71	        log_level (str): Logging level of ffmpeg.
72	        print_cmd (bool): Whether to print the final ffmpeg command.
73	    &quot;&quot;&quot;
74	    if size is None and ratio is None:
75	        raise ValueError(&#x27;expected size or ratio must be specified&#x27;)
76	    if size is not None and ratio is not None:
77	        raise ValueError(&#x27;size and ratio cannot be specified at the same time&#x27;)
78	    options = {&#x27;log_level&#x27;: log_level}
79	    if size:
80	        if not keep_ar:
81	            options[&#x27;vf&#x27;] = f&#x27;scale={size[0]}:{size[1]}&#x27;
82	        else:
83	            options[&#x27;vf&#x27;] = f&#x27;scale=w={size[0]}:h={size[1]}:&#x27; \
84	                            &#x27;force_original_aspect_ratio=decrease&#x27;
85	    else:
86	        if not isinstance(ratio, tuple):
87	            ratio = (ratio, ratio)
88	        options[&#x27;vf&#x27;] = f&#x27;scale=&quot;trunc(iw*{ratio[0]}):trunc(ih*{ratio[1]})&quot;&#x27;
89	    convert_video(in_file, out_file, print_cmd, **options)
90	
91	
92	@requires_executable(&#x27;ffmpeg&#x27;)
93	def cut_video(in_file,
94	              out_file,
95	              start=None,
96	              end=None,
97	              vcodec=None,
98	              acodec=None,
99	              log_level=&#x27;info&#x27;,
100	              print_cmd=False):
101	    &quot;&quot;&quot;Cut a clip from a video.
102	
103	    Args:
104	        in_file (str): Input video filename.
105	        out_file (str): Output video filename.
106	        start (None or float): Start time (in seconds).
107	        end (None or float): End time (in seconds).
108	        vcodec (None or str): Output video codec, None for unchanged.
109	        acodec (None or str): Output audio codec, None for unchanged.
110	        log_level (str): Logging level of ffmpeg.
111	        print_cmd (bool): Whether to print the final ffmpeg command.
112	    &quot;&quot;&quot;
113	    options = {&#x27;log_level&#x27;: log_level}
114	    if vcodec is None:
115	        options[&#x27;vcodec&#x27;] = &#x27;copy&#x27;
116	    if acodec is None:
117	        options[&#x27;acodec&#x27;] = &#x27;copy&#x27;
118	    if start:
119	        options[&#x27;ss&#x27;] = start
120	    else:
</pre>
</div>


</div>
</div>

<div id="issue-113">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/apis/test.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/apis/test.py</a><br>
    <b>Line number: </b>2<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	import os.path as osp
2	import pickle
3	import shutil
4	import tempfile
5	
6	import custom_mmpkg.custom_mmcv as mmcv
7	import numpy as np
8	import torch
9	import torch.distributed as dist
10	from custom_mmpkg.custom_mmcv.image import tensor2imgs
11	from custom_mmpkg.custom_mmcv.runner import get_dist_info
12	
13	
14	def np2tmp(array, temp_file_name=None):
15	    &quot;&quot;&quot;Save ndarray to local numpy file.
16	
17	    Args:
18	        array (ndarray): Ndarray to save.
19	        temp_file_name (str): Numpy file name. If &#x27;temp_file_name=None&#x27;, this
20	            function will generate a file name with tempfile.NamedTemporaryFile
21	            to save ndarray. Default: None.
22	
23	    Returns:
24	        str: The numpy file name.
25	    &quot;&quot;&quot;
26	
27	    if temp_file_name is None:
28	        temp_file_name = tempfile.NamedTemporaryFile(
29	            suffix=&#x27;.npy&#x27;, delete=False).name
30	    np.save(temp_file_name, array)
31	    return temp_file_name
32	
33	
34	def single_gpu_test(model,
35	                    data_loader,
36	                    show=False,
37	                    out_dir=None,
38	                    efficient_test=False,
39	                    opacity=0.5):
40	    &quot;&quot;&quot;Test with single GPU.
41	
42	    Args:
43	        model (nn.Module): Model to be tested.
44	        data_loader (utils.data.Dataloader): Pytorch data loader.
45	        show (bool): Whether show results during inference. Default: False.
46	        out_dir (str, optional): If specified, the results will be dumped into
47	            the directory to save output results.
48	        efficient_test (bool): Whether save the results as local numpy files to
49	            save CPU memory during evaluation. Default: False.
50	        opacity(float): Opacity of painted segmentation map.
51	            Default 0.5.
52	            Must be in (0, 1] range.
53	    Returns:
54	        list: The prediction results.
55	    &quot;&quot;&quot;
56	
57	    model.eval()
58	    results = []
59	    dataset = data_loader.dataset
60	    prog_bar = mmcv.ProgressBar(len(dataset))
61	    for i, data in enumerate(data_loader):
62	        with torch.no_grad():
63	            result = model(return_loss=False, **data)
64	
65	        if show or out_dir:
66	            img_tensor = data[&#x27;img&#x27;][0]
67	            img_metas = data[&#x27;img_metas&#x27;][0].data[0]
68	            imgs = tensor2imgs(img_tensor, **img_metas[0][&#x27;img_norm_cfg&#x27;])
69	            assert len(imgs) == len(img_metas)
70	
71	            for img, img_meta in zip(imgs, img_metas):
72	                h, w, _ = img_meta[&#x27;img_shape&#x27;]
73	                img_show = img[:h, :w, :]
74	
75	                ori_h, ori_w = img_meta[&#x27;ori_shape&#x27;][:-1]
76	                img_show = mmcv.imresize(img_show, (ori_w, ori_h))
77	
78	                if out_dir:
79	                    out_file = osp.join(out_dir, img_meta[&#x27;ori_filename&#x27;])
80	                else:
81	                    out_file = None
82	
83	                model.module.show_result(
84	                    img_show,
85	                    result,
86	                    palette=dataset.PALETTE,
87	                    show=show,
88	                    out_file=out_file,
89	                    opacity=opacity)
90	
91	        if isinstance(result, list):
92	            if efficient_test:
93	                result = [np2tmp(_) for _ in result]
94	            results.extend(result)
95	        else:
96	            if efficient_test:
97	                result = np2tmp(result)
98	            results.append(result)
99	
100	        batch_size = len(result)
101	        for _ in range(batch_size):
102	            prog_bar.update()
103	    return results
104	
105	
106	def multi_gpu_test(model,
107	                   data_loader,
108	                   tmpdir=None,
109	                   gpu_collect=False,
110	                   efficient_test=False):
111	    &quot;&quot;&quot;Test model with multiple gpus.
112	
113	    This method tests model with multiple gpus and collects the results
114	    under two different modes: gpu and cpu modes. By setting &#x27;gpu_collect=True&#x27;
115	    it encodes results to gpu tensors and use gpu communication for results
116	    collection. On cpu mode it saves the results on different gpus to &#x27;tmpdir&#x27;
117	    and collects them by the rank 0 worker.
118	
119	    Args:
120	        model (nn.Module): Model to be tested.
</pre>
</div>


</div>
</div>

<div id="issue-114">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/apis/test.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/apis/test.py</a><br>
    <b>Line number: </b>231<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
171	        dir_tensor = torch.full((MAX_LEN, ),
172	                                32,
173	                                dtype=torch.uint8,
174	                                device=&#x27;cuda&#x27;)
175	        if rank == 0:
176	            tmpdir = tempfile.mkdtemp()
177	            tmpdir = torch.tensor(
178	                bytearray(tmpdir.encode()), dtype=torch.uint8, device=&#x27;cuda&#x27;)
179	            dir_tensor[:len(tmpdir)] = tmpdir
180	        dist.broadcast(dir_tensor, 0)
181	        tmpdir = dir_tensor.cpu().numpy().tobytes().decode().rstrip()
182	    else:
183	        mmcv.mkdir_or_exist(tmpdir)
184	    # dump the part result to the dir
185	    mmcv.dump(result_part, osp.join(tmpdir, &#x27;part_{}.pkl&#x27;.format(rank)))
186	    dist.barrier()
187	    # collect all parts
188	    if rank != 0:
189	        return None
190	    else:
191	        # load results of all parts from tmp dir
192	        part_list = []
193	        for i in range(world_size):
194	            part_file = osp.join(tmpdir, &#x27;part_{}.pkl&#x27;.format(i))
195	            part_list.append(mmcv.load(part_file))
196	        # sort the results
197	        ordered_results = []
198	        for res in zip(*part_list):
199	            ordered_results.extend(list(res))
200	        # the dataloader may pad some samples
201	        ordered_results = ordered_results[:size]
202	        # remove tmp dir
203	        shutil.rmtree(tmpdir)
204	        return ordered_results
205	
206	
207	def collect_results_gpu(result_part, size):
208	    &quot;&quot;&quot;Collect results with GPU.&quot;&quot;&quot;
209	    rank, world_size = get_dist_info()
210	    # dump result part to tensor with pickle
211	    part_tensor = torch.tensor(
212	        bytearray(pickle.dumps(result_part)), dtype=torch.uint8, device=&#x27;cuda&#x27;)
213	    # gather all result part tensor shape
214	    shape_tensor = torch.tensor(part_tensor.shape, device=&#x27;cuda&#x27;)
215	    shape_list = [shape_tensor.clone() for _ in range(world_size)]
216	    dist.all_gather(shape_list, shape_tensor)
217	    # padding result part tensor to max length
218	    shape_max = torch.tensor(shape_list).max()
219	    part_send = torch.zeros(shape_max, dtype=torch.uint8, device=&#x27;cuda&#x27;)
220	    part_send[:shape_tensor[0]] = part_tensor
221	    part_recv_list = [
222	        part_tensor.new_zeros(shape_max) for _ in range(world_size)
223	    ]
224	    # gather all result part
225	    dist.all_gather(part_recv_list, part_send)
226	
227	    if rank == 0:
228	        part_list = []
229	        for recv, shape in zip(part_recv_list, shape_list):
230	            part_list.append(
231	                pickle.loads(recv[:shape[0]].cpu().numpy().tobytes()))
232	        # sort the results
233	        ordered_results = []
234	        for res in zip(*part_list):
235	            ordered_results.extend(list(res))
236	        # the dataloader may pad some samples
237	        ordered_results = ordered_results[:size]
238	        return ordered_results
</pre>
</div>


</div>
</div>

<div id="issue-115">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Use of possibly insecure function - consider using safer ast.literal_eval.<br>
    <b>Test ID:</b> B307<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/core/evaluation/class_names.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/core/evaluation/class_names.py</a><br>
    <b>Line number: </b>130<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval</a><br>

<div class="code">
<pre>
70	            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],
71	            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],
72	            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],
73	            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],
74	            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],
75	            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],
76	            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],
77	            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],
78	            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],
79	            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],
80	            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],
81	            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],
82	            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],
83	            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],
84	            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],
85	            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],
86	            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],
87	            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],
88	            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],
89	            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],
90	            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],
91	            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],
92	            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],
93	            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],
94	            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],
95	            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],
96	            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],
97	            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],
98	            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],
99	            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],
100	            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],
101	            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],
102	            [102, 255, 0], [92, 0, 255]]
103	
104	
105	def voc_palette():
106	    &quot;&quot;&quot;Pascal VOC palette for external use.&quot;&quot;&quot;
107	    return [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],
108	            [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0],
109	            [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128],
110	            [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0],
111	            [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]]
112	
113	
114	dataset_aliases = {
115	    &#x27;cityscapes&#x27;: [&#x27;cityscapes&#x27;],
116	    &#x27;ade&#x27;: [&#x27;ade&#x27;, &#x27;ade20k&#x27;],
117	    &#x27;voc&#x27;: [&#x27;voc&#x27;, &#x27;pascal_voc&#x27;, &#x27;voc12&#x27;, &#x27;voc12aug&#x27;]
118	}
119	
120	
121	def get_classes(dataset):
122	    &quot;&quot;&quot;Get class names of a dataset.&quot;&quot;&quot;
123	    alias2name = {}
124	    for name, aliases in dataset_aliases.items():
125	        for alias in aliases:
126	            alias2name[alias] = name
127	
128	    if mmcv.is_str(dataset):
129	        if dataset in alias2name:
130	            labels = eval(alias2name[dataset] + &#x27;_classes()&#x27;)
131	        else:
132	            raise ValueError(f&#x27;Unrecognized dataset: {dataset}&#x27;)
133	    else:
134	        raise TypeError(f&#x27;dataset must a str, but got {type(dataset)}&#x27;)
135	    return labels
136	
137	
138	def get_palette(dataset):
139	    &quot;&quot;&quot;Get class palette (RGB) of a dataset.&quot;&quot;&quot;
140	    alias2name = {}
141	    for name, aliases in dataset_aliases.items():
142	        for alias in aliases:
143	            alias2name[alias] = name
144	
145	    if mmcv.is_str(dataset):
146	        if dataset in alias2name:
147	            labels = eval(alias2name[dataset] + &#x27;_palette()&#x27;)
148	        else:
149	            raise ValueError(f&#x27;Unrecognized dataset: {dataset}&#x27;)
150	    else:
151	        raise TypeError(f&#x27;dataset must a str, but got {type(dataset)}&#x27;)
152	    return labels
</pre>
</div>


</div>
</div>

<div id="issue-116">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Use of possibly insecure function - consider using safer ast.literal_eval.<br>
    <b>Test ID:</b> B307<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/core/evaluation/class_names.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_mmpkg/custom_mmseg/core/evaluation/class_names.py</a><br>
    <b>Line number: </b>147<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b307-eval</a><br>

<div class="code">
<pre>
87	            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],
88	            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],
89	            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],
90	            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],
91	            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],
92	            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],
93	            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],
94	            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],
95	            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],
96	            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],
97	            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],
98	            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],
99	            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],
100	            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],
101	            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],
102	            [102, 255, 0], [92, 0, 255]]
103	
104	
105	def voc_palette():
106	    &quot;&quot;&quot;Pascal VOC palette for external use.&quot;&quot;&quot;
107	    return [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],
108	            [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0],
109	            [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128],
110	            [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0],
111	            [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]]
112	
113	
114	dataset_aliases = {
115	    &#x27;cityscapes&#x27;: [&#x27;cityscapes&#x27;],
116	    &#x27;ade&#x27;: [&#x27;ade&#x27;, &#x27;ade20k&#x27;],
117	    &#x27;voc&#x27;: [&#x27;voc&#x27;, &#x27;pascal_voc&#x27;, &#x27;voc12&#x27;, &#x27;voc12aug&#x27;]
118	}
119	
120	
121	def get_classes(dataset):
122	    &quot;&quot;&quot;Get class names of a dataset.&quot;&quot;&quot;
123	    alias2name = {}
124	    for name, aliases in dataset_aliases.items():
125	        for alias in aliases:
126	            alias2name[alias] = name
127	
128	    if mmcv.is_str(dataset):
129	        if dataset in alias2name:
130	            labels = eval(alias2name[dataset] + &#x27;_classes()&#x27;)
131	        else:
132	            raise ValueError(f&#x27;Unrecognized dataset: {dataset}&#x27;)
133	    else:
134	        raise TypeError(f&#x27;dataset must a str, but got {type(dataset)}&#x27;)
135	    return labels
136	
137	
138	def get_palette(dataset):
139	    &quot;&quot;&quot;Get class palette (RGB) of a dataset.&quot;&quot;&quot;
140	    alias2name = {}
141	    for name, aliases in dataset_aliases.items():
142	        for alias in aliases:
143	            alias2name[alias] = name
144	
145	    if mmcv.is_str(dataset):
146	        if dataset in alias2name:
147	            labels = eval(alias2name[dataset] + &#x27;_palette()&#x27;)
148	        else:
149	            raise ValueError(f&#x27;Unrecognized dataset: {dataset}&#x27;)
150	    else:
151	        raise TypeError(f&#x27;dataset must a str, but got {type(dataset)}&#x27;)
152	    return labels
</pre>
</div>


</div>
</div>

<div id="issue-117">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_oneformer/evaluation/coco_evaluator.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_oneformer/evaluation/coco_evaluator.py</a><br>
    <b>Line number: </b>14<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# ------------------------------------------------------------------------------
2	# Reference: https://github.com/facebookresearch/detectron2/blob/main/detectron2/evaluation/coco_evaluation.py
3	# Modified by Jitesh Jain (https://github.com/praeclarumjj3)
4	# ------------------------------------------------------------------------------
5	
6	import contextlib
7	import copy
8	import io
9	import itertools
10	import json
11	import logging
12	import numpy as np
13	import os
14	import pickle
15	from collections import OrderedDict
16	import custom_pycocotools.mask as mask_util
17	import torch
18	from custom_pycocotools.coco import COCO
19	from custom_pycocotools.cocoeval import COCOeval
20	from tabulate import tabulate
21	
22	import custom_detectron2.utils.comm as comm
23	from custom_detectron2.config import CfgNode
24	from custom_detectron2.data import MetadataCatalog
25	from custom_detectron2.data.datasets.coco import convert_to_coco_json
26	from custom_detectron2.structures import Boxes, BoxMode, pairwise_iou
27	from custom_detectron2.utils.file_io import PathManager
28	from custom_detectron2.utils.logger import create_small_table
29	
30	from .evaluator import DatasetEvaluator
31	
32	try:
33	    from custom_detectron2.evaluation.fast_eval_api import COCOeval_opt
34	except ImportError:
35	    COCOeval_opt = COCOeval
36	
37	
38	class COCOEvaluator(DatasetEvaluator):
39	    &quot;&quot;&quot;
40	    Evaluate AP for instance detection/segmentation, AP
41	    for keypoint detection outputs using COCO&#x27;s metrics.
42	    See http://cocodataset.org/#detection-eval and
43	    http://cocodataset.org/#keypoints-eval to understand its metrics.
44	    The metrics range from 0 to 100 (instead of 0 to 1), where a -1 or NaN means
45	    the metric cannot be computed (e.g. due to no predictions made).
46	
47	    In addition to COCO, this evaluator is able to support any bounding box detection,
48	    instance segmentation, or keypoint detection dataset.
49	    &quot;&quot;&quot;
50	
51	    def __init__(
52	        self,
53	        dataset_name,
54	        tasks=None,
55	        distributed=True,
56	        output_dir=None,
57	        *,
58	        max_dets_per_image=None,
59	        use_fast_impl=True,
60	        kpt_oks_sigmas=(),
61	        allow_cached_coco=True,
62	    ):
63	        &quot;&quot;&quot;
64	        Args:
65	            dataset_name (str): name of the dataset to be evaluated.
66	                It must have either the following corresponding metadata:
67	
68	                    &quot;json_file&quot;: the path to the COCO format annotation
69	
70	                Or it must be in detectron2&#x27;s standard dataset format
71	                so it can be converted to COCO format automatically.
72	            tasks (tuple[str]): tasks that can be evaluated under the given
73	                configuration. A task is one of &quot;bbox&quot;, &quot;segm&quot;, &quot;keypoints&quot;.
74	                By default, will infer this automatically from predictions.
75	            distributed (True): if True, will collect results from all ranks and run evaluation
76	                in the main process.
77	                Otherwise, will only evaluate the results in the current process.
78	            output_dir (str): optional, an output directory to dump all
79	                results predicted on the dataset. The dump contains two files:
80	
81	                1. &quot;instances_predictions.pth&quot; a file that can be loaded with `torch.load` and
82	                   contains all the results in the format they are produced by the model.
83	                2. &quot;coco_instances_results.json&quot; a json file in COCO&#x27;s result format.
84	            max_dets_per_image (int): limit on the maximum number of detections per image.
85	                By default in COCO, this limit is to 100, but this can be customized
86	                to be greater, as is needed in evaluation metrics AP fixed and AP pool
87	                (see https://arxiv.org/pdf/2102.01066.pdf)
88	                This doesn&#x27;t affect keypoint evaluation.
89	            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.
90	                Although the results should be very close to the official implementation in COCO
91	                API, it is still recommended to compute results with the official API for use in
92	                papers. The faster implementation also uses more RAM.
93	            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.
94	                See http://cocodataset.org/#keypoints-eval
95	                When empty, it will use the defaults in COCO.
96	                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.
97	            allow_cached_coco (bool): Whether to use cached coco json from previous validation
98	                runs. You should set this to False if you need to use different validation data.
99	                Defaults to True.
100	        &quot;&quot;&quot;
101	        self._logger = logging.getLogger(__name__)
102	        self._distributed = distributed
103	        self._output_dir = output_dir
104	
105	        if use_fast_impl and (COCOeval_opt is COCOeval):
106	            self._logger.info(&quot;Fast COCO eval is not built. Falling back to official COCO eval.&quot;)
107	            use_fast_impl = False
108	        self._use_fast_impl = use_fast_impl
109	
110	        # COCOeval requires the limit on the number of detections per image (maxDets) to be a list
111	        # with at least 3 elements. The default maxDets in COCOeval is [1, 10, 100], in which the
112	        # 3rd element (100) is used as the limit on the number of detections per image when
113	        # evaluating AP. COCOEvaluator expects an integer for max_dets_per_image, so for COCOeval,
114	        # we reformat max_dets_per_image into [1, 10, max_dets_per_image], based on the defaults.
115	        if max_dets_per_image is None:
116	            max_dets_per_image = [1, 10, 100]
117	        else:
118	            max_dets_per_image = [1, 10, max_dets_per_image]
119	        self._max_dets_per_image = max_dets_per_image
120	
</pre>
</div>


</div>
</div>

<div id="issue-118">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_oneformer/evaluation/detection_coco_evaluator.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_oneformer/evaluation/detection_coco_evaluator.py</a><br>
    <b>Line number: </b>14<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# ------------------------------------------------------------------------------
2	# Reference: https://github.com/facebookresearch/detectron2/blob/main/detectron2/evaluation/coco_evaluation.py
3	# Modified by Jitesh Jain (https://github.com/praeclarumjj3)
4	# ------------------------------------------------------------------------------
5	
6	import contextlib
7	import copy
8	import io
9	import itertools
10	import json
11	import logging
12	import numpy as np
13	import os
14	import pickle
15	from collections import OrderedDict
16	import custom_pycocotools.mask as mask_util
17	import torch
18	from custom_pycocotools.coco import COCO
19	from custom_pycocotools.cocoeval import COCOeval
20	from tabulate import tabulate
21	
22	import custom_detectron2.utils.comm as comm
23	from custom_detectron2.config import CfgNode
24	from custom_detectron2.data import MetadataCatalog
25	from custom_detectron2.data.datasets.coco import convert_to_coco_json
26	from custom_detectron2.structures import Boxes, BoxMode, pairwise_iou
27	from custom_detectron2.utils.file_io import PathManager
28	from custom_detectron2.utils.logger import create_small_table
29	
30	from .evaluator import DatasetEvaluator
31	
32	try:
33	    from custom_detectron2.evaluation.fast_eval_api import COCOeval_opt
34	except ImportError:
35	    COCOeval_opt = COCOeval
36	
37	
38	class DetectionCOCOEvaluator(DatasetEvaluator):
39	    &quot;&quot;&quot;
40	    Evaluate AR for object proposals, AP for instance detection/segmentation, AP
41	    for keypoint detection outputs using COCO&#x27;s metrics.
42	    See http://cocodataset.org/#detection-eval and
43	    http://cocodataset.org/#keypoints-eval to understand its metrics.
44	    The metrics range from 0 to 100 (instead of 0 to 1), where a -1 or NaN means
45	    the metric cannot be computed (e.g. due to no predictions made).
46	
47	    In addition to COCO, this evaluator is able to support any bounding box detection,
48	    instance segmentation, or keypoint detection dataset.
49	    &quot;&quot;&quot;
50	
51	    def __init__(
52	        self,
53	        dataset_name,
54	        tasks=None,
55	        distributed=True,
56	        output_dir=None,
57	        *,
58	        max_dets_per_image=None,
59	        use_fast_impl=True,
60	        kpt_oks_sigmas=(),
61	        allow_cached_coco=True,
62	    ):
63	        &quot;&quot;&quot;
64	        Args:
65	            dataset_name (str): name of the dataset to be evaluated.
66	                It must have either the following corresponding metadata:
67	
68	                    &quot;json_file&quot;: the path to the COCO format annotation
69	
70	                Or it must be in detectron2&#x27;s standard dataset format
71	                so it can be converted to COCO format automatically.
72	            tasks (tuple[str]): tasks that can be evaluated under the given
73	                configuration. A task is one of &quot;bbox&quot;, &quot;segm&quot;, &quot;keypoints&quot;.
74	                By default, will infer this automatically from predictions.
75	            distributed (True): if True, will collect results from all ranks and run evaluation
76	                in the main process.
77	                Otherwise, will only evaluate the results in the current process.
78	            output_dir (str): optional, an output directory to dump all
79	                results predicted on the dataset. The dump contains two files:
80	
81	                1. &quot;instances_predictions.pth&quot; a file that can be loaded with `torch.load` and
82	                   contains all the results in the format they are produced by the model.
83	                2. &quot;coco_instances_results.json&quot; a json file in COCO&#x27;s result format.
84	            max_dets_per_image (int): limit on the maximum number of detections per image.
85	                By default in COCO, this limit is to 100, but this can be customized
86	                to be greater, as is needed in evaluation metrics AP fixed and AP pool
87	                (see https://arxiv.org/pdf/2102.01066.pdf)
88	                This doesn&#x27;t affect keypoint evaluation.
89	            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.
90	                Although the results should be very close to the official implementation in COCO
91	                API, it is still recommended to compute results with the official API for use in
92	                papers. The faster implementation also uses more RAM.
93	            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.
94	                See http://cocodataset.org/#keypoints-eval
95	                When empty, it will use the defaults in COCO.
96	                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.
97	            allow_cached_coco (bool): Whether to use cached coco json from previous validation
98	                runs. You should set this to False if you need to use different validation data.
99	                Defaults to True.
100	        &quot;&quot;&quot;
101	        self._logger = logging.getLogger(__name__)
102	        self._distributed = distributed
103	        self._output_dir = output_dir
104	
105	        if use_fast_impl and (COCOeval_opt is COCOeval):
106	            self._logger.info(&quot;Fast COCO eval is not built. Falling back to official COCO eval.&quot;)
107	            use_fast_impl = False
108	        self._use_fast_impl = use_fast_impl
109	
110	        # COCOeval requires the limit on the number of detections per image (maxDets) to be a list
111	        # with at least 3 elements. The default maxDets in COCOeval is [1, 10, 100], in which the
112	        # 3rd element (100) is used as the limit on the number of detections per image when
113	        # evaluating AP. COCOEvaluator expects an integer for max_dets_per_image, so for COCOeval,
114	        # we reformat max_dets_per_image into [1, 10, max_dets_per_image], based on the defaults.
115	        if max_dets_per_image is None:
116	            max_dets_per_image = [1, 10, 100]
117	        else:
118	            max_dets_per_image = [1, 10, max_dets_per_image]
119	        self._max_dets_per_image = max_dets_per_image
120	
</pre>
</div>


</div>
</div>

<div id="issue-119">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_oneformer/evaluation/instance_evaluation.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_oneformer/evaluation/instance_evaluation.py</a><br>
    <b>Line number: </b>13<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	# ------------------------------------------------------------------------------
2	# Reference: https://github.com/facebookresearch/Mask2Former/blob/main/mask2former/evaluation/instance_evaluation.py
3	# ------------------------------------------------------------------------------
4	
5	import contextlib
6	import copy
7	import io
8	import itertools
9	import json
10	import logging
11	import numpy as np
12	import os
13	import pickle
14	from collections import OrderedDict
15	import custom_pycocotools.mask as mask_util
16	import torch
17	from custom_pycocotools.coco import COCO
18	from custom_pycocotools.cocoeval import COCOeval
19	from tabulate import tabulate
20	
21	import custom_detectron2.utils.comm as comm
22	from custom_detectron2.config import CfgNode
23	from custom_detectron2.data import MetadataCatalog
24	from custom_detectron2.data.datasets.coco import convert_to_coco_json
25	from custom_detectron2.evaluation.coco_evaluation import COCOEvaluator, _evaluate_predictions_on_coco
26	from custom_detectron2.evaluation.fast_eval_api import COCOeval_opt
27	from custom_detectron2.structures import Boxes, BoxMode, pairwise_iou
28	from custom_detectron2.utils.file_io import PathManager
29	from custom_detectron2.utils.logger import create_small_table
30	
31	
32	# modified from COCOEvaluator for instance segmetnat
33	class InstanceSegEvaluator(COCOEvaluator):
34	    &quot;&quot;&quot;
35	    Evaluate AR for object proposals, AP for instance detection/segmentation, AP
36	    for keypoint detection outputs using COCO&#x27;s metrics.
37	    See http://cocodataset.org/#detection-eval and
38	    http://cocodataset.org/#keypoints-eval to understand its metrics.
39	    The metrics range from 0 to 100 (instead of 0 to 1), where a -1 or NaN means
40	    the metric cannot be computed (e.g. due to no predictions made).
41	
42	    In addition to COCO, this evaluator is able to support any bounding box detection,
43	    instance segmentation, or keypoint detection dataset.
44	    &quot;&quot;&quot;
45	
46	    def _eval_predictions(self, predictions, img_ids=None):
47	        &quot;&quot;&quot;
48	        Evaluate predictions. Fill self._results with the metrics of the tasks.
49	        &quot;&quot;&quot;
50	        self._logger.info(&quot;Preparing results for COCO format ...&quot;)
51	        coco_results = list(itertools.chain(*[x[&quot;instances&quot;] for x in predictions]))
52	        tasks = self._tasks or self._tasks_from_predictions(coco_results)
53	
54	        # unmap the category ids for COCO
55	        if hasattr(self._metadata, &quot;thing_dataset_id_to_contiguous_id&quot;):
56	            dataset_id_to_contiguous_id = self._metadata.thing_dataset_id_to_contiguous_id
57	            # all_contiguous_ids = list(dataset_id_to_contiguous_id.values())
58	            # num_classes = len(all_contiguous_ids)
59	            # assert min(all_contiguous_ids) == 0 and max(all_contiguous_ids) == num_classes - 1
60	
61	            reverse_id_mapping = {v: k for k, v in dataset_id_to_contiguous_id.items()}
62	            for result in coco_results:
63	                category_id = result[&quot;category_id&quot;]
64	                # assert category_id &lt; num_classes, (
65	                #     f&quot;A prediction has class={category_id}, &quot;
66	                #     f&quot;but the dataset only has {num_classes} classes and &quot;
67	                #     f&quot;predicted class id should be in [0, {num_classes - 1}].&quot;
68	                # )
69	                assert category_id in reverse_id_mapping, (
70	                    f&quot;A prediction has class={category_id}, &quot;
71	                    f&quot;but the dataset only has class ids in {dataset_id_to_contiguous_id}.&quot;
72	                )
73	                result[&quot;category_id&quot;] = reverse_id_mapping[category_id]
74	
75	        if self._output_dir:
76	            file_path = os.path.join(self._output_dir, &quot;coco_instances_results.json&quot;)
77	            self._logger.info(&quot;Saving results to {}&quot;.format(file_path))
78	            with PathManager.open(file_path, &quot;w&quot;) as f:
79	                f.write(json.dumps(coco_results))
80	                f.flush()
81	
82	        if not self._do_evaluation:
83	            self._logger.info(&quot;Annotations are not available for evaluation.&quot;)
84	            return
85	
86	        self._logger.info(
87	            &quot;Evaluating predictions with {} COCO API...&quot;.format(
88	                &quot;unofficial&quot; if self._use_fast_impl else &quot;official&quot;
89	            )
90	        )
91	        for task in sorted(tasks):
92	            assert task in {&quot;bbox&quot;, &quot;segm&quot;, &quot;keypoints&quot;}, f&quot;Got unknown task: {task}!&quot;
93	            coco_eval = (
94	                _evaluate_predictions_on_coco(
95	                    self._coco_api,
96	                    coco_results,
97	                    task,
98	                    kpt_oks_sigmas=self._kpt_oks_sigmas,
99	                    use_fast_impl=self._use_fast_impl,
100	                    img_ids=img_ids,
101	                    max_dets_per_image=self._max_dets_per_image,
102	                )
103	                if len(coco_results) &gt; 0
104	                else None  # cocoapi does not handle empty results very well
105	            )
106	
107	            res = self._derive_coco_results(
108	                coco_eval, task, class_names=self._metadata.get(&quot;thing_classes&quot;)
109	            )
110	            self._results[task] = res
</pre>
</div>


</div>
</div>

<div id="issue-120">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Audit url open for permitted schemes. Allowing use of file:/ or custom schemes is often unexpected.<br>
    <b>Test ID:</b> B310<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/22.html" target="_blank">CWE-22</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_pycocotools/coco.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_pycocotools/coco.py</a><br>
    <b>Line number: </b>390<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b310-urllib-urlopen</a><br>

<div class="code">
<pre>
330	            imgIds = set([img[&#x27;id&#x27;] for img in res.dataset[&#x27;images&#x27;]]) &amp; set([ann[&#x27;image_id&#x27;] for ann in anns])
331	            res.dataset[&#x27;images&#x27;] = [img for img in res.dataset[&#x27;images&#x27;] if img[&#x27;id&#x27;] in imgIds]
332	            for id, ann in enumerate(anns):
333	                ann[&#x27;id&#x27;] = id+1
334	        elif &#x27;bbox&#x27; in anns[0] and not anns[0][&#x27;bbox&#x27;] == []:
335	            res.dataset[&#x27;categories&#x27;] = copy.deepcopy(self.dataset[&#x27;categories&#x27;])
336	            for id, ann in enumerate(anns):
337	                bb = ann[&#x27;bbox&#x27;]
338	                x1, x2, y1, y2 = [bb[0], bb[0]+bb[2], bb[1], bb[1]+bb[3]]
339	                if not &#x27;segmentation&#x27; in ann:
340	                    ann[&#x27;segmentation&#x27;] = [[x1, y1, x1, y2, x2, y2, x2, y1]]
341	                ann[&#x27;area&#x27;] = bb[2]*bb[3]
342	                ann[&#x27;id&#x27;] = id+1
343	                ann[&#x27;iscrowd&#x27;] = 0
344	        elif &#x27;segmentation&#x27; in anns[0]:
345	            res.dataset[&#x27;categories&#x27;] = copy.deepcopy(self.dataset[&#x27;categories&#x27;])
346	            for id, ann in enumerate(anns):
347	                # now only support compressed RLE format as segmentation results
348	                ann[&#x27;area&#x27;] = maskUtils.area(ann[&#x27;segmentation&#x27;])
349	                if not &#x27;bbox&#x27; in ann:
350	                    ann[&#x27;bbox&#x27;] = maskUtils.toBbox(ann[&#x27;segmentation&#x27;])
351	                ann[&#x27;id&#x27;] = id+1
352	                ann[&#x27;iscrowd&#x27;] = 0
353	        elif &#x27;keypoints&#x27; in anns[0]:
354	            res.dataset[&#x27;categories&#x27;] = copy.deepcopy(self.dataset[&#x27;categories&#x27;])
355	            for id, ann in enumerate(anns):
356	                s = ann[&#x27;keypoints&#x27;]
357	                x = s[0::3]
358	                y = s[1::3]
359	                x0,x1,y0,y1 = np.min(x), np.max(x), np.min(y), np.max(y)
360	                ann[&#x27;area&#x27;] = (x1-x0)*(y1-y0)
361	                ann[&#x27;id&#x27;] = id + 1
362	                ann[&#x27;bbox&#x27;] = [x0,y0,x1-x0,y1-y0]
363	        print(&#x27;DONE (t={:0.2f}s)&#x27;.format(time.time()- tic))
364	
365	        res.dataset[&#x27;annotations&#x27;] = anns
366	        res.createIndex()
367	        return res
368	
369	    def download(self, tarDir = None, imgIds = [] ):
370	        &#x27;&#x27;&#x27;
371	        Download COCO images from mscoco.org server.
372	        :param tarDir (str): COCO results directory name
373	               imgIds (list): images to be downloaded
374	        :return:
375	        &#x27;&#x27;&#x27;
376	        if tarDir is None:
377	            print(&#x27;Please specify target directory&#x27;)
378	            return -1
379	        if len(imgIds) == 0:
380	            imgs = self.imgs.values()
381	        else:
382	            imgs = self.loadImgs(imgIds)
383	        N = len(imgs)
384	        if not os.path.exists(tarDir):
385	            os.makedirs(tarDir)
386	        for i, img in enumerate(imgs):
387	            tic = time.time()
388	            fname = os.path.join(tarDir, img[&#x27;file_name&#x27;])
389	            if not os.path.exists(fname):
390	                urlretrieve(img[&#x27;coco_url&#x27;], fname)
391	            print(&#x27;downloaded {}/{} images (t={:0.1f}s)&#x27;.format(i, N, time.time()- tic))
392	
393	    def loadNumpyAnnotations(self, data):
394	        &quot;&quot;&quot;
395	        Convert result data from a numpy array [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}
396	        :param  data (numpy.ndarray)
397	        :return: annotations (python nested list)
398	        &quot;&quot;&quot;
399	        print(&#x27;Converting ndarray to lists...&#x27;)
400	        assert(type(data) == np.ndarray)
401	        print(data.shape)
402	        assert(data.shape[1] == 7)
403	        N = data.shape[0]
404	        ann = []
405	        for i in range(N):
406	            if i % 1000000 == 0:
407	                print(&#x27;{}/{}&#x27;.format(i,N))
408	            ann += [{
409	                &#x27;image_id&#x27;  : int(data[i, 0]),
410	                &#x27;bbox&#x27;  : [ data[i, 1], data[i, 2], data[i, 3], data[i, 4] ],
411	                &#x27;score&#x27; : data[i, 5],
412	                &#x27;category_id&#x27;: int(data[i, 6]),
413	                }]
414	        return ann
415	
416	    def annToRLE(self, ann):
417	        &quot;&quot;&quot;
418	        Convert annotation which can be polygons, uncompressed RLE to RLE.
419	        :return: binary mask (numpy 2D array)
420	        &quot;&quot;&quot;
421	        t = self.imgs[ann[&#x27;image_id&#x27;]]
422	        h, w = t[&#x27;height&#x27;], t[&#x27;width&#x27;]
423	        segm = ann[&#x27;segmentation&#x27;]
424	        if type(segm) == list:
425	            # polygon -- a single object might consist of multiple parts
426	            # we merge all parts into one mask rle code
427	            rles = maskUtils.frPyObjects(segm, h, w)
428	            rle = maskUtils.merge(rles)
429	        elif type(segm[&#x27;counts&#x27;]) == list:
430	            # uncompressed RLE
431	            rle = maskUtils.frPyObjects(segm, h, w)
432	        else:
433	            # rle
434	            rle = ann[&#x27;segmentation&#x27;]
435	        return rle
436	
437	    def annToMask(self, ann):
438	        &quot;&quot;&quot;
439	        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.
440	        :return: binary mask (numpy 2D array)
441	        &quot;&quot;&quot;
442	        rle = self.annToRLE(ann)
443	        m = maskUtils.decode(rle)
444	        return m
</pre>
</div>


</div>
</div>

<div id="issue-121">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_pycocotools/cocoeval.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_pycocotools/cocoeval.py</a><br>
    <b>Line number: </b>407<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
347	        m_list = [m for n, m in enumerate(p.maxDets) if m in setM]
348	        a_list = [n for n, a in enumerate(map(lambda x: tuple(x), p.areaRng)) if a in setA]
349	        i_list = [n for n, i in enumerate(p.imgIds)  if i in setI]
350	        I0 = len(_pe.imgIds)
351	        A0 = len(_pe.areaRng)
352	        # retrieve E at each category, area range, and max number of detections
353	        for k, k0 in enumerate(k_list):
354	            Nk = k0*A0*I0
355	            for a, a0 in enumerate(a_list):
356	                Na = a0*I0
357	                for m, maxDet in enumerate(m_list):
358	                    E = [self.evalImgs[Nk + Na + i] for i in i_list]
359	                    E = [e for e in E if not e is None]
360	                    if len(E) == 0:
361	                        continue
362	                    dtScores = np.concatenate([e[&#x27;dtScores&#x27;][0:maxDet] for e in E])
363	
364	                    # different sorting method generates slightly different results.
365	                    # mergesort is used to be consistent as Matlab implementation.
366	                    inds = np.argsort(-dtScores, kind=&#x27;mergesort&#x27;)
367	                    dtScoresSorted = dtScores[inds]
368	
369	                    dtm  = np.concatenate([e[&#x27;dtMatches&#x27;][:,0:maxDet] for e in E], axis=1)[:,inds]
370	                    dtIg = np.concatenate([e[&#x27;dtIgnore&#x27;][:,0:maxDet]  for e in E], axis=1)[:,inds]
371	                    gtIg = np.concatenate([e[&#x27;gtIgnore&#x27;] for e in E])
372	                    npig = np.count_nonzero(gtIg==0 )
373	                    if npig == 0:
374	                        continue
375	                    tps = np.logical_and(               dtm,  np.logical_not(dtIg) )
376	                    fps = np.logical_and(np.logical_not(dtm), np.logical_not(dtIg) )
377	
378	                    tp_sum = np.cumsum(tps, axis=1).astype(dtype=float)
379	                    fp_sum = np.cumsum(fps, axis=1).astype(dtype=float)
380	                    for t, (tp, fp) in enumerate(zip(tp_sum, fp_sum)):
381	                        tp = np.array(tp)
382	                        fp = np.array(fp)
383	                        nd = len(tp)
384	                        rc = tp / npig
385	                        pr = tp / (fp+tp+np.spacing(1))
386	                        q  = np.zeros((R,))
387	                        ss = np.zeros((R,))
388	
389	                        if nd:
390	                            recall[t,k,a,m] = rc[-1]
391	                        else:
392	                            recall[t,k,a,m] = 0
393	
394	                        # numpy is slow without cython optimization for accessing elements
395	                        # use python array gets significant speed improvement
396	                        pr = pr.tolist(); q = q.tolist()
397	
398	                        for i in range(nd-1, 0, -1):
399	                            if pr[i] &gt; pr[i-1]:
400	                                pr[i-1] = pr[i]
401	
402	                        inds = np.searchsorted(rc, p.recThrs, side=&#x27;left&#x27;)
403	                        try:
404	                            for ri, pi in enumerate(inds):
405	                                q[ri] = pr[pi]
406	                                ss[ri] = dtScoresSorted[pi]
407	                        except:
408	                            pass
409	                        precision[t,:,k,a,m] = np.array(q)
410	                        scores[t,:,k,a,m] = np.array(ss)
411	        self.eval = {
412	            &#x27;params&#x27;: p,
413	            &#x27;counts&#x27;: [T, R, K, A, M],
414	            &#x27;date&#x27;: datetime.datetime.now().strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;),
415	            &#x27;precision&#x27;: precision,
416	            &#x27;recall&#x27;:   recall,
417	            &#x27;scores&#x27;: scores,
418	        }
419	        toc = time.time()
420	        print(&#x27;DONE (t={:0.2f}s).&#x27;.format( toc-tic))
421	
422	    def summarize(self):
423	        &#x27;&#x27;&#x27;
424	        Compute and display summary metrics for evaluation results.
425	        Note this functin can *only* be applied on the default parameter setting
426	        &#x27;&#x27;&#x27;
427	        def _summarize( ap=1, iouThr=None, areaRng=&#x27;all&#x27;, maxDets=100 ):
428	            p = self.params
429	            iStr = &#x27; {:&lt;18} {} @[ IoU={:&lt;9} | area={:&gt;6s} | maxDets={:&gt;3d} ] = {:0.3f}&#x27;
430	            titleStr = &#x27;Average Precision&#x27; if ap == 1 else &#x27;Average Recall&#x27;
431	            typeStr = &#x27;(AP)&#x27; if ap==1 else &#x27;(AR)&#x27;
432	            iouStr = &#x27;{:0.2f}:{:0.2f}&#x27;.format(p.iouThrs[0], p.iouThrs[-1]) \
433	                if iouThr is None else &#x27;{:0.2f}&#x27;.format(iouThr)
434	
435	            aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]
436	            mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]
437	            if ap == 1:
438	                # dimension of precision: [TxRxKxAxM]
439	                s = self.eval[&#x27;precision&#x27;]
440	                # IoU
441	                if iouThr is not None:
442	                    t = np.where(iouThr == p.iouThrs)[0]
443	                    s = s[t]
444	                s = s[:,:,:,aind,mind]
445	            else:
446	                # dimension of recall: [TxKxAxM]
447	                s = self.eval[&#x27;recall&#x27;]
448	                if iouThr is not None:
449	                    t = np.where(iouThr == p.iouThrs)[0]
450	                    s = s[t]
451	                s = s[:,:,aind,mind]
452	            if len(s[s&gt;-1])==0:
453	                mean_s = -1
454	            else:
455	                mean_s = np.mean(s[s&gt;-1])
456	            print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))
457	            return mean_s
458	        def _summarizeDets():
459	            stats = np.zeros((12,))
460	            stats[0] = _summarize(1)
461	            stats[1] = _summarize(1, iouThr=.5, maxDets=self.params.maxDets[2])
462	            stats[2] = _summarize(1, iouThr=.75, maxDets=self.params.maxDets[2])
463	            stats[3] = _summarize(1, areaRng=&#x27;small&#x27;, maxDets=self.params.maxDets[2])
464	            stats[4] = _summarize(1, areaRng=&#x27;medium&#x27;, maxDets=self.params.maxDets[2])
465	            stats[5] = _summarize(1, areaRng=&#x27;large&#x27;, maxDets=self.params.maxDets[2])
466	            stats[6] = _summarize(0, maxDets=self.params.maxDets[0])
467	            stats[7] = _summarize(0, maxDets=self.params.maxDets[1])
</pre>
</div>


</div>
</div>

<div id="issue-122">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/class_map.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/class_map.py</a><br>
    <b>Line number: </b>2<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	import os
2	import pickle
3	
4	def load_class_map(map_or_filename, root=&#x27;&#x27;):
5	    if isinstance(map_or_filename, dict):
6	        assert dict, &#x27;class_map dict must be non-empty&#x27;
7	        return map_or_filename
8	    class_map_path = map_or_filename
9	    if not os.path.exists(class_map_path):
10	        class_map_path = os.path.join(root, class_map_path)
11	        assert os.path.exists(class_map_path), &#x27;Cannot locate specified class map file (%s)&#x27; % map_or_filename
12	    class_map_ext = os.path.splitext(map_or_filename)[-1].lower()
13	    if class_map_ext == &#x27;.txt&#x27;:
14	        with open(class_map_path) as f:
15	            class_to_idx = {v.strip(): k for k, v in enumerate(f)}
16	    elif class_map_ext == &#x27;.pkl&#x27;:
17	        with open(class_map_path,&#x27;rb&#x27;) as f:
18	            class_to_idx = pickle.load(f)
19	    else:
20	        assert False, f&#x27;Unsupported class map file extension ({class_map_ext}).&#x27;
21	    return class_to_idx
22	
</pre>
</div>


</div>
</div>

<div id="issue-123">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/class_map.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/class_map.py</a><br>
    <b>Line number: </b>18<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
1	import os
2	import pickle
3	
4	def load_class_map(map_or_filename, root=&#x27;&#x27;):
5	    if isinstance(map_or_filename, dict):
6	        assert dict, &#x27;class_map dict must be non-empty&#x27;
7	        return map_or_filename
8	    class_map_path = map_or_filename
9	    if not os.path.exists(class_map_path):
10	        class_map_path = os.path.join(root, class_map_path)
11	        assert os.path.exists(class_map_path), &#x27;Cannot locate specified class map file (%s)&#x27; % map_or_filename
12	    class_map_ext = os.path.splitext(map_or_filename)[-1].lower()
13	    if class_map_ext == &#x27;.txt&#x27;:
14	        with open(class_map_path) as f:
15	            class_to_idx = {v.strip(): k for k, v in enumerate(f)}
16	    elif class_map_ext == &#x27;.pkl&#x27;:
17	        with open(class_map_path,&#x27;rb&#x27;) as f:
18	            class_to_idx = pickle.load(f)
19	    else:
20	        assert False, f&#x27;Unsupported class map file extension ({class_map_ext}).&#x27;
21	    return class_to_idx
22	
</pre>
</div>


</div>
</div>

<div id="issue-124">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with pickle module.<br>
    <b>Test ID:</b> B403<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/parser_image_in_tar.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/parser_image_in_tar.py</a><br>
    <b>Line number: </b>14<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b403-import-pickle</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot; A dataset parser that reads tarfile based datasets
2	
3	This parser can read and extract image samples from:
4	* a single tar of image files
5	* a folder of multiple tarfiles containing imagefiles
6	* a tar of tars containing image files
7	
8	Labels are based on the combined folder and/or tar name structure.
9	
10	Hacked together by / Copyright 2020 Ross Wightman
11	&quot;&quot;&quot;
12	import logging
13	import os
14	import pickle
15	import tarfile
16	from glob import glob
17	from typing import List, Tuple, Dict, Set, Optional, Union
18	
19	import numpy as np
20	
21	from custom_timm.utils.misc import natural_key
22	
23	from .class_map import load_class_map
24	from .img_extensions import get_img_extensions
25	from .parser import Parser
26	
27	_logger = logging.getLogger(__name__)
28	CACHE_FILENAME_SUFFIX = &#x27;_tarinfos.pickle&#x27;
29	
30	
31	class TarState:
32	
33	    def __init__(self, tf: tarfile.TarFile = None, ti: tarfile.TarInfo = None):
34	        self.tf: tarfile.TarFile = tf
35	        self.ti: tarfile.TarInfo = ti
36	        self.children: Dict[str, TarState] = {}  # child states (tars within tars)
37	
38	    def reset(self):
39	        self.tf = None
40	
41	
42	def _extract_tarinfo(tf: tarfile.TarFile, parent_info: Dict, extensions: Set[str]):
43	    sample_count = 0
44	    for i, ti in enumerate(tf):
45	        if not ti.isfile():
46	            continue
47	        dirname, basename = os.path.split(ti.path)
48	        name, ext = os.path.splitext(basename)
49	        ext = ext.lower()
50	        if ext == &#x27;.tar&#x27;:
51	            with tarfile.open(fileobj=tf.extractfile(ti), mode=&#x27;r|&#x27;) as ctf:
52	                child_info = dict(
53	                    name=ti.name, path=os.path.join(parent_info[&#x27;path&#x27;], name), ti=ti, children=[], samples=[])
54	                sample_count += _extract_tarinfo(ctf, child_info, extensions=extensions)
55	                _logger.debug(f&#x27;{i}/?. Extracted child tarinfos from {ti.name}. {len(child_info[&quot;samples&quot;])} images.&#x27;)
56	                parent_info[&#x27;children&#x27;].append(child_info)
57	        elif ext in extensions:
58	            parent_info[&#x27;samples&#x27;].append(ti)
59	            sample_count += 1
60	    return sample_count
61	
62	
63	def extract_tarinfos(
64	        root,
65	        class_name_to_idx: Optional[Dict] = None,
66	        cache_tarinfo: Optional[bool] = None,
67	        extensions: Optional[Union[List, Tuple, Set]] = None,
68	        sort: bool = True
69	):
70	    extensions = get_img_extensions(as_set=True) if not extensions else set(extensions)
71	    root_is_tar = False
72	    if os.path.isfile(root):
73	        assert os.path.splitext(root)[-1].lower() == &#x27;.tar&#x27;
74	        tar_filenames = [root]
75	        root, root_name = os.path.split(root)
76	        root_name = os.path.splitext(root_name)[0]
77	        root_is_tar = True
78	    else:
79	        root_name = root.strip(os.path.sep).split(os.path.sep)[-1]
80	        tar_filenames = glob(os.path.join(root, &#x27;*.tar&#x27;), recursive=True)
81	    num_tars = len(tar_filenames)
82	    tar_bytes = sum([os.path.getsize(f) for f in tar_filenames])
83	    assert num_tars, f&#x27;No .tar files found at specified path ({root}).&#x27;
84	
85	    _logger.info(f&#x27;Scanning {tar_bytes/1024**2:.2f}MB of tar files...&#x27;)
86	    info = dict(tartrees=[])
87	    cache_path = &#x27;&#x27;
88	    if cache_tarinfo is None:
89	        cache_tarinfo = True if tar_bytes &gt; 10*1024**3 else False  # FIXME magic number, 10GB
90	    if cache_tarinfo:
91	        cache_filename = &#x27;_&#x27; + root_name + CACHE_FILENAME_SUFFIX
92	        cache_path = os.path.join(root, cache_filename)
93	    if os.path.exists(cache_path):
94	        _logger.info(f&#x27;Reading tar info from cache file {cache_path}.&#x27;)
95	        with open(cache_path, &#x27;rb&#x27;) as pf:
96	            info = pickle.load(pf)
97	        assert len(info[&#x27;tartrees&#x27;]) == num_tars, &quot;Cached tartree len doesn&#x27;t match number of tarfiles&quot;
98	    else:
99	        for i, fn in enumerate(tar_filenames):
100	            path = &#x27;&#x27; if root_is_tar else os.path.splitext(os.path.basename(fn))[0]
101	            with tarfile.open(fn, mode=&#x27;r|&#x27;) as tf:  # tarinfo scans done in streaming mode
102	                parent_info = dict(name=os.path.relpath(fn, root), path=path, ti=None, children=[], samples=[])
103	                num_samples = _extract_tarinfo(tf, parent_info, extensions=extensions)
104	                num_children = len(parent_info[&quot;children&quot;])
105	                _logger.debug(
106	                    f&#x27;{i}/{num_tars}. Extracted tarinfos from {fn}. {num_children} children, {num_samples} samples.&#x27;)
107	            info[&#x27;tartrees&#x27;].append(parent_info)
108	        if cache_path:
109	            _logger.info(f&#x27;Writing tar info to cache file {cache_path}.&#x27;)
110	            with open(cache_path, &#x27;wb&#x27;) as pf:
111	                pickle.dump(info, pf)
112	
113	    samples = []
114	    labels = []
115	    build_class_map = False
116	    if class_name_to_idx is None:
117	        build_class_map = True
118	
119	    # Flatten tartree info into lists of samples and targets w/ targets based on label id via
120	    # class map arg or from unique paths.
</pre>
</div>


</div>
</div>

<div id="issue-125">
<div class="issue-block issue-sev-medium">
    <b>blacklist: </b> Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.<br>
    <b>Test ID:</b> B301<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/502.html" target="_blank">CWE-502</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/parser_image_in_tar.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/data/parsers/parser_image_in_tar.py</a><br>
    <b>Line number: </b>96<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_calls.html#b301-pickle</a><br>

<div class="code">
<pre>
36	        self.children: Dict[str, TarState] = {}  # child states (tars within tars)
37	
38	    def reset(self):
39	        self.tf = None
40	
41	
42	def _extract_tarinfo(tf: tarfile.TarFile, parent_info: Dict, extensions: Set[str]):
43	    sample_count = 0
44	    for i, ti in enumerate(tf):
45	        if not ti.isfile():
46	            continue
47	        dirname, basename = os.path.split(ti.path)
48	        name, ext = os.path.splitext(basename)
49	        ext = ext.lower()
50	        if ext == &#x27;.tar&#x27;:
51	            with tarfile.open(fileobj=tf.extractfile(ti), mode=&#x27;r|&#x27;) as ctf:
52	                child_info = dict(
53	                    name=ti.name, path=os.path.join(parent_info[&#x27;path&#x27;], name), ti=ti, children=[], samples=[])
54	                sample_count += _extract_tarinfo(ctf, child_info, extensions=extensions)
55	                _logger.debug(f&#x27;{i}/?. Extracted child tarinfos from {ti.name}. {len(child_info[&quot;samples&quot;])} images.&#x27;)
56	                parent_info[&#x27;children&#x27;].append(child_info)
57	        elif ext in extensions:
58	            parent_info[&#x27;samples&#x27;].append(ti)
59	            sample_count += 1
60	    return sample_count
61	
62	
63	def extract_tarinfos(
64	        root,
65	        class_name_to_idx: Optional[Dict] = None,
66	        cache_tarinfo: Optional[bool] = None,
67	        extensions: Optional[Union[List, Tuple, Set]] = None,
68	        sort: bool = True
69	):
70	    extensions = get_img_extensions(as_set=True) if not extensions else set(extensions)
71	    root_is_tar = False
72	    if os.path.isfile(root):
73	        assert os.path.splitext(root)[-1].lower() == &#x27;.tar&#x27;
74	        tar_filenames = [root]
75	        root, root_name = os.path.split(root)
76	        root_name = os.path.splitext(root_name)[0]
77	        root_is_tar = True
78	    else:
79	        root_name = root.strip(os.path.sep).split(os.path.sep)[-1]
80	        tar_filenames = glob(os.path.join(root, &#x27;*.tar&#x27;), recursive=True)
81	    num_tars = len(tar_filenames)
82	    tar_bytes = sum([os.path.getsize(f) for f in tar_filenames])
83	    assert num_tars, f&#x27;No .tar files found at specified path ({root}).&#x27;
84	
85	    _logger.info(f&#x27;Scanning {tar_bytes/1024**2:.2f}MB of tar files...&#x27;)
86	    info = dict(tartrees=[])
87	    cache_path = &#x27;&#x27;
88	    if cache_tarinfo is None:
89	        cache_tarinfo = True if tar_bytes &gt; 10*1024**3 else False  # FIXME magic number, 10GB
90	    if cache_tarinfo:
91	        cache_filename = &#x27;_&#x27; + root_name + CACHE_FILENAME_SUFFIX
92	        cache_path = os.path.join(root, cache_filename)
93	    if os.path.exists(cache_path):
94	        _logger.info(f&#x27;Reading tar info from cache file {cache_path}.&#x27;)
95	        with open(cache_path, &#x27;rb&#x27;) as pf:
96	            info = pickle.load(pf)
97	        assert len(info[&#x27;tartrees&#x27;]) == num_tars, &quot;Cached tartree len doesn&#x27;t match number of tarfiles&quot;
98	    else:
99	        for i, fn in enumerate(tar_filenames):
100	            path = &#x27;&#x27; if root_is_tar else os.path.splitext(os.path.basename(fn))[0]
101	            with tarfile.open(fn, mode=&#x27;r|&#x27;) as tf:  # tarinfo scans done in streaming mode
102	                parent_info = dict(name=os.path.relpath(fn, root), path=path, ti=None, children=[], samples=[])
103	                num_samples = _extract_tarinfo(tf, parent_info, extensions=extensions)
104	                num_children = len(parent_info[&quot;children&quot;])
105	                _logger.debug(
106	                    f&#x27;{i}/{num_tars}. Extracted tarinfos from {fn}. {num_children} children, {num_samples} samples.&#x27;)
107	            info[&#x27;tartrees&#x27;].append(parent_info)
108	        if cache_path:
109	            _logger.info(f&#x27;Writing tar info to cache file {cache_path}.&#x27;)
110	            with open(cache_path, &#x27;wb&#x27;) as pf:
111	                pickle.dump(info, pf)
112	
113	    samples = []
114	    labels = []
115	    build_class_map = False
116	    if class_name_to_idx is None:
117	        build_class_map = True
118	
119	    # Flatten tartree info into lists of samples and targets w/ targets based on label id via
120	    # class map arg or from unique paths.
121	    # NOTE: currently only flattening up to two-levels, filesystem .tars and then one level of sub-tar children
122	    # this covers my current use cases and keeps things a little easier to test for now.
123	    tarfiles = []
124	
125	    def _label_from_paths(*path, leaf_only=True):
126	        path = os.path.join(*path).strip(os.path.sep)
127	        return path.split(os.path.sep)[-1] if leaf_only else path.replace(os.path.sep, &#x27;_&#x27;)
128	
129	    def _add_samples(info, fn):
130	        added = 0
131	        for s in info[&#x27;samples&#x27;]:
132	            label = _label_from_paths(info[&#x27;path&#x27;], os.path.dirname(s.path))
133	            if not build_class_map and label not in class_name_to_idx:
134	                continue
135	            samples.append((s, fn, info[&#x27;ti&#x27;]))
136	            labels.append(label)
137	            added += 1
138	        return added
139	
140	    _logger.info(f&#x27;Collecting samples and building tar states.&#x27;)
141	    for parent_info in info[&#x27;tartrees&#x27;]:
142	        # if tartree has children, we assume all samples are at the child level
143	        tar_name = None if root_is_tar else parent_info[&#x27;name&#x27;]
144	        tar_state = TarState()
145	        parent_added = 0
146	        for child_info in parent_info[&#x27;children&#x27;]:
147	            child_added = _add_samples(child_info, fn=tar_name)
148	            if child_added:
149	                tar_state.children[child_info[&#x27;name&#x27;]] = TarState(ti=child_info[&#x27;ti&#x27;])
150	            parent_added += child_added
151	        parent_added += _add_samples(parent_info, fn=tar_name)
152	        if parent_added:
153	            tarfiles.append((tar_name, tar_state))
154	    del info
155	
</pre>
</div>


</div>
</div>

<div id="issue-126">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/utils/jit.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/utils/jit.py</a><br>
    <b>Line number: </b>33<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot; JIT scripting/tracing utils
2	
3	Hacked together by / Copyright 2020 Ross Wightman
4	&quot;&quot;&quot;
5	import os
6	
7	import torch
8	
9	
10	def set_jit_legacy():
11	    &quot;&quot;&quot; Set JIT executor to legacy w/ support for op fusion
12	    This is hopefully a temporary need in 1.5/1.5.1/1.6 to restore performance due to changes
13	    in the JIT exectutor. These API are not supported so could change.
14	    &quot;&quot;&quot;
15	    #
16	    assert hasattr(torch._C, &#x27;_jit_set_profiling_executor&#x27;), &quot;Old JIT behavior doesn&#x27;t exist!&quot;
17	    torch._C._jit_set_profiling_executor(False)
18	    torch._C._jit_set_profiling_mode(False)
19	    torch._C._jit_override_can_fuse_on_gpu(True)
20	    #torch._C._jit_set_texpr_fuser_enabled(True)
21	
22	
23	def set_jit_fuser(fuser):
24	    if fuser == &quot;te&quot;:
25	        # default fuser should be == &#x27;te&#x27;
26	        torch._C._jit_set_profiling_executor(True)
27	        torch._C._jit_set_profiling_mode(True)
28	        torch._C._jit_override_can_fuse_on_cpu(False)
29	        torch._C._jit_override_can_fuse_on_gpu(True)
30	        torch._C._jit_set_texpr_fuser_enabled(True)
31	        try:
32	            torch._C._jit_set_nvfuser_enabled(False)
33	        except Exception:
34	            pass
35	    elif fuser == &quot;old&quot; or fuser == &quot;legacy&quot;:
36	        torch._C._jit_set_profiling_executor(False)
37	        torch._C._jit_set_profiling_mode(False)
38	        torch._C._jit_override_can_fuse_on_gpu(True)
39	        torch._C._jit_set_texpr_fuser_enabled(False)
40	        try:
41	            torch._C._jit_set_nvfuser_enabled(False)
42	        except Exception:
43	            pass
44	    elif fuser == &quot;nvfuser&quot; or fuser == &quot;nvf&quot;:
45	        os.environ[&#x27;PYTORCH_NVFUSER_DISABLE_FALLBACK&#x27;] = &#x27;1&#x27;
46	        #os.environ[&#x27;PYTORCH_NVFUSER_DISABLE_FMA&#x27;] = &#x27;1&#x27;
47	        #os.environ[&#x27;PYTORCH_NVFUSER_JIT_OPT_LEVEL&#x27;] = &#x27;0&#x27;
48	        torch._C._jit_set_texpr_fuser_enabled(False)
49	        torch._C._jit_set_profiling_executor(True)
50	        torch._C._jit_set_profiling_mode(True)
51	        torch._C._jit_can_fuse_on_cpu()
52	        torch._C._jit_can_fuse_on_gpu()
53	        torch._C._jit_override_can_fuse_on_cpu(False)
54	        torch._C._jit_override_can_fuse_on_gpu(False)
55	        torch._C._jit_set_nvfuser_guard_mode(True)
56	        torch._C._jit_set_nvfuser_enabled(True)
57	    else:
58	        assert False, f&quot;Invalid jit fuser ({fuser})&quot;
</pre>
</div>


</div>
</div>

<div id="issue-127">
<div class="issue-block issue-sev-low">
    <b>try_except_pass: </b> Try, Except, Pass detected.<br>
    <b>Test ID:</b> B110<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/703.html" target="_blank">CWE-703</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/utils/jit.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/src/custom_timm/utils/jit.py</a><br>
    <b>Line number: </b>42<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b110_try_except_pass.html</a><br>

<div class="code">
<pre>
1	&quot;&quot;&quot; JIT scripting/tracing utils
2	
3	Hacked together by / Copyright 2020 Ross Wightman
4	&quot;&quot;&quot;
5	import os
6	
7	import torch
8	
9	
10	def set_jit_legacy():
11	    &quot;&quot;&quot; Set JIT executor to legacy w/ support for op fusion
12	    This is hopefully a temporary need in 1.5/1.5.1/1.6 to restore performance due to changes
13	    in the JIT exectutor. These API are not supported so could change.
14	    &quot;&quot;&quot;
15	    #
16	    assert hasattr(torch._C, &#x27;_jit_set_profiling_executor&#x27;), &quot;Old JIT behavior doesn&#x27;t exist!&quot;
17	    torch._C._jit_set_profiling_executor(False)
18	    torch._C._jit_set_profiling_mode(False)
19	    torch._C._jit_override_can_fuse_on_gpu(True)
20	    #torch._C._jit_set_texpr_fuser_enabled(True)
21	
22	
23	def set_jit_fuser(fuser):
24	    if fuser == &quot;te&quot;:
25	        # default fuser should be == &#x27;te&#x27;
26	        torch._C._jit_set_profiling_executor(True)
27	        torch._C._jit_set_profiling_mode(True)
28	        torch._C._jit_override_can_fuse_on_cpu(False)
29	        torch._C._jit_override_can_fuse_on_gpu(True)
30	        torch._C._jit_set_texpr_fuser_enabled(True)
31	        try:
32	            torch._C._jit_set_nvfuser_enabled(False)
33	        except Exception:
34	            pass
35	    elif fuser == &quot;old&quot; or fuser == &quot;legacy&quot;:
36	        torch._C._jit_set_profiling_executor(False)
37	        torch._C._jit_set_profiling_mode(False)
38	        torch._C._jit_override_can_fuse_on_gpu(True)
39	        torch._C._jit_set_texpr_fuser_enabled(False)
40	        try:
41	            torch._C._jit_set_nvfuser_enabled(False)
42	        except Exception:
43	            pass
44	    elif fuser == &quot;nvfuser&quot; or fuser == &quot;nvf&quot;:
45	        os.environ[&#x27;PYTORCH_NVFUSER_DISABLE_FALLBACK&#x27;] = &#x27;1&#x27;
46	        #os.environ[&#x27;PYTORCH_NVFUSER_DISABLE_FMA&#x27;] = &#x27;1&#x27;
47	        #os.environ[&#x27;PYTORCH_NVFUSER_JIT_OPT_LEVEL&#x27;] = &#x27;0&#x27;
48	        torch._C._jit_set_texpr_fuser_enabled(False)
49	        torch._C._jit_set_profiling_executor(True)
50	        torch._C._jit_set_profiling_mode(True)
51	        torch._C._jit_can_fuse_on_cpu()
52	        torch._C._jit_can_fuse_on_gpu()
53	        torch._C._jit_override_can_fuse_on_cpu(False)
54	        torch._C._jit_override_can_fuse_on_gpu(False)
55	        torch._C._jit_set_nvfuser_guard_mode(True)
56	        torch._C._jit_set_nvfuser_enabled(True)
57	    else:
58	        assert False, f&quot;Invalid jit fuser ({fuser})&quot;
</pre>
</div>


</div>
</div>

<div id="issue-128">
<div class="issue-block issue-sev-medium">
    <b>request_without_timeout: </b> Requests call without timeout<br>
    <b>Test ID:</b> B113<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>LOW<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/400.html" target="_blank">CWE-400</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/tests/test_controlnet_aux.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/tests/test_controlnet_aux.py</a><br>
    <b>Line number: </b>39<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b113_request_without_timeout.html</a><br>

<div class="code">
<pre>
1	import os
2	import shutil
3	from io import BytesIO
4	
5	import numpy as np
6	import pytest
7	import requests
8	from PIL import Image
9	
10	from controlnet_aux import (CannyDetector, ContentShuffleDetector, HEDdetector,
11	                            LeresDetector, LineartAnimeDetector,
12	                            LineartDetector, MediapipeFaceDetector,
13	                            MidasDetector, MLSDdetector, NormalBaeDetector,
14	                            OpenposeDetector, PidiNetDetector, SamDetector,
15	                            ZoeDetector, TileDetector)
16	
17	OUTPUT_DIR = &quot;tests/outputs&quot;
18	
19	def output(name, img):
20	    img.save(os.path.join(OUTPUT_DIR, &quot;{:s}.png&quot;.format(name)))
21	
22	def common(name, processor, img):
23	    output(name, processor(img))
24	    output(name + &quot;_pil_np&quot;, Image.fromarray(processor(img, output_type=&quot;np&quot;)))
25	    output(name + &quot;_np_np&quot;, Image.fromarray(processor(np.array(img, dtype=np.uint8), output_type=&quot;np&quot;)))
26	    output(name + &quot;_np_pil&quot;, processor(np.array(img, dtype=np.uint8), output_type=&quot;pil&quot;))
27	    output(name + &quot;_scaled&quot;, processor(img, detect_resolution=640, image_resolution=768))
28	
29	def return_pil(name, processor, img):
30	    output(name + &quot;_pil_false&quot;, Image.fromarray(processor(img, return_pil=False)))
31	    output(name + &quot;_pil_true&quot;, processor(img, return_pil=True))
32	
33	@pytest.fixture(scope=&quot;module&quot;)
34	def img():
35	    if os.path.exists(OUTPUT_DIR):
36	        shutil.rmtree(OUTPUT_DIR)
37	    os.mkdir(OUTPUT_DIR)
38	    url = &quot;https://huggingface.co/lllyasviel/sd-controlnet-openpose/resolve/main/images/pose.png&quot;
39	    response = requests.get(url)
40	    img = Image.open(BytesIO(response.content)).convert(&quot;RGB&quot;).resize((512, 512))
41	    return img
42	
43	def test_canny(img):
44	    canny = CannyDetector()
45	    common(&quot;canny&quot;, canny, img)
46	    output(&quot;canny_img&quot;, canny(img=img))
47	
48	def test_hed(img):
49	    hed = HEDdetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
50	    common(&quot;hed&quot;, hed, img)
51	    return_pil(&quot;hed&quot;, hed, img)
52	    output(&quot;hed_safe&quot;, hed(img, safe=True))
53	    output(&quot;hed_scribble&quot;, hed(img, scribble=True))
54	
55	def test_leres(img):
56	    leres = LeresDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
57	    common(&quot;leres&quot;, leres, img)
58	    output(&quot;leres_boost&quot;, leres(img, boost=True))
59	
60	def test_lineart(img):
61	    lineart = LineartDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
62	    common(&quot;lineart&quot;, lineart, img)
63	    return_pil(&quot;lineart&quot;, lineart, img)
64	    output(&quot;lineart_coarse&quot;, lineart(img, coarse=True))
65	
66	def test_lineart_anime(img):
67	    lineart_anime = LineartAnimeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
68	    common(&quot;lineart_anime&quot;, lineart_anime, img)
69	    return_pil(&quot;lineart_anime&quot;, lineart_anime, img)
70	
71	def test_mediapipe_face(img):
72	    mediapipe = MediapipeFaceDetector()
73	    common(&quot;mediapipe&quot;, mediapipe, img)
74	    output(&quot;mediapipe_image&quot;, mediapipe(image=img))
75	
76	def test_midas(img):
77	    midas = MidasDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
78	    common(&quot;midas&quot;, midas, img)
79	    output(&quot;midas_normal&quot;, midas(img, depth_and_normal=True)[1])
80	
81	def test_mlsd(img):
82	    mlsd = MLSDdetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
83	    common(&quot;mlsd&quot;, mlsd, img)
84	    return_pil(&quot;mlsd&quot;, mlsd, img)
85	
86	def test_normalbae(img):
87	    normal_bae = NormalBaeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
88	    common(&quot;normal_bae&quot;, normal_bae, img)
89	    return_pil(&quot;normal_bae&quot;, normal_bae, img)
90	
91	def test_openpose(img):
92	    openpose = OpenposeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
93	    common(&quot;openpose&quot;, openpose, img)
94	    return_pil(&quot;openpose&quot;, openpose, img)
95	    output(&quot;openpose_hand_and_face_false&quot;, openpose(img, hand_and_face=False))
96	    output(&quot;openpose_hand_and_face_true&quot;, openpose(img, hand_and_face=True))
97	    output(&quot;openpose_face&quot;, openpose(img, include_body=True, include_hand=False, include_face=True))
98	    output(&quot;openpose_faceonly&quot;, openpose(img, include_body=False, include_hand=False, include_face=True))
99	    output(&quot;openpose_full&quot;, openpose(img, include_body=True, include_hand=True, include_face=True))
100	    output(&quot;openpose_hand&quot;, openpose(img, include_body=True, include_hand=True, include_face=False))
101	
102	def test_pidi(img):
103	    pidi = PidiNetDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
104	    common(&quot;pidi&quot;, pidi, img)
105	    return_pil(&quot;pidi&quot;, pidi, img)
106	    output(&quot;pidi_safe&quot;, pidi(img, safe=True))
107	    output(&quot;pidi_scribble&quot;, pidi(img, scribble=True))
108	
109	def test_sam(img):
110	    sam = SamDetector.from_pretrained(&quot;ybelkada/segment-anything&quot;, subfolder=&quot;checkpoints&quot;)
111	    common(&quot;sam&quot;, sam, img)
112	    output(&quot;sam_image&quot;, sam(image=img))
113	
114	def test_shuffle(img):
115	    shuffle = ContentShuffleDetector()
116	    common(&quot;shuffle&quot;, shuffle, img)
117	    return_pil(&quot;shuffle&quot;, shuffle, img)
118	
119	def test_zoe(img):
120	    zoe = ZoeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)
</pre>
</div>


</div>
</div>

<div id="issue-129">
<div class="issue-block issue-sev-low">
    <b>blacklist: </b> Consider possible security implications associated with the subprocess module.<br>
    <b>Test ID:</b> B404<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/utils.py</a><br>
    <b>Line number: </b>9<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess" target="_blank">https://bandit.readthedocs.io/en/1.7.9/blacklists/blacklist_imports.html#b404-import-subprocess</a><br>

<div class="code">
<pre>
1	import torch
2	import numpy as np
3	import os
4	import cv2
5	import yaml
6	from pathlib import Path
7	from enum import Enum
8	from .log import log
9	import subprocess
10	import threading
11	import comfy
12	import tempfile
13	
14	here = Path(__file__).parent.resolve()
15	
16	config_path = Path(here, &quot;config.yaml&quot;)
17	
18	if os.path.exists(config_path):
19	    config = yaml.load(open(config_path, &quot;r&quot;), Loader=yaml.FullLoader)
20	
21	    annotator_ckpts_path = str(Path(here, config[&quot;annotator_ckpts_path&quot;]))
22	    TEMP_DIR = config[&quot;custom_temp_path&quot;]
23	    USE_SYMLINKS = config[&quot;USE_SYMLINKS&quot;]
24	    ORT_PROVIDERS = config[&quot;EP_list&quot;]
25	
26	    if USE_SYMLINKS is None or type(USE_SYMLINKS) != bool:
27	        log.error(&quot;USE_SYMLINKS must be a boolean. Using False by default.&quot;)
28	        USE_SYMLINKS = False
29	
30	    if TEMP_DIR is None:
31	        TEMP_DIR = tempfile.gettempdir()
32	    elif not os.path.isdir(TEMP_DIR):
33	        try:
34	            os.makedirs(TEMP_DIR)
35	        except:
36	            log.error(&quot;Failed to create custom temp directory. Using default.&quot;)
37	            TEMP_DIR = tempfile.gettempdir()
38	
39	    if not os.path.isdir(annotator_ckpts_path):
40	        try:
41	            os.makedirs(annotator_ckpts_path)
42	        except:
43	            log.error(&quot;Failed to create config ckpts directory. Using default.&quot;)
44	            annotator_ckpts_path = str(Path(here, &quot;./ckpts&quot;))
45	else:
46	    annotator_ckpts_path = str(Path(here, &quot;./ckpts&quot;))
47	    TEMP_DIR = tempfile.gettempdir()
48	    USE_SYMLINKS = False
49	    ORT_PROVIDERS = [&quot;CUDAExecutionProvider&quot;, &quot;DirectMLExecutionProvider&quot;, &quot;OpenVINOExecutionProvider&quot;, &quot;ROCMExecutionProvider&quot;, &quot;CPUExecutionProvider&quot;, &quot;CoreMLExecutionProvider&quot;]
50	
51	os.environ[&#x27;AUX_ANNOTATOR_CKPTS_PATH&#x27;] = annotator_ckpts_path
52	os.environ[&#x27;AUX_TEMP_DIR&#x27;] = str(TEMP_DIR)
53	os.environ[&#x27;AUX_USE_SYMLINKS&#x27;] = str(USE_SYMLINKS)
54	os.environ[&#x27;AUX_ORT_PROVIDERS&#x27;] = str(&quot;,&quot;.join(ORT_PROVIDERS))
55	
56	log.info(f&quot;Using ckpts path: {annotator_ckpts_path}&quot;)
57	log.info(f&quot;Using symlinks: {USE_SYMLINKS}&quot;)
58	log.info(f&quot;Using ort providers: {ORT_PROVIDERS}&quot;)
59	
60	# Sync with theoritical limit from Comfy base
61	# https://github.com/comfyanonymous/ComfyUI/blob/eecd69b53a896343775bcb02a4f8349e7442ffd1/nodes.py#L45
62	MAX_RESOLUTION=16384
63	
64	def common_annotator_call(model, tensor_image, input_batch=False, **kwargs):
65	    if &quot;detect_resolution&quot; in kwargs:
66	        del kwargs[&quot;detect_resolution&quot;] #Prevent weird case?
67	
68	    if &quot;resolution&quot; in kwargs:
69	        detect_resolution = kwargs[&quot;resolution&quot;] if type(kwargs[&quot;resolution&quot;]) == int and kwargs[&quot;resolution&quot;] &gt;= 64 else 512
70	        del kwargs[&quot;resolution&quot;]
71	    else:
72	        detect_resolution = 512
73	
74	    if input_batch:
75	        np_images = np.asarray(tensor_image * 255., dtype=np.uint8)
76	        np_results = model(np_images, output_type=&quot;np&quot;, detect_resolution=detect_resolution, **kwargs)
77	        return torch.from_numpy(np_results.astype(np.float32) / 255.0)
78	
79	    batch_size = tensor_image.shape[0]
80	    pbar = comfy.utils.ProgressBar(batch_size)
81	    out_tensor = None
82	    for i, image in enumerate(tensor_image):
83	        np_image = np.asarray(image.cpu() * 255., dtype=np.uint8)
84	        np_result = model(np_image, output_type=&quot;np&quot;, detect_resolution=detect_resolution, **kwargs)
85	        out = torch.from_numpy(np_result.astype(np.float32) / 255.0)
86	        if out_tensor is None:
87	            out_tensor = torch.zeros(batch_size, *out.shape, dtype=torch.float32)
88	        out_tensor[i] = out
89	        pbar.update(1)
90	    return out_tensor
91	
92	def create_node_input_types(**extra_kwargs):
93	    return {
94	        &quot;required&quot;: {
95	            &quot;image&quot;: (&quot;IMAGE&quot;,)
96	        },
97	        &quot;optional&quot;: {
98	            **extra_kwargs,
99	            &quot;resolution&quot;: (&quot;INT&quot;, {&quot;default&quot;: 512, &quot;min&quot;: 64, &quot;max&quot;: MAX_RESOLUTION, &quot;step&quot;: 64})
100	        }
101	    }
102	
103	class ResizeMode(Enum):
104	    &quot;&quot;&quot;
105	    Resize modes for ControlNet input images.
106	    &quot;&quot;&quot;
107	
108	    RESIZE = &quot;Just Resize&quot;
109	    INNER_FIT = &quot;Crop and Resize&quot;
110	    OUTER_FIT = &quot;Resize and Fill&quot;
111	
112	    def int_value(self):
113	        if self == ResizeMode.RESIZE:
114	            return 0
115	        elif self == ResizeMode.INNER_FIT:
116	            return 1
117	        elif self == ResizeMode.OUTER_FIT:
118	            return 2
119	        assert False, &quot;NOTREACHED&quot;
120	
</pre>
</div>


</div>
</div>

<div id="issue-130">
<div class="issue-block issue-sev-medium">
    <b>yaml_load: </b> Use of unsafe yaml load. Allows instantiation of arbitrary objects. Consider yaml.safe_load().<br>
    <b>Test ID:</b> B506<br>
    <b>Severity: </b>MEDIUM<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/20.html" target="_blank">CWE-20</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/utils.py</a><br>
    <b>Line number: </b>19<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b506_yaml_load.html</a><br>

<div class="code">
<pre>
1	import torch
2	import numpy as np
3	import os
4	import cv2
5	import yaml
6	from pathlib import Path
7	from enum import Enum
8	from .log import log
9	import subprocess
10	import threading
11	import comfy
12	import tempfile
13	
14	here = Path(__file__).parent.resolve()
15	
16	config_path = Path(here, &quot;config.yaml&quot;)
17	
18	if os.path.exists(config_path):
19	    config = yaml.load(open(config_path, &quot;r&quot;), Loader=yaml.FullLoader)
20	
21	    annotator_ckpts_path = str(Path(here, config[&quot;annotator_ckpts_path&quot;]))
22	    TEMP_DIR = config[&quot;custom_temp_path&quot;]
23	    USE_SYMLINKS = config[&quot;USE_SYMLINKS&quot;]
24	    ORT_PROVIDERS = config[&quot;EP_list&quot;]
25	
26	    if USE_SYMLINKS is None or type(USE_SYMLINKS) != bool:
27	        log.error(&quot;USE_SYMLINKS must be a boolean. Using False by default.&quot;)
28	        USE_SYMLINKS = False
29	
30	    if TEMP_DIR is None:
31	        TEMP_DIR = tempfile.gettempdir()
32	    elif not os.path.isdir(TEMP_DIR):
33	        try:
34	            os.makedirs(TEMP_DIR)
35	        except:
36	            log.error(&quot;Failed to create custom temp directory. Using default.&quot;)
37	            TEMP_DIR = tempfile.gettempdir()
38	
39	    if not os.path.isdir(annotator_ckpts_path):
40	        try:
41	            os.makedirs(annotator_ckpts_path)
42	        except:
43	            log.error(&quot;Failed to create config ckpts directory. Using default.&quot;)
44	            annotator_ckpts_path = str(Path(here, &quot;./ckpts&quot;))
45	else:
46	    annotator_ckpts_path = str(Path(here, &quot;./ckpts&quot;))
47	    TEMP_DIR = tempfile.gettempdir()
48	    USE_SYMLINKS = False
49	    ORT_PROVIDERS = [&quot;CUDAExecutionProvider&quot;, &quot;DirectMLExecutionProvider&quot;, &quot;OpenVINOExecutionProvider&quot;, &quot;ROCMExecutionProvider&quot;, &quot;CPUExecutionProvider&quot;, &quot;CoreMLExecutionProvider&quot;]
50	
51	os.environ[&#x27;AUX_ANNOTATOR_CKPTS_PATH&#x27;] = annotator_ckpts_path
52	os.environ[&#x27;AUX_TEMP_DIR&#x27;] = str(TEMP_DIR)
53	os.environ[&#x27;AUX_USE_SYMLINKS&#x27;] = str(USE_SYMLINKS)
54	os.environ[&#x27;AUX_ORT_PROVIDERS&#x27;] = str(&quot;,&quot;.join(ORT_PROVIDERS))
55	
56	log.info(f&quot;Using ckpts path: {annotator_ckpts_path}&quot;)
57	log.info(f&quot;Using symlinks: {USE_SYMLINKS}&quot;)
58	log.info(f&quot;Using ort providers: {ORT_PROVIDERS}&quot;)
59	
60	# Sync with theoritical limit from Comfy base
61	# https://github.com/comfyanonymous/ComfyUI/blob/eecd69b53a896343775bcb02a4f8349e7442ffd1/nodes.py#L45
62	MAX_RESOLUTION=16384
63	
64	def common_annotator_call(model, tensor_image, input_batch=False, **kwargs):
65	    if &quot;detect_resolution&quot; in kwargs:
66	        del kwargs[&quot;detect_resolution&quot;] #Prevent weird case?
67	
68	    if &quot;resolution&quot; in kwargs:
69	        detect_resolution = kwargs[&quot;resolution&quot;] if type(kwargs[&quot;resolution&quot;]) == int and kwargs[&quot;resolution&quot;] &gt;= 64 else 512
70	        del kwargs[&quot;resolution&quot;]
71	    else:
72	        detect_resolution = 512
73	
74	    if input_batch:
75	        np_images = np.asarray(tensor_image * 255., dtype=np.uint8)
76	        np_results = model(np_images, output_type=&quot;np&quot;, detect_resolution=detect_resolution, **kwargs)
77	        return torch.from_numpy(np_results.astype(np.float32) / 255.0)
78	
79	    batch_size = tensor_image.shape[0]
80	    pbar = comfy.utils.ProgressBar(batch_size)
81	    out_tensor = None
82	    for i, image in enumerate(tensor_image):
83	        np_image = np.asarray(image.cpu() * 255., dtype=np.uint8)
84	        np_result = model(np_image, output_type=&quot;np&quot;, detect_resolution=detect_resolution, **kwargs)
85	        out = torch.from_numpy(np_result.astype(np.float32) / 255.0)
86	        if out_tensor is None:
87	            out_tensor = torch.zeros(batch_size, *out.shape, dtype=torch.float32)
88	        out_tensor[i] = out
89	        pbar.update(1)
90	    return out_tensor
91	
92	def create_node_input_types(**extra_kwargs):
93	    return {
94	        &quot;required&quot;: {
95	            &quot;image&quot;: (&quot;IMAGE&quot;,)
96	        },
97	        &quot;optional&quot;: {
98	            **extra_kwargs,
99	            &quot;resolution&quot;: (&quot;INT&quot;, {&quot;default&quot;: 512, &quot;min&quot;: 64, &quot;max&quot;: MAX_RESOLUTION, &quot;step&quot;: 64})
100	        }
101	    }
102	
103	class ResizeMode(Enum):
104	    &quot;&quot;&quot;
105	    Resize modes for ControlNet input images.
106	    &quot;&quot;&quot;
107	
108	    RESIZE = &quot;Just Resize&quot;
109	    INNER_FIT = &quot;Crop and Resize&quot;
110	    OUTER_FIT = &quot;Resize and Fill&quot;
111	
112	    def int_value(self):
113	        if self == ResizeMode.RESIZE:
114	            return 0
115	        elif self == ResizeMode.INNER_FIT:
116	            return 1
117	        elif self == ResizeMode.OUTER_FIT:
118	            return 2
119	        assert False, &quot;NOTREACHED&quot;
120	
</pre>
</div>


</div>
</div>

<div id="issue-131">
<div class="issue-block issue-sev-low">
    <b>subprocess_without_shell_equals_true: </b> subprocess call - check for execution of untrusted input.<br>
    <b>Test ID:</b> B603<br>
    <b>Severity: </b>LOW<br>
    <b>Confidence: </b>HIGH<br>
    <b>CWE: </b><a href="https://cwe.mitre.org/data/definitions/78.html" target="_blank">CWE-78</a><br>
    <b>File: </b><a href="/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/utils.py" target="_blank">/home/c_byrne/tools/sd/sd-interfaces/ComfyUI/custom_nodes/comfyui_controlnet_aux/utils.py</a><br>
    <b>Line number: </b>201<br>
    <b>More info: </b><a href="https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html" target="_blank">https://bandit.readthedocs.io/en/1.7.9/plugins/b603_subprocess_without_shell_equals_true.html</a><br>

<div class="code">
<pre>
141	
142	    After calculating the estimated resolution, the function prints some debugging information.
143	
144	    Args:
145	        image (np.ndarray): A 3D numpy array representing an image. The dimensions represent [height, width, channels].
146	        target_H (int): The target height for the image.
147	        target_W (int): The target width for the image.
148	        resize_mode (ResizeMode): The mode for resizing.
149	
150	    Returns:
151	        int: The estimated resolution after resizing.
152	    &quot;&quot;&quot;
153	    raw_H, raw_W, _ = image.shape
154	
155	    k0 = float(target_H) / float(raw_H)
156	    k1 = float(target_W) / float(raw_W)
157	
158	    if resize_mode == ResizeMode.OUTER_FIT:
159	        estimation = min(k0, k1) * float(min(raw_H, raw_W))
160	    else:
161	        estimation = max(k0, k1) * float(min(raw_H, raw_W))
162	
163	    log.debug(f&quot;Pixel Perfect Computation:&quot;)
164	    log.debug(f&quot;resize_mode = {resize_mode}&quot;)
165	    log.debug(f&quot;raw_H = {raw_H}&quot;)
166	    log.debug(f&quot;raw_W = {raw_W}&quot;)
167	    log.debug(f&quot;target_H = {target_H}&quot;)
168	    log.debug(f&quot;target_W = {target_W}&quot;)
169	    log.debug(f&quot;estimation = {estimation}&quot;)
170	
171	    return int(np.round(estimation))
172	
173	#https://github.com/Mikubill/sd-webui-controlnet/blob/e67e017731aad05796b9615dc6eadce911298ea1/scripts/controlnet.py#L404
174	def safe_numpy(x):
175	    # A very safe method to make sure that Apple/Mac works
176	    y = x
177	
178	    # below is very boring but do not change these. If you change these Apple or Mac may fail.
179	    y = y.copy()
180	    y = np.ascontiguousarray(y)
181	    y = y.copy()
182	    return y
183	
184	#https://github.com/Mikubill/sd-webui-controlnet/blob/e67e017731aad05796b9615dc6eadce911298ea1/scripts/utils.py#L140
185	def get_unique_axis0(data):
186	    arr = np.asanyarray(data)
187	    idxs = np.lexsort(arr.T)
188	    arr = arr[idxs]
189	    unique_idxs = np.empty(len(arr), dtype=np.bool_)
190	    unique_idxs[:1] = True
191	    unique_idxs[1:] = np.any(arr[:-1, :] != arr[1:, :], axis=-1)
192	    return arr[unique_idxs]
193	
194	#Ref: https://github.com/ltdrdata/ComfyUI-Manager/blob/284e90dc8296a2e1e4f14b4b2d10fba2f52f0e53/__init__.py#L14
195	def handle_stream(stream, prefix):
196	    for line in stream:
197	        print(prefix, line, end=&quot;&quot;)
198	
199	
200	def run_script(cmd, cwd=&#x27;.&#x27;):
201	    process = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)
202	
203	    stdout_thread = threading.Thread(target=handle_stream, args=(process.stdout, &quot;&quot;))
204	    stderr_thread = threading.Thread(target=handle_stream, args=(process.stderr, &quot;[!]&quot;))
205	
206	    stdout_thread.start()
207	    stderr_thread.start()
208	
209	    stdout_thread.join()
210	    stderr_thread.join()
211	
212	    return process.wait()
213	
214	def nms(x, t, s):
215	    x = cv2.GaussianBlur(x.astype(np.float32), (0, 0), s)
216	
217	    f1 = np.array([[0, 0, 0], [1, 1, 1], [0, 0, 0]], dtype=np.uint8)
218	    f2 = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]], dtype=np.uint8)
219	    f3 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=np.uint8)
220	    f4 = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]], dtype=np.uint8)
221	
222	    y = np.zeros_like(x)
223	
224	    for f in [f1, f2, f3, f4]:
225	        np.putmask(y, cv2.dilate(x, kernel=f) == x, x)
226	
227	    z = np.zeros_like(y, dtype=np.uint8)
228	    z[y &gt; t] = 255
229	    return z
</pre>
</div>


</div>
</div>

</div>

</body>
</html>
